{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "我们已经实现了卷积层和池化层，现在来组合这些层，搭建进行手写数字识别的 CNN。这里的实现如下图所示。\n",
    "网络的构成是“Convolution - ReLU - Pooling -Affine - ReLU - Affine - Softmax”，我们将它实现为名为 SimpleConvNet 的类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "#卷积神经网络的python实现\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"简单的ConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 输入大小（MNIST的情况下为784）\n",
    "    hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]）\n",
    "    output_size : 输出大小（MNIST的情况下为10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 指定权重的标准差（e.g. 0.01）\n",
    "        指定'relu'或'he'的情况下设定“He的初始值”\n",
    "        指定'sigmoid'或'xavier'的情况下设定“Xavier的初始值”\n",
    "    \"\"\"\n",
    "    \n",
    "    '''\n",
    "    这里将由初始化参数传入的卷积层的超参数从字典中取了出来（以方便后面使用），然后，计算卷积层的输出大小。接下来是权重参数的初始化部分。\n",
    "    学习所需的参数是第 1 层的卷积层和剩余两个全连接层的权重和偏置。将这些参数保存在实例变量的 params 字典中。\n",
    "    将第 1 层的卷积层的权重设为关键字 W1，偏置设为关键字 b1。\n",
    "    同样，分别用关键字 W2、b2 和关键字 W3、b3 来保存第 2 个和第 3 个全连接层的权重和偏置。\n",
    "    \n",
    "    从最前面开始按顺序向有序字典（OrderedDict）的 layers 中添加层。只有最后的 SoftmaxWithLoss 层被添加到别的变量 lastLayer 中。\n",
    "    '''\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "\n",
    "    '''用于推理的 predict 方法从头开始依次调用已添加的层，并将结果传递给下一层。\n",
    "    在求损失函数的 loss 方法中，除了使用 predict 方法进行的 forward 处理之外，还会继续进行 forward 处理，直到到达最后的 SoftmaxWithLoss 层。'''\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"求损失函数\n",
    "        参数x是输入数据、t是教师标签\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"求梯度（数值微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 输入数据\n",
    "        t : 教师标签\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        具有各层的梯度的字典变量\n",
    "            grads['W1']、grads['W2']、...是各层的权重\n",
    "            grads['b1']、grads['b2']、...是各层的偏置\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    '''\n",
    "    参数的梯度通过误差反向传播法（反向传播）求出，通过把正向传播和反向传播组装在一起来完成。\n",
    "    因为已经在各层正确实现了正向传播和反向传播的功能，所以这里只需要以合适的顺序调用即可。\n",
    "    最后，把各个权重参数的梯度保存到 grads 字典中。\n",
    "    '''\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"求梯度（误差反向传播法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 输入数据\n",
    "        t : 教师标签\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        具有各层的梯度的字典变量\n",
    "            grads['W1']、grads['W2']、...是各层的权重\n",
    "            grads['b1']、grads['b2']、...是各层的偏置\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 设定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2997658292461685\n",
      "=== epoch:1, train acc:0.191, test acc:0.2 ===\n",
      "train loss:2.2976939292157237\n",
      "train loss:2.294979500079835\n",
      "train loss:2.2869464207086425\n",
      "train loss:2.2762563321579843\n",
      "train loss:2.2680487838847982\n",
      "train loss:2.2391743724389572\n",
      "train loss:2.2373111274153916\n",
      "train loss:2.1942367532859666\n",
      "train loss:2.195069453199639\n",
      "train loss:2.184659167032752\n",
      "train loss:2.1489931490948546\n",
      "train loss:2.0760491695615673\n",
      "train loss:2.050364768794575\n",
      "train loss:2.057782485366414\n",
      "train loss:1.964743392590386\n",
      "train loss:1.8721953209427034\n",
      "train loss:1.831547405385943\n",
      "train loss:1.8134421985375622\n",
      "train loss:1.7471001043631313\n",
      "train loss:1.6469086119056666\n",
      "train loss:1.5483079840317902\n",
      "train loss:1.4254511528776037\n",
      "train loss:1.368705952806135\n",
      "train loss:1.3138730109823231\n",
      "train loss:1.1619208229078708\n",
      "train loss:1.1676906446410462\n",
      "train loss:0.9390009943606372\n",
      "train loss:0.9975347226536381\n",
      "train loss:1.0896355882373654\n",
      "train loss:0.9329137566248794\n",
      "train loss:0.7920763312291735\n",
      "train loss:0.9039881908425547\n",
      "train loss:0.6668857808698108\n",
      "train loss:1.0033827080036777\n",
      "train loss:0.9243468435414331\n",
      "train loss:0.8765448309317877\n",
      "train loss:0.6223171709884191\n",
      "train loss:0.7112545613380528\n",
      "train loss:0.6099848822927738\n",
      "train loss:0.6382297556452398\n",
      "train loss:0.7716857611868052\n",
      "train loss:0.6445126993018446\n",
      "train loss:0.5383744107298442\n",
      "train loss:0.5299064872636214\n",
      "train loss:0.6726890804182619\n",
      "train loss:0.5732222668030303\n",
      "train loss:0.7715991619571111\n",
      "train loss:0.49541323999935166\n",
      "train loss:0.5776601940856149\n",
      "train loss:0.7299386627634319\n",
      "train loss:0.4409111875093002\n",
      "train loss:0.6886276309548174\n",
      "train loss:0.7360202244759649\n",
      "train loss:0.6199493049329922\n",
      "train loss:0.32348580418920575\n",
      "train loss:0.5177932479455319\n",
      "train loss:0.44999332358837074\n",
      "train loss:0.5209618164709073\n",
      "train loss:0.6110200587317182\n",
      "train loss:0.5511666489597655\n",
      "train loss:0.5024542635534062\n",
      "train loss:0.4240311830911548\n",
      "train loss:0.5435756855913194\n",
      "train loss:0.538858492610711\n",
      "train loss:0.534132693619069\n",
      "train loss:0.4521068780285003\n",
      "train loss:0.5865490029167306\n",
      "train loss:0.4156031075551072\n",
      "train loss:0.48891535318766066\n",
      "train loss:0.5836340163828405\n",
      "train loss:0.3466357555265189\n",
      "train loss:0.3381753224864271\n",
      "train loss:0.3246436298707948\n",
      "train loss:0.4822169757014011\n",
      "train loss:0.48393935744556926\n",
      "train loss:0.3979926860009879\n",
      "train loss:0.4206614332923177\n",
      "train loss:0.42195922697790406\n",
      "train loss:0.3537979415666433\n",
      "train loss:0.3418421556474259\n",
      "train loss:0.2967558425594029\n",
      "train loss:0.3259012493617572\n",
      "train loss:0.3077061339507284\n",
      "train loss:0.34111943888384005\n",
      "train loss:0.46745877688581705\n",
      "train loss:0.45975928357145934\n",
      "train loss:0.31991911572465326\n",
      "train loss:0.31501365016452615\n",
      "train loss:0.393755678729245\n",
      "train loss:0.36948199205787996\n",
      "train loss:0.5010952526893994\n",
      "train loss:0.41633521867473\n",
      "train loss:0.4306170437678323\n",
      "train loss:0.3943290228652891\n",
      "train loss:0.2692817113425634\n",
      "train loss:0.49696325342712216\n",
      "train loss:0.41372351296021953\n",
      "train loss:0.2728252156570874\n",
      "train loss:0.3919136051049368\n",
      "train loss:0.33614089891380877\n",
      "train loss:0.35719579100720666\n",
      "train loss:0.30518491221789296\n",
      "train loss:0.3390045770503669\n",
      "train loss:0.4372738790630606\n",
      "train loss:0.37264473690232947\n",
      "train loss:0.3552373578709211\n",
      "train loss:0.4090209306247\n",
      "train loss:0.4326189785736907\n",
      "train loss:0.3469434677210132\n",
      "train loss:0.36922252109528286\n",
      "train loss:0.37452475785938283\n",
      "train loss:0.19543954723448548\n",
      "train loss:0.3464879473929102\n",
      "train loss:0.4984262025453788\n",
      "train loss:0.23594384085606712\n",
      "train loss:0.37373564402117554\n",
      "train loss:0.29506503508670084\n",
      "train loss:0.34098954820111976\n",
      "train loss:0.3704602207596422\n",
      "train loss:0.3442432412522659\n",
      "train loss:0.4154128643517684\n",
      "train loss:0.33213648373118915\n",
      "train loss:0.4323179130388478\n",
      "train loss:0.3326212316908045\n",
      "train loss:0.4325379415958758\n",
      "train loss:0.3301793782534494\n",
      "train loss:0.29357081677481156\n",
      "train loss:0.42582313941026045\n",
      "train loss:0.26418710207821955\n",
      "train loss:0.28095030596866194\n",
      "train loss:0.3009899608648883\n",
      "train loss:0.2549626482831267\n",
      "train loss:0.510756635688637\n",
      "train loss:0.27562051188809084\n",
      "train loss:0.28587907590515627\n",
      "train loss:0.32182700245758306\n",
      "train loss:0.2622715978815312\n",
      "train loss:0.3758741147980041\n",
      "train loss:0.4027108120763737\n",
      "train loss:0.217009557923815\n",
      "train loss:0.4619272763936903\n",
      "train loss:0.3536425282601288\n",
      "train loss:0.29956560429183476\n",
      "train loss:0.5534262248631534\n",
      "train loss:0.1488489831777972\n",
      "train loss:0.33054816163085154\n",
      "train loss:0.24707714769229497\n",
      "train loss:0.4090232593950307\n",
      "train loss:0.558624020453261\n",
      "train loss:0.4011279328948365\n",
      "train loss:0.3695458357190143\n",
      "train loss:0.33883967852477\n",
      "train loss:0.2761120418171763\n",
      "train loss:0.4136983987404642\n",
      "train loss:0.48063089819424926\n",
      "train loss:0.359436707595249\n",
      "train loss:0.38054855135284016\n",
      "train loss:0.3391023621031639\n",
      "train loss:0.4393192468058546\n",
      "train loss:0.27575649877509395\n",
      "train loss:0.321028098550336\n",
      "train loss:0.3517184110689429\n",
      "train loss:0.2921801409228514\n",
      "train loss:0.3228032445147654\n",
      "train loss:0.19629823098329463\n",
      "train loss:0.21331657603561932\n",
      "train loss:0.2831551045721975\n",
      "train loss:0.3002550914091826\n",
      "train loss:0.3122283788821696\n",
      "train loss:0.4265650045915401\n",
      "train loss:0.2448825968722089\n",
      "train loss:0.22959584195581573\n",
      "train loss:0.28965978490586936\n",
      "train loss:0.32879160740782565\n",
      "train loss:0.24785606646358604\n",
      "train loss:0.37082110361015025\n",
      "train loss:0.2561303645869851\n",
      "train loss:0.27300745165989343\n",
      "train loss:0.4388682122190849\n",
      "train loss:0.27111256562057284\n",
      "train loss:0.1828041450734896\n",
      "train loss:0.2631557599216705\n",
      "train loss:0.3269322326501143\n",
      "train loss:0.21217291001437963\n",
      "train loss:0.3096448710664208\n",
      "train loss:0.3049845815749325\n",
      "train loss:0.25021578569410613\n",
      "train loss:0.36824259165791723\n",
      "train loss:0.31616138231506447\n",
      "train loss:0.32409574431910654\n",
      "train loss:0.3725951121264871\n",
      "train loss:0.26648786221752324\n",
      "train loss:0.2023309619911589\n",
      "train loss:0.31135489791758486\n",
      "train loss:0.20983910614848053\n",
      "train loss:0.26429369453858337\n",
      "train loss:0.31210447533899105\n",
      "train loss:0.33000096345213337\n",
      "train loss:0.31055619303930243\n",
      "train loss:0.2897565455602035\n",
      "train loss:0.3292145636905176\n",
      "train loss:0.25886710544575137\n",
      "train loss:0.25080590020996285\n",
      "train loss:0.25166088732125064\n",
      "train loss:0.2837352323714273\n",
      "train loss:0.19731819048323626\n",
      "train loss:0.3058635100127709\n",
      "train loss:0.292376853449946\n",
      "train loss:0.44098165976972686\n",
      "train loss:0.21127392686737956\n",
      "train loss:0.27647566928897993\n",
      "train loss:0.1939654809376156\n",
      "train loss:0.3988701785276836\n",
      "train loss:0.16412462608202397\n",
      "train loss:0.3335016703064174\n",
      "train loss:0.22013800347736956\n",
      "train loss:0.3656159227124212\n",
      "train loss:0.20780048645052043\n",
      "train loss:0.2770087415582533\n",
      "train loss:0.2878080974695528\n",
      "train loss:0.19779164149150838\n",
      "train loss:0.1931961733317393\n",
      "train loss:0.35034067282554693\n",
      "train loss:0.24172454423741319\n",
      "train loss:0.2624815800058842\n",
      "train loss:0.21140349516020748\n",
      "train loss:0.3090032989968645\n",
      "train loss:0.2810193063917442\n",
      "train loss:0.22474225526335015\n",
      "train loss:0.2216820816843597\n",
      "train loss:0.2103831624744374\n",
      "train loss:0.17679996041540608\n",
      "train loss:0.3228589948837683\n",
      "train loss:0.27225863928999205\n",
      "train loss:0.23502730000156993\n",
      "train loss:0.324640910954262\n",
      "train loss:0.24076434523234005\n",
      "train loss:0.2359364058408439\n",
      "train loss:0.2626385311992328\n",
      "train loss:0.22477000633737249\n",
      "train loss:0.4032267841181717\n",
      "train loss:0.20313058757433314\n",
      "train loss:0.31945416668985727\n",
      "train loss:0.27253477567216317\n",
      "train loss:0.2591824205387755\n",
      "train loss:0.30939625663077325\n",
      "train loss:0.3007102796863022\n",
      "train loss:0.13413488352962963\n",
      "train loss:0.4959254645994139\n",
      "train loss:0.22777005932022468\n",
      "train loss:0.19053280371135503\n",
      "train loss:0.22574423717357114\n",
      "train loss:0.1423759184822302\n",
      "train loss:0.24949999530389128\n",
      "train loss:0.268635322142241\n",
      "train loss:0.2937850495021152\n",
      "train loss:0.24565813023565705\n",
      "train loss:0.3379234841132952\n",
      "train loss:0.26815147003115736\n",
      "train loss:0.23248719315088945\n",
      "train loss:0.20183041991844455\n",
      "train loss:0.20767432471578462\n",
      "train loss:0.17406913074347802\n",
      "train loss:0.31397184240322823\n",
      "train loss:0.36475219726378577\n",
      "train loss:0.30437387249100617\n",
      "train loss:0.5282502664919854\n",
      "train loss:0.17816923655741632\n",
      "train loss:0.36709130563964953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11503723323634402\n",
      "train loss:0.3702603653074145\n",
      "train loss:0.2329779704337151\n",
      "train loss:0.33547984435078393\n",
      "train loss:0.29414185333577764\n",
      "train loss:0.17061465030864162\n",
      "train loss:0.19363743555584834\n",
      "train loss:0.24433457102680542\n",
      "train loss:0.20178325492904026\n",
      "train loss:0.271750338173601\n",
      "train loss:0.29484142711015726\n",
      "train loss:0.16228851425907911\n",
      "train loss:0.2794032311555996\n",
      "train loss:0.16903501072686744\n",
      "train loss:0.2312080545481032\n",
      "train loss:0.27323262102930534\n",
      "train loss:0.17967053459159232\n",
      "train loss:0.1562325813941826\n",
      "train loss:0.11552836880347644\n",
      "train loss:0.2139447253407502\n",
      "train loss:0.42911668826619676\n",
      "train loss:0.1974193649237805\n",
      "train loss:0.3923162005511975\n",
      "train loss:0.13250140735130123\n",
      "train loss:0.21484734784706988\n",
      "train loss:0.12290135550003659\n",
      "train loss:0.22039588656347153\n",
      "train loss:0.2838657632598781\n",
      "train loss:0.23416041889530156\n",
      "train loss:0.2375757273760441\n",
      "train loss:0.22013877522590675\n",
      "train loss:0.38160750359761036\n",
      "train loss:0.20493467236281912\n",
      "train loss:0.26536197244138954\n",
      "train loss:0.19360448731347404\n",
      "train loss:0.14454495119374727\n",
      "train loss:0.19398417285163075\n",
      "train loss:0.12551055891892562\n",
      "train loss:0.2393668490921482\n",
      "train loss:0.17560305952762575\n",
      "train loss:0.17587773391461473\n",
      "train loss:0.16940464962384508\n",
      "train loss:0.13355526378839294\n",
      "train loss:0.14225235074222928\n",
      "train loss:0.24504432302776588\n",
      "train loss:0.22703795428642945\n",
      "train loss:0.24181492410697258\n",
      "train loss:0.23333919001337727\n",
      "train loss:0.2276124071841614\n",
      "train loss:0.2784029502010886\n",
      "train loss:0.14624583892917634\n",
      "train loss:0.18559171126715068\n",
      "train loss:0.12202191995942435\n",
      "train loss:0.21516587755004646\n",
      "train loss:0.2606260460156972\n",
      "train loss:0.2020184402980653\n",
      "train loss:0.18184887004059752\n",
      "train loss:0.2335582567849279\n",
      "train loss:0.12631564175918256\n",
      "train loss:0.32206407387992625\n",
      "train loss:0.2156501557135033\n",
      "train loss:0.21799317273802798\n",
      "train loss:0.30319430319562785\n",
      "train loss:0.1907328850520274\n",
      "train loss:0.2070864888278227\n",
      "train loss:0.2257225785119809\n",
      "train loss:0.1901221939447326\n",
      "train loss:0.24810798840651085\n",
      "train loss:0.17385827819405994\n",
      "train loss:0.176207321948577\n",
      "train loss:0.17509168073366865\n",
      "train loss:0.19741024695943857\n",
      "train loss:0.16782562917181756\n",
      "train loss:0.3555547483047164\n",
      "train loss:0.2574756062884615\n",
      "train loss:0.11437150881425603\n",
      "train loss:0.265008722259883\n",
      "train loss:0.13834093845550544\n",
      "train loss:0.2139955579754721\n",
      "train loss:0.19087639888674413\n",
      "train loss:0.17864613753398811\n",
      "train loss:0.2803350226122607\n",
      "train loss:0.28092906509076454\n",
      "train loss:0.22188708281027722\n",
      "train loss:0.2506245074195934\n",
      "train loss:0.1637866641560844\n",
      "train loss:0.16212993717409963\n",
      "train loss:0.22791375596610725\n",
      "train loss:0.18763182871199863\n",
      "train loss:0.20925707233415686\n",
      "train loss:0.2668190446538834\n",
      "train loss:0.1610166131597384\n",
      "train loss:0.1623263521047252\n",
      "train loss:0.2175458712942583\n",
      "train loss:0.3095799325343508\n",
      "train loss:0.17027950401564648\n",
      "train loss:0.33625688771235057\n",
      "train loss:0.16407378972390382\n",
      "train loss:0.1942785811796819\n",
      "train loss:0.09665318385636171\n",
      "train loss:0.1762908688491091\n",
      "train loss:0.22041087916040772\n",
      "train loss:0.16802511885646498\n",
      "train loss:0.07502417048880174\n",
      "train loss:0.22633356711284058\n",
      "train loss:0.08483444907099871\n",
      "train loss:0.14854916510159527\n",
      "train loss:0.14931775581673157\n",
      "train loss:0.20277575690489766\n",
      "train loss:0.20262359136241428\n",
      "train loss:0.27043345260612744\n",
      "train loss:0.11372196874428217\n",
      "train loss:0.13451050977757084\n",
      "train loss:0.17834913656189447\n",
      "train loss:0.1852351474239151\n",
      "train loss:0.20980558549768372\n",
      "train loss:0.10968237652241328\n",
      "train loss:0.2432582758038024\n",
      "train loss:0.18254789495496607\n",
      "train loss:0.06918470252337328\n",
      "train loss:0.25799357631129544\n",
      "train loss:0.21308794191514774\n",
      "train loss:0.09275507855870359\n",
      "train loss:0.19988260328422347\n",
      "train loss:0.27213019332502913\n",
      "train loss:0.19853579818467876\n",
      "train loss:0.1411592443614847\n",
      "train loss:0.21110322949516053\n",
      "train loss:0.12319018596580253\n",
      "train loss:0.18454761210161627\n",
      "train loss:0.13451119894084798\n",
      "train loss:0.20447014265748087\n",
      "train loss:0.2174522795778363\n",
      "train loss:0.11870645560356291\n",
      "train loss:0.09784135063265052\n",
      "train loss:0.20537994849340163\n",
      "train loss:0.14734546394394007\n",
      "train loss:0.2842543203748598\n",
      "train loss:0.13277350967487966\n",
      "train loss:0.2664414263292551\n",
      "train loss:0.06491567052181785\n",
      "train loss:0.07740363658418994\n",
      "train loss:0.13000212739209208\n",
      "train loss:0.17049200659165706\n",
      "train loss:0.1889638347098901\n",
      "train loss:0.2315686665680224\n",
      "train loss:0.224524874158217\n",
      "train loss:0.10971672599627354\n",
      "train loss:0.26921133587078117\n",
      "train loss:0.10571609825427757\n",
      "train loss:0.18335260092215794\n",
      "train loss:0.07675890919287784\n",
      "train loss:0.18158747376285803\n",
      "train loss:0.11790565149088783\n",
      "train loss:0.12446314015940453\n",
      "train loss:0.15929698841934511\n",
      "train loss:0.1846472710712961\n",
      "train loss:0.15694684813671433\n",
      "train loss:0.10612619617736958\n",
      "train loss:0.19256404560065704\n",
      "train loss:0.12627322937669885\n",
      "train loss:0.1452052810008359\n",
      "train loss:0.314613387153286\n",
      "train loss:0.24169445322103736\n",
      "train loss:0.24739633046339532\n",
      "train loss:0.1600234459176634\n",
      "train loss:0.18072302800822337\n",
      "train loss:0.1612725538031518\n",
      "train loss:0.18756122497192693\n",
      "train loss:0.10702241199134482\n",
      "train loss:0.2708079799853603\n",
      "train loss:0.20613260721889173\n",
      "train loss:0.18353979087607455\n",
      "train loss:0.15514028776228161\n",
      "train loss:0.15774154325221873\n",
      "train loss:0.112975037160281\n",
      "train loss:0.1595873423857999\n",
      "train loss:0.10382370474295141\n",
      "train loss:0.10731300873811712\n",
      "train loss:0.1008406515864205\n",
      "train loss:0.10864451327927281\n",
      "train loss:0.17262207950889177\n",
      "train loss:0.27606406776376163\n",
      "train loss:0.09211616741013309\n",
      "train loss:0.2660236152836743\n",
      "train loss:0.1822826276473344\n",
      "train loss:0.17348784279819168\n",
      "train loss:0.18005277644604997\n",
      "train loss:0.12213661367759364\n",
      "train loss:0.14576971150045215\n",
      "train loss:0.15995450240439824\n",
      "train loss:0.13411410892766873\n",
      "train loss:0.09369391666682082\n",
      "train loss:0.19794211960348243\n",
      "train loss:0.21905288462763184\n",
      "train loss:0.1391308044523008\n",
      "train loss:0.12854977926282402\n",
      "train loss:0.18894039533686674\n",
      "train loss:0.20616257837913332\n",
      "train loss:0.15259576620106555\n",
      "train loss:0.08840991867351303\n",
      "train loss:0.17616647612739758\n",
      "train loss:0.16498859703901253\n",
      "train loss:0.12546976202962498\n",
      "train loss:0.09814827494650531\n",
      "train loss:0.10441285452307875\n",
      "train loss:0.0888594306981754\n",
      "train loss:0.1523096596812863\n",
      "train loss:0.10185387841222243\n",
      "train loss:0.14138553964572792\n",
      "train loss:0.13018463173175077\n",
      "train loss:0.14583672002741585\n",
      "train loss:0.2469413914341391\n",
      "train loss:0.21675870668183364\n",
      "train loss:0.2633027185679064\n",
      "train loss:0.12928967715461664\n",
      "train loss:0.23537488962512923\n",
      "train loss:0.1100214577778529\n",
      "train loss:0.1514303797926359\n",
      "train loss:0.096692618618295\n",
      "train loss:0.09407042441069371\n",
      "train loss:0.15901087275133086\n",
      "train loss:0.130487056663955\n",
      "train loss:0.15411236472299697\n",
      "train loss:0.21550381464399315\n",
      "train loss:0.22256662834971955\n",
      "train loss:0.13597089961130193\n",
      "train loss:0.1384365714093016\n",
      "train loss:0.11485518567940761\n",
      "train loss:0.3148020173619377\n",
      "train loss:0.10314488087153909\n",
      "train loss:0.07951642715927104\n",
      "train loss:0.11082150934173103\n",
      "train loss:0.19384805957559448\n",
      "train loss:0.2367323776574127\n",
      "train loss:0.11281882016646554\n",
      "train loss:0.11604067478353512\n",
      "train loss:0.14174254489829774\n",
      "train loss:0.14092367998197552\n",
      "train loss:0.22536639908456993\n",
      "train loss:0.21261231422361118\n",
      "train loss:0.0902265627341723\n",
      "train loss:0.2110184457756531\n",
      "train loss:0.18105131724728932\n",
      "train loss:0.1027605522772934\n",
      "train loss:0.14963262075078818\n",
      "train loss:0.12918473869296115\n",
      "train loss:0.13009734838996612\n",
      "train loss:0.15289991003483094\n",
      "train loss:0.08947419095927397\n",
      "train loss:0.0992391029092002\n",
      "train loss:0.20317771062340628\n",
      "train loss:0.1188022800933315\n",
      "train loss:0.18941893557165077\n",
      "train loss:0.06921535820383835\n",
      "train loss:0.21855287160475145\n",
      "train loss:0.15744967546082628\n",
      "train loss:0.07399512788656737\n",
      "train loss:0.07237461926321836\n",
      "train loss:0.15370895371714088\n",
      "train loss:0.09668506985354469\n",
      "train loss:0.237843698134811\n",
      "train loss:0.11459829259354488\n",
      "train loss:0.1376302368996704\n",
      "train loss:0.12949473663206967\n",
      "train loss:0.1075447441330733\n",
      "train loss:0.11064609073902366\n",
      "train loss:0.09114256109859278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.17592957925870312\n",
      "train loss:0.15920157703732385\n",
      "train loss:0.08721852039446447\n",
      "train loss:0.07478451706636267\n",
      "train loss:0.11783389243672625\n",
      "train loss:0.0951213992457998\n",
      "train loss:0.07092223947423312\n",
      "train loss:0.19053956409825198\n",
      "train loss:0.07634419653928055\n",
      "train loss:0.102052983083603\n",
      "train loss:0.3153738801778173\n",
      "train loss:0.06246714405351426\n",
      "train loss:0.09354968545583892\n",
      "train loss:0.10334950419431424\n",
      "train loss:0.19058308458138495\n",
      "train loss:0.08216589215923252\n",
      "train loss:0.21552949595816664\n",
      "train loss:0.06629568588061839\n",
      "train loss:0.13902605711230032\n",
      "train loss:0.18623646317135661\n",
      "train loss:0.16826711903758576\n",
      "train loss:0.1287523871630344\n",
      "train loss:0.1109371915325269\n",
      "train loss:0.1171181017612279\n",
      "train loss:0.16142791950397656\n",
      "train loss:0.13843096000391253\n",
      "train loss:0.12260421385180562\n",
      "train loss:0.10166284976673402\n",
      "train loss:0.06256129356694261\n",
      "train loss:0.11730296251305125\n",
      "train loss:0.14370399719589486\n",
      "train loss:0.26004378932572164\n",
      "train loss:0.2120836269247527\n",
      "train loss:0.10186931541772276\n",
      "train loss:0.09203933322182759\n",
      "train loss:0.22072506267300496\n",
      "train loss:0.16739781069267046\n",
      "train loss:0.1179752013412889\n",
      "train loss:0.13146606505518318\n",
      "train loss:0.11737169976309375\n",
      "train loss:0.10296004082072888\n",
      "train loss:0.12331603231133745\n",
      "train loss:0.12940526148260226\n",
      "train loss:0.14404166173612626\n",
      "train loss:0.15841100276797526\n",
      "train loss:0.09567787050130873\n",
      "train loss:0.1358120945145312\n",
      "train loss:0.15676436614678418\n",
      "train loss:0.13156393578843675\n",
      "train loss:0.07662740251982271\n",
      "train loss:0.09295925813915278\n",
      "train loss:0.059458491840874005\n",
      "train loss:0.15240352260200882\n",
      "train loss:0.08629106320652306\n",
      "train loss:0.1371594595634374\n",
      "train loss:0.10581058036128745\n",
      "train loss:0.18532829126742142\n",
      "train loss:0.2270600228740323\n",
      "train loss:0.086548853876217\n",
      "train loss:0.12679600419053794\n",
      "train loss:0.16405996461055647\n",
      "train loss:0.0644030693863405\n",
      "train loss:0.053580296448892145\n",
      "=== epoch:2, train acc:0.953, test acc:0.959 ===\n",
      "train loss:0.050576203644771695\n",
      "train loss:0.11770411313966626\n",
      "train loss:0.20973574555338864\n",
      "train loss:0.2039665961657378\n",
      "train loss:0.0840437210682392\n",
      "train loss:0.053070465615019075\n",
      "train loss:0.13309121542290106\n",
      "train loss:0.15024298354578589\n",
      "train loss:0.160207886028495\n",
      "train loss:0.08073410181145617\n",
      "train loss:0.08299366720563812\n",
      "train loss:0.14733118134343462\n",
      "train loss:0.07199096947264079\n",
      "train loss:0.17116594510089908\n",
      "train loss:0.201152510333645\n",
      "train loss:0.17857209288453657\n",
      "train loss:0.09483656471584995\n",
      "train loss:0.17359816640953724\n",
      "train loss:0.08513509972497557\n",
      "train loss:0.14562646301366236\n",
      "train loss:0.04134801272170366\n",
      "train loss:0.1219704469160132\n",
      "train loss:0.08316559830077912\n",
      "train loss:0.0723013892426951\n",
      "train loss:0.05865334483048398\n",
      "train loss:0.11449890425394775\n",
      "train loss:0.2016813077960097\n",
      "train loss:0.09812804122006634\n",
      "train loss:0.035107205074184085\n",
      "train loss:0.1626804873966399\n",
      "train loss:0.07092940744881031\n",
      "train loss:0.0890878513075286\n",
      "train loss:0.19286494097959492\n",
      "train loss:0.06915274391032797\n",
      "train loss:0.1108417685703612\n",
      "train loss:0.0933198902619813\n",
      "train loss:0.06008777733850636\n",
      "train loss:0.08949500729599758\n",
      "train loss:0.15973382440003753\n",
      "train loss:0.08730181477845181\n",
      "train loss:0.03992620143062905\n",
      "train loss:0.12127261894844274\n",
      "train loss:0.04694515049473384\n",
      "train loss:0.0866752066793575\n",
      "train loss:0.12217848261616275\n",
      "train loss:0.08855049877256438\n",
      "train loss:0.07639730144357389\n",
      "train loss:0.05673939411757379\n",
      "train loss:0.11899389740987512\n",
      "train loss:0.06815403084437727\n",
      "train loss:0.11503901595923308\n",
      "train loss:0.06537204368327429\n",
      "train loss:0.10478117719667378\n",
      "train loss:0.1417347799528718\n",
      "train loss:0.03810247128117731\n",
      "train loss:0.04479886917933396\n",
      "train loss:0.13860095326922892\n",
      "train loss:0.07347749296071882\n",
      "train loss:0.13304811024476146\n",
      "train loss:0.06560937243391933\n",
      "train loss:0.10636087952044763\n",
      "train loss:0.1407336674387131\n",
      "train loss:0.0867025672837065\n",
      "train loss:0.14834770479832543\n",
      "train loss:0.08614299864462764\n",
      "train loss:0.140567113856082\n",
      "train loss:0.132674397496448\n",
      "train loss:0.1784647558758742\n",
      "train loss:0.07154208951158807\n",
      "train loss:0.08892237185235886\n",
      "train loss:0.10649904804069213\n",
      "train loss:0.09883224578041999\n",
      "train loss:0.08255338132893376\n",
      "train loss:0.07856840863565141\n",
      "train loss:0.09847896772212289\n",
      "train loss:0.07946695109187774\n",
      "train loss:0.16281426855878872\n",
      "train loss:0.1140745945082993\n",
      "train loss:0.13801402897356932\n",
      "train loss:0.1131808595353685\n",
      "train loss:0.07115808098740682\n",
      "train loss:0.13579255286350356\n",
      "train loss:0.08217187476962556\n",
      "train loss:0.13419898792088414\n",
      "train loss:0.07361935403557625\n",
      "train loss:0.073355171256818\n",
      "train loss:0.0713445420615295\n",
      "train loss:0.07120344451827376\n",
      "train loss:0.09166008759195192\n",
      "train loss:0.11678197241033139\n",
      "train loss:0.11325666093175159\n",
      "train loss:0.17284159471907212\n",
      "train loss:0.056796809754379375\n",
      "train loss:0.03650201857103372\n",
      "train loss:0.159250577146235\n",
      "train loss:0.11283528257042887\n",
      "train loss:0.0861470394892433\n",
      "train loss:0.12088756071960771\n",
      "train loss:0.06563769210755134\n",
      "train loss:0.10565401282991309\n",
      "train loss:0.11656069406388124\n",
      "train loss:0.043773095185033306\n",
      "train loss:0.1671905954095196\n",
      "train loss:0.12219238262859934\n",
      "train loss:0.08262192317545253\n",
      "train loss:0.08030248988907168\n",
      "train loss:0.18534660703977812\n",
      "train loss:0.12075114886811854\n",
      "train loss:0.11009136927623166\n",
      "train loss:0.09826264569231839\n",
      "train loss:0.1935384337539002\n",
      "train loss:0.1359419470351807\n",
      "train loss:0.13005453110742846\n",
      "train loss:0.07722083442438965\n",
      "train loss:0.05369580815075019\n",
      "train loss:0.06482316510802011\n",
      "train loss:0.24995290394309286\n",
      "train loss:0.04492839012635895\n",
      "train loss:0.05778444969266644\n",
      "train loss:0.11459995999556843\n",
      "train loss:0.15415848239046018\n",
      "train loss:0.16315908421051858\n",
      "train loss:0.18354819934571381\n",
      "train loss:0.15487498448667855\n",
      "train loss:0.1026455886791104\n",
      "train loss:0.06711563221104525\n",
      "train loss:0.04920359235663101\n",
      "train loss:0.06362343031566216\n",
      "train loss:0.07383773300187152\n",
      "train loss:0.0710373276600169\n",
      "train loss:0.09298489620241565\n",
      "train loss:0.2139401952585834\n",
      "train loss:0.11679842412195283\n",
      "train loss:0.0799580149383296\n",
      "train loss:0.13696175636337501\n",
      "train loss:0.07122047852543888\n",
      "train loss:0.11108413750907031\n",
      "train loss:0.17009472896308198\n",
      "train loss:0.1807704835276912\n",
      "train loss:0.1774907605014241\n",
      "train loss:0.06398443473463662\n",
      "train loss:0.07516243812275519\n",
      "train loss:0.12663508391586958\n",
      "train loss:0.0933178098297375\n",
      "train loss:0.09650956869195401\n",
      "train loss:0.1414668278485691\n",
      "train loss:0.07825822159244694\n",
      "train loss:0.1862428620249156\n",
      "train loss:0.06002563810395665\n",
      "train loss:0.07319114560718071\n",
      "train loss:0.12183872418014245\n",
      "train loss:0.07870666951232297\n",
      "train loss:0.18506127978531262\n",
      "train loss:0.10195643598830709\n",
      "train loss:0.05295382437937569\n",
      "train loss:0.11052056630033476\n",
      "train loss:0.052419729149132975\n",
      "train loss:0.11930369111219445\n",
      "train loss:0.05925292702576586\n",
      "train loss:0.10636845566589623\n",
      "train loss:0.08113179280036334\n",
      "train loss:0.13916778049173734\n",
      "train loss:0.14511389202554262\n",
      "train loss:0.0823759291824871\n",
      "train loss:0.055836129897103286\n",
      "train loss:0.10155609330640061\n",
      "train loss:0.10196270749601727\n",
      "train loss:0.17803785054563384\n",
      "train loss:0.14418236099141002\n",
      "train loss:0.06809658950229774\n",
      "train loss:0.11070237975875806\n",
      "train loss:0.18095127887949616\n",
      "train loss:0.09842711885704296\n",
      "train loss:0.1009203553205582\n",
      "train loss:0.08276058605018145\n",
      "train loss:0.07238985687945249\n",
      "train loss:0.05493627927457103\n",
      "train loss:0.09148193603836363\n",
      "train loss:0.1500858657084924\n",
      "train loss:0.05817338991459908\n",
      "train loss:0.17110495448714771\n",
      "train loss:0.3282923111440617\n",
      "train loss:0.1173843487399874\n",
      "train loss:0.09675605213784548\n",
      "train loss:0.17929553280049038\n",
      "train loss:0.05592787077130805\n",
      "train loss:0.08147608713010332\n",
      "train loss:0.042171547273966555\n",
      "train loss:0.13585118027791818\n",
      "train loss:0.13981297248290406\n",
      "train loss:0.0929222505024256\n",
      "train loss:0.07441346485122262\n",
      "train loss:0.1825414285614968\n",
      "train loss:0.08740006998091088\n",
      "train loss:0.1583119349900306\n",
      "train loss:0.05547963144262388\n",
      "train loss:0.07086234105824281\n",
      "train loss:0.07027196240736627\n",
      "train loss:0.15321532300362167\n",
      "train loss:0.039652397439121655\n",
      "train loss:0.06379198883713552\n",
      "train loss:0.09770411166906222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07142162866442553\n",
      "train loss:0.09834632115535619\n",
      "train loss:0.1137418387411278\n",
      "train loss:0.07419341412254676\n",
      "train loss:0.05759994761483161\n",
      "train loss:0.0965219132767906\n",
      "train loss:0.0712180738617087\n",
      "train loss:0.11702847041122952\n",
      "train loss:0.10745169625989702\n",
      "train loss:0.10096202357984867\n",
      "train loss:0.053121593720037656\n",
      "train loss:0.09928729121357364\n",
      "train loss:0.10551234749366975\n",
      "train loss:0.05514516954389268\n",
      "train loss:0.06337440651874424\n",
      "train loss:0.045503012706797914\n",
      "train loss:0.06006038484303899\n",
      "train loss:0.1296942688472115\n",
      "train loss:0.04604912685143395\n",
      "train loss:0.049599818352415136\n",
      "train loss:0.09724273740011029\n",
      "train loss:0.2691621503166264\n",
      "train loss:0.052677487009465035\n",
      "train loss:0.0780116543859864\n",
      "train loss:0.1136549196033012\n",
      "train loss:0.06680357227156161\n",
      "train loss:0.03591651690471756\n",
      "train loss:0.05175641635064765\n",
      "train loss:0.07446649004338517\n",
      "train loss:0.09761383300070879\n",
      "train loss:0.10087805121973187\n",
      "train loss:0.11088493758857222\n",
      "train loss:0.058687493133742524\n",
      "train loss:0.08425840554142504\n",
      "train loss:0.051593707481848605\n",
      "train loss:0.10459082223659538\n",
      "train loss:0.02998288001853465\n",
      "train loss:0.14754287651922823\n",
      "train loss:0.19350880102874357\n",
      "train loss:0.12711534678434988\n",
      "train loss:0.0778833233933871\n",
      "train loss:0.055017618945033785\n",
      "train loss:0.0811753819530623\n",
      "train loss:0.082778939660487\n",
      "train loss:0.1364346414907799\n",
      "train loss:0.03735194161966773\n",
      "train loss:0.08004956166298158\n",
      "train loss:0.0547520538249753\n",
      "train loss:0.034017382265255434\n",
      "train loss:0.07273476894327462\n",
      "train loss:0.029742919163848455\n",
      "train loss:0.04142448466509697\n",
      "train loss:0.04348971593776165\n",
      "train loss:0.060450873016425447\n",
      "train loss:0.07236665806361756\n",
      "train loss:0.08918005295480688\n",
      "train loss:0.047640788543109894\n",
      "train loss:0.06521345320993203\n",
      "train loss:0.03773110828651937\n",
      "train loss:0.04042230345120161\n",
      "train loss:0.04927436272219166\n",
      "train loss:0.049781423482028825\n",
      "train loss:0.04070151433021775\n",
      "train loss:0.08062342602386316\n",
      "train loss:0.06645960364266601\n",
      "train loss:0.019445892308352107\n",
      "train loss:0.09249097910317852\n",
      "train loss:0.03589176100412464\n",
      "train loss:0.04146226594760802\n",
      "train loss:0.07534284539209832\n",
      "train loss:0.1332849405773251\n",
      "train loss:0.10686771199685817\n",
      "train loss:0.09779032982360875\n",
      "train loss:0.04651536211989095\n",
      "train loss:0.10061119359637187\n",
      "train loss:0.09725969332446603\n",
      "train loss:0.12801336816488734\n",
      "train loss:0.04167814080392345\n",
      "train loss:0.11037636508760779\n",
      "train loss:0.04745456024928078\n",
      "train loss:0.11571601682440796\n",
      "train loss:0.09687403003246936\n",
      "train loss:0.0585874123740901\n",
      "train loss:0.07016842972323474\n",
      "train loss:0.12726818253113586\n",
      "train loss:0.06439911266688678\n",
      "train loss:0.07303719343780092\n",
      "train loss:0.15220563712837182\n",
      "train loss:0.02389745625263795\n",
      "train loss:0.1314857015658382\n",
      "train loss:0.06974737098108466\n",
      "train loss:0.036402259534336595\n",
      "train loss:0.058572516203295226\n",
      "train loss:0.08428936216518038\n",
      "train loss:0.08912349873777826\n",
      "train loss:0.08026322694156438\n",
      "train loss:0.06044325273892793\n",
      "train loss:0.08462218355761075\n",
      "train loss:0.11558527070866496\n",
      "train loss:0.042590874150951315\n",
      "train loss:0.05882744847125758\n",
      "train loss:0.05353176905467546\n",
      "train loss:0.059197816715209496\n",
      "train loss:0.08499583354069612\n",
      "train loss:0.03839268582208708\n",
      "train loss:0.10546367368468794\n",
      "train loss:0.06482319258257065\n",
      "train loss:0.09385155574577739\n",
      "train loss:0.08206545260199384\n",
      "train loss:0.06226956240250831\n",
      "train loss:0.1022466365190692\n",
      "train loss:0.048728060837074684\n",
      "train loss:0.051476171430301434\n",
      "train loss:0.1824056938809937\n",
      "train loss:0.043479300576984015\n",
      "train loss:0.038085324756705834\n",
      "train loss:0.09022313558422916\n",
      "train loss:0.06982516542131548\n",
      "train loss:0.17150532877667005\n",
      "train loss:0.0858821791627681\n",
      "train loss:0.04556165791050578\n",
      "train loss:0.02702551956175712\n",
      "train loss:0.043355344568488066\n",
      "train loss:0.04994225024338042\n",
      "train loss:0.09141997016318912\n",
      "train loss:0.05119198890008627\n",
      "train loss:0.10700302495333544\n",
      "train loss:0.03641343663668206\n",
      "train loss:0.09545211704793718\n",
      "train loss:0.07862828697705028\n",
      "train loss:0.14662922200500936\n",
      "train loss:0.1842422870414811\n",
      "train loss:0.13251412622687286\n",
      "train loss:0.13413839414816223\n",
      "train loss:0.07591882658877483\n",
      "train loss:0.12753718731672176\n",
      "train loss:0.11115996385450445\n",
      "train loss:0.03767686834721988\n",
      "train loss:0.04974528024155443\n",
      "train loss:0.11356273078218755\n",
      "train loss:0.10107326728435533\n",
      "train loss:0.09370566598654535\n",
      "train loss:0.02827980846893779\n",
      "train loss:0.04972459190671134\n",
      "train loss:0.032065739263495825\n",
      "train loss:0.10762226528738943\n",
      "train loss:0.13948053263144072\n",
      "train loss:0.09545110437897666\n",
      "train loss:0.18656114929469175\n",
      "train loss:0.026730518460900233\n",
      "train loss:0.06089225957279137\n",
      "train loss:0.10329284598623661\n",
      "train loss:0.11115403994573526\n",
      "train loss:0.06568043738230098\n",
      "train loss:0.02749737896281703\n",
      "train loss:0.05566833614229016\n",
      "train loss:0.05853584645533465\n",
      "train loss:0.14747160459523204\n",
      "train loss:0.11025508010524059\n",
      "train loss:0.04667524111074337\n",
      "train loss:0.04972855000035461\n",
      "train loss:0.07328293831604671\n",
      "train loss:0.04146436503829794\n",
      "train loss:0.06727262086295407\n",
      "train loss:0.04617705698513295\n",
      "train loss:0.15688164390038262\n",
      "train loss:0.10652568696123786\n",
      "train loss:0.06778159343415012\n",
      "train loss:0.02875680846974289\n",
      "train loss:0.04169780767053788\n",
      "train loss:0.10903936279264786\n",
      "train loss:0.14878039821263994\n",
      "train loss:0.03937659062336556\n",
      "train loss:0.06578397074711263\n",
      "train loss:0.11394088542820169\n",
      "train loss:0.03595491462102929\n",
      "train loss:0.12465350518110696\n",
      "train loss:0.10428762190129615\n",
      "train loss:0.04670533929742926\n",
      "train loss:0.09367985575030623\n",
      "train loss:0.11339355550756505\n",
      "train loss:0.09995462954699962\n",
      "train loss:0.09385296379460988\n",
      "train loss:0.10785754786295602\n",
      "train loss:0.08504347621891056\n",
      "train loss:0.09352595390988784\n",
      "train loss:0.0969102233143492\n",
      "train loss:0.07328856663282948\n",
      "train loss:0.0336601438855531\n",
      "train loss:0.08914417819265165\n",
      "train loss:0.054616851926615674\n",
      "train loss:0.03749368139703425\n",
      "train loss:0.05677090668619374\n",
      "train loss:0.09965848372663663\n",
      "train loss:0.10205118209577094\n",
      "train loss:0.03667564287809564\n",
      "train loss:0.06234091644408458\n",
      "train loss:0.10878523152858074\n",
      "train loss:0.03908130771051392\n",
      "train loss:0.09002613197424654\n",
      "train loss:0.07875844904181058\n",
      "train loss:0.08467997977817968\n",
      "train loss:0.03603784942518296\n",
      "train loss:0.06539094333905975\n",
      "train loss:0.08277153175334172\n",
      "train loss:0.021354664181191706\n",
      "train loss:0.07924105847902782\n",
      "train loss:0.027270192044933084\n",
      "train loss:0.045528959635452095\n",
      "train loss:0.1173619771944056\n",
      "train loss:0.03381002019802639\n",
      "train loss:0.08566049528975636\n",
      "train loss:0.04209022018884584\n",
      "train loss:0.0539809936478078\n",
      "train loss:0.13345858039264502\n",
      "train loss:0.11786299750466817\n",
      "train loss:0.042541890899945825\n",
      "train loss:0.033416312972800885\n",
      "train loss:0.056125338734660885\n",
      "train loss:0.060205284358670924\n",
      "train loss:0.05004183846034217\n",
      "train loss:0.09355305587180159\n",
      "train loss:0.10196796077071149\n",
      "train loss:0.08477877277452173\n",
      "train loss:0.058082632856293\n",
      "train loss:0.026180209973238763\n",
      "train loss:0.09095506502263101\n",
      "train loss:0.05223334156853673\n",
      "train loss:0.05651932138305098\n",
      "train loss:0.061772676999755693\n",
      "train loss:0.04611361596012676\n",
      "train loss:0.03255757534120017\n",
      "train loss:0.1207176191923538\n",
      "train loss:0.05788716095191708\n",
      "train loss:0.08593013406481843\n",
      "train loss:0.05701684973737226\n",
      "train loss:0.08503402653364263\n",
      "train loss:0.03470339272978437\n",
      "train loss:0.12753258797643816\n",
      "train loss:0.046327302451523035\n",
      "train loss:0.07503810674333325\n",
      "train loss:0.024327873734843818\n",
      "train loss:0.0649465721611102\n",
      "train loss:0.01788599035669436\n",
      "train loss:0.030308840218038112\n",
      "train loss:0.11440990213909759\n",
      "train loss:0.09347099633442577\n",
      "train loss:0.03899450295646201\n",
      "train loss:0.030853165925830525\n",
      "train loss:0.06310586768182352\n",
      "train loss:0.03429985575159334\n",
      "train loss:0.09238380439693897\n",
      "train loss:0.07206042178113362\n",
      "train loss:0.10115924916170511\n",
      "train loss:0.046636848804992435\n",
      "train loss:0.022801395407341635\n",
      "train loss:0.059067727892501504\n",
      "train loss:0.02170430029233037\n",
      "train loss:0.027812564704193778\n",
      "train loss:0.10128625522661087\n",
      "train loss:0.05090249988731374\n",
      "train loss:0.016143570056866997\n",
      "train loss:0.12789868384209227\n",
      "train loss:0.053024420307672744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03156254237640892\n",
      "train loss:0.026637311295471474\n",
      "train loss:0.057917995001907904\n",
      "train loss:0.028677654595632793\n",
      "train loss:0.041300030681993914\n",
      "train loss:0.11330363773302446\n",
      "train loss:0.0370509029400231\n",
      "train loss:0.14071332050488924\n",
      "train loss:0.10489631987921406\n",
      "train loss:0.11528248277333752\n",
      "train loss:0.10706953755675092\n",
      "train loss:0.05001003017189412\n",
      "train loss:0.04415341668775516\n",
      "train loss:0.03453977481380711\n",
      "train loss:0.11415808110901239\n",
      "train loss:0.12385637557407424\n",
      "train loss:0.10451715378708626\n",
      "train loss:0.07951984708021106\n",
      "train loss:0.03320336959495342\n",
      "train loss:0.09234573531150586\n",
      "train loss:0.03850473875014655\n",
      "train loss:0.07390342373478695\n",
      "train loss:0.059534163627349736\n",
      "train loss:0.06329615905359509\n",
      "train loss:0.03296395482790355\n",
      "train loss:0.04587083404811598\n",
      "train loss:0.07142186001678963\n",
      "train loss:0.08535516735955437\n",
      "train loss:0.188591995077004\n",
      "train loss:0.0896408536231885\n",
      "train loss:0.036331349102431625\n",
      "train loss:0.019764197178483312\n",
      "train loss:0.10309316871438408\n",
      "train loss:0.08194770553791456\n",
      "train loss:0.025321966751013426\n",
      "train loss:0.05662243454596434\n",
      "train loss:0.06966911884244519\n",
      "train loss:0.13983168908155114\n",
      "train loss:0.04290434464959299\n",
      "train loss:0.04807925529029787\n",
      "train loss:0.12409512410092016\n",
      "train loss:0.05283752770034659\n",
      "train loss:0.053840847498131186\n",
      "train loss:0.18034429989618644\n",
      "train loss:0.0811633648126181\n",
      "train loss:0.026680174792772245\n",
      "train loss:0.06633083023497394\n",
      "train loss:0.057673638142022\n",
      "train loss:0.036765537057386694\n",
      "train loss:0.13559626265736852\n",
      "train loss:0.07502191867988083\n",
      "train loss:0.06312837590726658\n",
      "train loss:0.12630165385636855\n",
      "train loss:0.14530681150276892\n",
      "train loss:0.035877568189396664\n",
      "train loss:0.05738956901780007\n",
      "train loss:0.0946834061232147\n",
      "train loss:0.04699467321954685\n",
      "train loss:0.08198646803368201\n",
      "train loss:0.11516889952281233\n",
      "train loss:0.08442317675621482\n",
      "train loss:0.1975433488688369\n",
      "train loss:0.018772101661912805\n",
      "train loss:0.09074896908152037\n",
      "train loss:0.07631381258211117\n",
      "train loss:0.029312259697801556\n",
      "train loss:0.24905187440529875\n",
      "train loss:0.1069461795279034\n",
      "train loss:0.0834396537712425\n",
      "train loss:0.032683911823610357\n",
      "train loss:0.025346638922539952\n",
      "train loss:0.06112442016115895\n",
      "train loss:0.05895881722409404\n",
      "train loss:0.05364967722024243\n",
      "train loss:0.10807451604530606\n",
      "train loss:0.03064626921879411\n",
      "train loss:0.11579063105880652\n",
      "train loss:0.038707067088614565\n",
      "train loss:0.02572689277543898\n",
      "train loss:0.048835331519048654\n",
      "train loss:0.0554432650766882\n",
      "train loss:0.07156452806576018\n",
      "train loss:0.0650582235386762\n",
      "train loss:0.08564728521981063\n",
      "train loss:0.08692656694120926\n",
      "train loss:0.07149451339185318\n",
      "train loss:0.16230461551698616\n",
      "train loss:0.04173995980479873\n",
      "train loss:0.03282079614632992\n",
      "train loss:0.029930535334803478\n",
      "train loss:0.048830274182230286\n",
      "train loss:0.035125138692800116\n",
      "train loss:0.13781854015848993\n",
      "train loss:0.0382251610535263\n",
      "train loss:0.08615707318671154\n",
      "train loss:0.13339518807080922\n",
      "train loss:0.06782416363093685\n",
      "train loss:0.015246569306162756\n",
      "train loss:0.0235016631442925\n",
      "train loss:0.04197385218093725\n",
      "train loss:0.08484345536640198\n",
      "train loss:0.11928530942380103\n",
      "train loss:0.025844021960870423\n",
      "train loss:0.03984097009766703\n",
      "train loss:0.07866483703985694\n",
      "train loss:0.05056528843466946\n",
      "train loss:0.01972577427923209\n",
      "train loss:0.07446887130279327\n",
      "train loss:0.05392829271106267\n",
      "train loss:0.09546886471387697\n",
      "train loss:0.06074897870408793\n",
      "train loss:0.04900210892665416\n",
      "train loss:0.07515255055331221\n",
      "train loss:0.03894215610211023\n",
      "train loss:0.12332981381177677\n",
      "train loss:0.05723393073791026\n",
      "train loss:0.022733795305790463\n",
      "train loss:0.056611645401909785\n",
      "train loss:0.04739594085195681\n",
      "train loss:0.03080060260361131\n",
      "train loss:0.025807779819035398\n",
      "train loss:0.08722473444443887\n",
      "train loss:0.06795515774286445\n",
      "train loss:0.04348976375902235\n",
      "train loss:0.04964140166252466\n",
      "train loss:0.1665586648564991\n",
      "train loss:0.023799283414780728\n",
      "train loss:0.0328850296580136\n",
      "train loss:0.14468197695346027\n",
      "train loss:0.12122866435371561\n",
      "train loss:0.1188346662906575\n",
      "train loss:0.05171724178621763\n",
      "train loss:0.1650662830657838\n",
      "train loss:0.04609956685044076\n",
      "=== epoch:3, train acc:0.974, test acc:0.975 ===\n",
      "train loss:0.04035743189149714\n",
      "train loss:0.10635077476884654\n",
      "train loss:0.10817574096399596\n",
      "train loss:0.08500979261684001\n",
      "train loss:0.043229264382367696\n",
      "train loss:0.05579158718761252\n",
      "train loss:0.036583796850276185\n",
      "train loss:0.08785136756661999\n",
      "train loss:0.05561232647561786\n",
      "train loss:0.05793771959971557\n",
      "train loss:0.03805690949052601\n",
      "train loss:0.06751824141770275\n",
      "train loss:0.07824315086416317\n",
      "train loss:0.06287376707810045\n",
      "train loss:0.12968824650148636\n",
      "train loss:0.07179057059666892\n",
      "train loss:0.08245925465471095\n",
      "train loss:0.1050811824839205\n",
      "train loss:0.04556863766699903\n",
      "train loss:0.03685075438825027\n",
      "train loss:0.08369141893515161\n",
      "train loss:0.041969001421879495\n",
      "train loss:0.07052293901461987\n",
      "train loss:0.09028543540022874\n",
      "train loss:0.1588985527183573\n",
      "train loss:0.11600839041770622\n",
      "train loss:0.10098401904967591\n",
      "train loss:0.08704862443303617\n",
      "train loss:0.04383622342696857\n",
      "train loss:0.05424106719039273\n",
      "train loss:0.08137929803480345\n",
      "train loss:0.043967999841530804\n",
      "train loss:0.04185587133524948\n",
      "train loss:0.1616411606963161\n",
      "train loss:0.037897051840802026\n",
      "train loss:0.027156784291824915\n",
      "train loss:0.018437192223615298\n",
      "train loss:0.019767903249839555\n",
      "train loss:0.06737264741378295\n",
      "train loss:0.052777708389355305\n",
      "train loss:0.04552692865306955\n",
      "train loss:0.03406553790787226\n",
      "train loss:0.03521387928214586\n",
      "train loss:0.18424581698585893\n",
      "train loss:0.09019501235943368\n",
      "train loss:0.0470490221595926\n",
      "train loss:0.02794256284986328\n",
      "train loss:0.1560624088368694\n",
      "train loss:0.00789525028047363\n",
      "train loss:0.021784019851394536\n",
      "train loss:0.08476672512289117\n",
      "train loss:0.04298874720413554\n",
      "train loss:0.04848993706284349\n",
      "train loss:0.03923278761993477\n",
      "train loss:0.037613092927140795\n",
      "train loss:0.05666846136971494\n",
      "train loss:0.08782716688139207\n",
      "train loss:0.08014874392910407\n",
      "train loss:0.05180117727961476\n",
      "train loss:0.10285266612708696\n",
      "train loss:0.05585787320267227\n",
      "train loss:0.12742638994061858\n",
      "train loss:0.06608730089563593\n",
      "train loss:0.10075902648635422\n",
      "train loss:0.13549648455246419\n",
      "train loss:0.11098722711899718\n",
      "train loss:0.042348136947153205\n",
      "train loss:0.04936078401175898\n",
      "train loss:0.05754222019070363\n",
      "train loss:0.09545968970249624\n",
      "train loss:0.03284372670054789\n",
      "train loss:0.05593195194677612\n",
      "train loss:0.0455369184747265\n",
      "train loss:0.047273509995950216\n",
      "train loss:0.01993118904205007\n",
      "train loss:0.028346346472448367\n",
      "train loss:0.05786798536075339\n",
      "train loss:0.051921746395678606\n",
      "train loss:0.02099793370192398\n",
      "train loss:0.06777727354490963\n",
      "train loss:0.04654255188320336\n",
      "train loss:0.06098239832897773\n",
      "train loss:0.03436056886353258\n",
      "train loss:0.11886910650421255\n",
      "train loss:0.05896278963918041\n",
      "train loss:0.09402194238531371\n",
      "train loss:0.07600541803666802\n",
      "train loss:0.04171506873992267\n",
      "train loss:0.03129328536554185\n",
      "train loss:0.024586200487619912\n",
      "train loss:0.06242326237676209\n",
      "train loss:0.10934721632923403\n",
      "train loss:0.01385535945755187\n",
      "train loss:0.17166855745386914\n",
      "train loss:0.03578661804309515\n",
      "train loss:0.08722357846408725\n",
      "train loss:0.05708908059799476\n",
      "train loss:0.04834561062406041\n",
      "train loss:0.09771630388348564\n",
      "train loss:0.060737798449129354\n",
      "train loss:0.0448094456194474\n",
      "train loss:0.02246226899078106\n",
      "train loss:0.046461614593450405\n",
      "train loss:0.043222353303704955\n",
      "train loss:0.02964017250961417\n",
      "train loss:0.1267407073393012\n",
      "train loss:0.022581336693886\n",
      "train loss:0.061105983318691444\n",
      "train loss:0.11039932685385524\n",
      "train loss:0.05850868942184786\n",
      "train loss:0.03546390203731854\n",
      "train loss:0.0665436535083362\n",
      "train loss:0.03306624516982986\n",
      "train loss:0.09270313985429184\n",
      "train loss:0.04824184574502663\n",
      "train loss:0.11170392384510368\n",
      "train loss:0.08328077437871105\n",
      "train loss:0.09741943970656469\n",
      "train loss:0.057447127972850204\n",
      "train loss:0.08386837514902909\n",
      "train loss:0.05959512591934276\n",
      "train loss:0.0490131364053442\n",
      "train loss:0.03231067922067637\n",
      "train loss:0.07409103716976655\n",
      "train loss:0.01963471078405831\n",
      "train loss:0.040899101601958886\n",
      "train loss:0.05802464808847738\n",
      "train loss:0.02598098372171309\n",
      "train loss:0.02416846643519406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022090980973890013\n",
      "train loss:0.03393515741890551\n",
      "train loss:0.04434651573823909\n",
      "train loss:0.019887675028766396\n",
      "train loss:0.07132798617233355\n",
      "train loss:0.06768278016480318\n",
      "train loss:0.05745862198347534\n",
      "train loss:0.09898144505523966\n",
      "train loss:0.10086701002582477\n",
      "train loss:0.05336090998610608\n",
      "train loss:0.09962718190599375\n",
      "train loss:0.046190003122724275\n",
      "train loss:0.07982810635361787\n",
      "train loss:0.043115932602544885\n",
      "train loss:0.0355766949453766\n",
      "train loss:0.05067002399114332\n",
      "train loss:0.03432752174588036\n",
      "train loss:0.024862504840691444\n",
      "train loss:0.04893642773539451\n",
      "train loss:0.08689800966514177\n",
      "train loss:0.06273096184019124\n",
      "train loss:0.07919722762124515\n",
      "train loss:0.11331448142771251\n",
      "train loss:0.03163834007403477\n",
      "train loss:0.05856397243294368\n",
      "train loss:0.0777579439511118\n",
      "train loss:0.15830687592859952\n",
      "train loss:0.04316253397006297\n",
      "train loss:0.1473846773836011\n",
      "train loss:0.050270472110236844\n",
      "train loss:0.08817971542354153\n",
      "train loss:0.11137062133484939\n",
      "train loss:0.019424209973034623\n",
      "train loss:0.014887169210887228\n",
      "train loss:0.024026266409031133\n",
      "train loss:0.039988083482366654\n",
      "train loss:0.04912020366356875\n",
      "train loss:0.11457607011154834\n",
      "train loss:0.09230782241309239\n",
      "train loss:0.07254456248449694\n",
      "train loss:0.06008109495207561\n",
      "train loss:0.0498766128891148\n",
      "train loss:0.0523761740668128\n",
      "train loss:0.05909718510191018\n",
      "train loss:0.037208796989336934\n",
      "train loss:0.058964354203729946\n",
      "train loss:0.17962175527675808\n",
      "train loss:0.02889385248192963\n",
      "train loss:0.06761286792641646\n",
      "train loss:0.020066308203777087\n",
      "train loss:0.11085079663897314\n",
      "train loss:0.055986665204301886\n",
      "train loss:0.05073769757138078\n",
      "train loss:0.07872326069385978\n",
      "train loss:0.08747600579465198\n",
      "train loss:0.03922618440246304\n",
      "train loss:0.09798961573962364\n",
      "train loss:0.04257120722799817\n",
      "train loss:0.05933818202232511\n",
      "train loss:0.06653870548236765\n",
      "train loss:0.055761118351828044\n",
      "train loss:0.07109951053421994\n",
      "train loss:0.03276429497349427\n",
      "train loss:0.04853489502650463\n",
      "train loss:0.04101239876031812\n",
      "train loss:0.031217469512020077\n",
      "train loss:0.04787283760664717\n",
      "train loss:0.028708009125461807\n",
      "train loss:0.05121296498704106\n",
      "train loss:0.05972789810418828\n",
      "train loss:0.03699729037223565\n",
      "train loss:0.0732764875692151\n",
      "train loss:0.036845236008709537\n",
      "train loss:0.02199456448689606\n",
      "train loss:0.044283618837640495\n",
      "train loss:0.0987522059547044\n",
      "train loss:0.06567129328195857\n",
      "train loss:0.07967963488880368\n",
      "train loss:0.021643246056009695\n",
      "train loss:0.01786235381633243\n",
      "train loss:0.020119830907184503\n",
      "train loss:0.024163298069094785\n",
      "train loss:0.07221676015631587\n",
      "train loss:0.044328592674739487\n",
      "train loss:0.029056115281336243\n",
      "train loss:0.07062598119067162\n",
      "train loss:0.06004628779776992\n",
      "train loss:0.055605205568066716\n",
      "train loss:0.021324357029541437\n",
      "train loss:0.01932750402528004\n",
      "train loss:0.049942215562979106\n",
      "train loss:0.050929195993482786\n",
      "train loss:0.06132170164334573\n",
      "train loss:0.013599933181353345\n",
      "train loss:0.06243307390640388\n",
      "train loss:0.02606659473539347\n",
      "train loss:0.021172191182769032\n",
      "train loss:0.03069671658135748\n",
      "train loss:0.037458186053551834\n",
      "train loss:0.0525634667722444\n",
      "train loss:0.0524981771301938\n",
      "train loss:0.11220295397797861\n",
      "train loss:0.013787611219296909\n",
      "train loss:0.04621582805271997\n",
      "train loss:0.0940375412751328\n",
      "train loss:0.058018630265461696\n",
      "train loss:0.04175865888115658\n",
      "train loss:0.020273096614851296\n",
      "train loss:0.026669283587559503\n",
      "train loss:0.07560032004096259\n",
      "train loss:0.021339953107051616\n",
      "train loss:0.054753087389479226\n",
      "train loss:0.02032152977968254\n",
      "train loss:0.03777092971481824\n",
      "train loss:0.040647839899643046\n",
      "train loss:0.07950075741069275\n",
      "train loss:0.03443243962369314\n",
      "train loss:0.04922638933627065\n",
      "train loss:0.08016428031150767\n",
      "train loss:0.0410302798790749\n",
      "train loss:0.03320218808121477\n",
      "train loss:0.022958780448763275\n",
      "train loss:0.03127881776221474\n",
      "train loss:0.05346417939690666\n",
      "train loss:0.057549242382304674\n",
      "train loss:0.012929370421425992\n",
      "train loss:0.061274100594215036\n",
      "train loss:0.14430007814903864\n",
      "train loss:0.053344515880046746\n",
      "train loss:0.042594888616090044\n",
      "train loss:0.04214621309024977\n",
      "train loss:0.021150451052641354\n",
      "train loss:0.035704872788067894\n",
      "train loss:0.042804228095141\n",
      "train loss:0.0583684520780647\n",
      "train loss:0.06415399073123913\n",
      "train loss:0.026109023289090764\n",
      "train loss:0.029666922884033605\n",
      "train loss:0.08181298759578368\n",
      "train loss:0.03540889576856615\n",
      "train loss:0.11591641628145227\n",
      "train loss:0.08299233004748455\n",
      "train loss:0.030508021240352824\n",
      "train loss:0.009722570297759282\n",
      "train loss:0.10777917771813024\n",
      "train loss:0.05835878212529297\n",
      "train loss:0.08093427044360472\n",
      "train loss:0.04483670425809274\n",
      "train loss:0.10481559631946037\n",
      "train loss:0.020758690483237946\n",
      "train loss:0.069797654403657\n",
      "train loss:0.025921828677891327\n",
      "train loss:0.035167019329863713\n",
      "train loss:0.05813632092904841\n",
      "train loss:0.021384773334915508\n",
      "train loss:0.029382955885132546\n",
      "train loss:0.018762403808051924\n",
      "train loss:0.06748946853544566\n",
      "train loss:0.011189696066987418\n",
      "train loss:0.07916676504538663\n",
      "train loss:0.04594300676274022\n",
      "train loss:0.05434420536823659\n",
      "train loss:0.03306970694089501\n",
      "train loss:0.04110898923273416\n",
      "train loss:0.04379543252463262\n",
      "train loss:0.008184547578410677\n",
      "train loss:0.026221138081457207\n",
      "train loss:0.09526182362432771\n",
      "train loss:0.02488691124902964\n",
      "train loss:0.043519957849580605\n",
      "train loss:0.010336301951468571\n",
      "train loss:0.050084487096813304\n",
      "train loss:0.027892649435335187\n",
      "train loss:0.03376947502703288\n",
      "train loss:0.03294911754668231\n",
      "train loss:0.021161737023746262\n",
      "train loss:0.09818747342109635\n",
      "train loss:0.010005276082191449\n",
      "train loss:0.026634200479995863\n",
      "train loss:0.019445879231998586\n",
      "train loss:0.07862095018882423\n",
      "train loss:0.039831475536069715\n",
      "train loss:0.025442502362822902\n",
      "train loss:0.023374043263602245\n",
      "train loss:0.03286792185690379\n",
      "train loss:0.06135742729292873\n",
      "train loss:0.09768718642093564\n",
      "train loss:0.01819084663140811\n",
      "train loss:0.07162270623937578\n",
      "train loss:0.045066613865187115\n",
      "train loss:0.01630795478476262\n",
      "train loss:0.044315646273476866\n",
      "train loss:0.13204683355205482\n",
      "train loss:0.015386684702226283\n",
      "train loss:0.01524908962510259\n",
      "train loss:0.04330309725592239\n",
      "train loss:0.09022236411935396\n",
      "train loss:0.0187591879127436\n",
      "train loss:0.05187503996806336\n",
      "train loss:0.06160549423426522\n",
      "train loss:0.10448471892716885\n",
      "train loss:0.09002533174638488\n",
      "train loss:0.03497415978143911\n",
      "train loss:0.05406459744591827\n",
      "train loss:0.06024434022959916\n",
      "train loss:0.040531879842463876\n",
      "train loss:0.12197339356677998\n",
      "train loss:0.08184811300810782\n",
      "train loss:0.066427959341908\n",
      "train loss:0.06269856157936285\n",
      "train loss:0.1329996220827427\n",
      "train loss:0.07576365389430775\n",
      "train loss:0.041788548974784116\n",
      "train loss:0.09797385737693222\n",
      "train loss:0.0840685459144046\n",
      "train loss:0.023286844414853604\n",
      "train loss:0.09904239593663614\n",
      "train loss:0.0214632360453219\n",
      "train loss:0.07245368169588104\n",
      "train loss:0.03002586816297905\n",
      "train loss:0.02549781747649768\n",
      "train loss:0.008666219203506331\n",
      "train loss:0.03205708704800015\n",
      "train loss:0.018453533534147026\n",
      "train loss:0.0313992013130842\n",
      "train loss:0.0292062711830887\n",
      "train loss:0.13662241179132734\n",
      "train loss:0.05141029072902737\n",
      "train loss:0.042252620735071335\n",
      "train loss:0.015521656820485525\n",
      "train loss:0.07915907245504958\n",
      "train loss:0.01845290580781587\n",
      "train loss:0.03194076865072917\n",
      "train loss:0.03866795357024165\n",
      "train loss:0.03439769911476699\n",
      "train loss:0.04688985378627725\n",
      "train loss:0.0805694216249166\n",
      "train loss:0.023600979097668704\n",
      "train loss:0.04440300177512336\n",
      "train loss:0.027864193759417698\n",
      "train loss:0.033249442707641665\n",
      "train loss:0.05373768039552426\n",
      "train loss:0.04894760546766215\n",
      "train loss:0.041341745164261756\n",
      "train loss:0.05313056095665037\n",
      "train loss:0.1001946357105105\n",
      "train loss:0.031360619519025384\n",
      "train loss:0.05883649924317233\n",
      "train loss:0.07077800405908696\n",
      "train loss:0.10405353873500067\n",
      "train loss:0.0729957963043995\n",
      "train loss:0.044463654205814704\n",
      "train loss:0.06291097223501475\n",
      "train loss:0.057090909177630544\n",
      "train loss:0.07748854594195845\n",
      "train loss:0.08728352557957875\n",
      "train loss:0.037072536733882104\n",
      "train loss:0.07376423382740147\n",
      "train loss:0.04398247525355238\n",
      "train loss:0.010358238570360633\n",
      "train loss:0.026368603069796572\n",
      "train loss:0.048626746116361426\n",
      "train loss:0.0909356051345339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.029475689432447365\n",
      "train loss:0.042953925829396396\n",
      "train loss:0.04229192662067802\n",
      "train loss:0.052658749750039605\n",
      "train loss:0.043559112627700534\n",
      "train loss:0.04816326419700405\n",
      "train loss:0.038513406472495036\n",
      "train loss:0.04405232458852021\n",
      "train loss:0.029936417939878713\n",
      "train loss:0.016820974732966763\n",
      "train loss:0.025469934949695416\n",
      "train loss:0.044319297891515105\n",
      "train loss:0.018928778185876703\n",
      "train loss:0.030945060719580322\n",
      "train loss:0.10230151828140319\n",
      "train loss:0.06269922916833028\n",
      "train loss:0.04464572093496104\n",
      "train loss:0.049217677780603444\n",
      "train loss:0.025821825998259443\n",
      "train loss:0.03999117164923888\n",
      "train loss:0.023336737527937725\n",
      "train loss:0.07024095816487848\n",
      "train loss:0.026600473679015076\n",
      "train loss:0.058770438586974796\n",
      "train loss:0.045852683875145475\n",
      "train loss:0.040667720608171226\n",
      "train loss:0.016335021840520447\n",
      "train loss:0.05312411459448397\n",
      "train loss:0.03708681677889969\n",
      "train loss:0.030991959676456505\n",
      "train loss:0.061072030207810456\n",
      "train loss:0.060215001973397554\n",
      "train loss:0.1358279980169851\n",
      "train loss:0.009267947272778448\n",
      "train loss:0.021892475101460307\n",
      "train loss:0.04864721601273587\n",
      "train loss:0.09461292578036706\n",
      "train loss:0.026478478447500862\n",
      "train loss:0.07389003167992127\n",
      "train loss:0.03531568486482204\n",
      "train loss:0.02029297296455709\n",
      "train loss:0.06213654920356074\n",
      "train loss:0.07267064681710127\n",
      "train loss:0.03589432832224966\n",
      "train loss:0.047347996381956366\n",
      "train loss:0.038389842231581955\n",
      "train loss:0.042675308197887965\n",
      "train loss:0.054563040518161146\n",
      "train loss:0.03164556281055169\n",
      "train loss:0.05656343949156586\n",
      "train loss:0.03429660962003231\n",
      "train loss:0.04834316843458869\n",
      "train loss:0.059405799237676665\n",
      "train loss:0.02778643749409466\n",
      "train loss:0.09089525628517309\n",
      "train loss:0.028123415964306977\n",
      "train loss:0.0242279135866443\n",
      "train loss:0.10324569479386055\n",
      "train loss:0.06234546335022263\n",
      "train loss:0.04432285283343192\n",
      "train loss:0.03976088916806836\n",
      "train loss:0.06399911806494593\n",
      "train loss:0.012033067250333818\n",
      "train loss:0.020073451032420832\n",
      "train loss:0.014704218864390122\n",
      "train loss:0.05985180817992496\n",
      "train loss:0.01661907598238215\n",
      "train loss:0.02410093706425216\n",
      "train loss:0.012848794718568746\n",
      "train loss:0.04603655264441223\n",
      "train loss:0.06774294053244667\n",
      "train loss:0.03857496670705695\n",
      "train loss:0.038725593671870055\n",
      "train loss:0.04867462916888998\n",
      "train loss:0.06827980918895711\n",
      "train loss:0.04336196433801432\n",
      "train loss:0.035698662182789824\n",
      "train loss:0.048196393128129025\n",
      "train loss:0.037333562913053744\n",
      "train loss:0.011021585992571494\n",
      "train loss:0.03903598804806473\n",
      "train loss:0.07332038043335186\n",
      "train loss:0.04555723435828394\n",
      "train loss:0.023710629825826456\n",
      "train loss:0.027187131627079877\n",
      "train loss:0.03454199837259139\n",
      "train loss:0.12035576603513672\n",
      "train loss:0.1353326130629486\n",
      "train loss:0.1147309432747819\n",
      "train loss:0.024131966030869104\n",
      "train loss:0.020098333315444118\n",
      "train loss:0.06066329795794017\n",
      "train loss:0.01643748756952502\n",
      "train loss:0.02322237471799161\n",
      "train loss:0.04578356970162425\n",
      "train loss:0.01817066231515084\n",
      "train loss:0.09585069964222598\n",
      "train loss:0.07023795191699628\n",
      "train loss:0.016378929893992675\n",
      "train loss:0.03981164348231749\n",
      "train loss:0.06310423098354741\n",
      "train loss:0.09399743279037526\n",
      "train loss:0.03276996753896339\n",
      "train loss:0.06955151214815414\n",
      "train loss:0.03332691934970969\n",
      "train loss:0.05758103311880251\n",
      "train loss:0.04266653759077326\n",
      "train loss:0.030011731126397944\n",
      "train loss:0.03302040812528656\n",
      "train loss:0.023221273462992117\n",
      "train loss:0.016041280259376463\n",
      "train loss:0.09580882182970928\n",
      "train loss:0.015063067166785798\n",
      "train loss:0.0675492810418641\n",
      "train loss:0.01812702796684389\n",
      "train loss:0.043397284625590844\n",
      "train loss:0.07760378763567323\n",
      "train loss:0.010947868492971313\n",
      "train loss:0.015600748311753964\n",
      "train loss:0.026730107471548612\n",
      "train loss:0.01915696978525651\n",
      "train loss:0.024263949064233743\n",
      "train loss:0.01885793296413921\n",
      "train loss:0.14241396579719046\n",
      "train loss:0.0547833385707887\n",
      "train loss:0.04638585800001522\n",
      "train loss:0.03750257445223882\n",
      "train loss:0.04172300911919009\n",
      "train loss:0.048104962219528015\n",
      "train loss:0.03242825354850177\n",
      "train loss:0.028955612455530574\n",
      "train loss:0.12100810932319135\n",
      "train loss:0.020878600722365585\n",
      "train loss:0.03901566054191365\n",
      "train loss:0.051985580079292604\n",
      "train loss:0.04653980630765472\n",
      "train loss:0.07045389979624503\n",
      "train loss:0.07248466582554508\n",
      "train loss:0.04696423265409466\n",
      "train loss:0.025724703303706957\n",
      "train loss:0.012483468027119655\n",
      "train loss:0.0702433061662098\n",
      "train loss:0.0892386166711271\n",
      "train loss:0.07259295797302735\n",
      "train loss:0.06492550713900674\n",
      "train loss:0.07475014471349978\n",
      "train loss:0.02982868587976143\n",
      "train loss:0.10913524005809676\n",
      "train loss:0.024981704338479824\n",
      "train loss:0.11053243987930247\n",
      "train loss:0.059669758517129974\n",
      "train loss:0.04546213310105835\n",
      "train loss:0.044924108421924125\n",
      "train loss:0.007296511444853634\n",
      "train loss:0.0780908464436775\n",
      "train loss:0.028680081970689133\n",
      "train loss:0.026514092765087236\n",
      "train loss:0.05826807201906787\n",
      "train loss:0.015184610398705629\n",
      "train loss:0.03895975676454441\n",
      "train loss:0.04851479177660923\n",
      "train loss:0.019465832016175175\n",
      "train loss:0.04463151125782825\n",
      "train loss:0.030685922659520495\n",
      "train loss:0.014716993911113141\n",
      "train loss:0.026322539158440114\n",
      "train loss:0.02742092118207646\n",
      "train loss:0.03104184121917059\n",
      "train loss:0.09118719982705727\n",
      "train loss:0.052266411635255805\n",
      "train loss:0.10661600137367513\n",
      "train loss:0.014686531119883621\n",
      "train loss:0.013598937685595782\n",
      "train loss:0.018122095346344173\n",
      "train loss:0.02739492768127227\n",
      "train loss:0.02215816919248661\n",
      "train loss:0.08420092108430573\n",
      "train loss:0.04817606068782178\n",
      "train loss:0.03702191590319326\n",
      "train loss:0.02153982772658012\n",
      "train loss:0.03733756383167957\n",
      "train loss:0.01849256111567181\n",
      "train loss:0.051155882495366185\n",
      "train loss:0.0666820987679333\n",
      "train loss:0.021350926210965473\n",
      "train loss:0.03315622863666471\n",
      "train loss:0.09550715296304349\n",
      "train loss:0.012282288975574731\n",
      "train loss:0.04524054273027096\n",
      "train loss:0.008425331571016317\n",
      "train loss:0.04745625604439829\n",
      "train loss:0.030337621244999734\n",
      "train loss:0.02305004060866448\n",
      "train loss:0.03666473523956255\n",
      "train loss:0.041201439304553805\n",
      "train loss:0.04886582143460897\n",
      "train loss:0.059253298423426595\n",
      "train loss:0.09203821884814353\n",
      "train loss:0.048285074756288286\n",
      "train loss:0.04112316450847657\n",
      "train loss:0.028089593713330422\n",
      "train loss:0.055020908965254585\n",
      "train loss:0.017921297934808785\n",
      "train loss:0.034176432996543826\n",
      "train loss:0.054992712409363965\n",
      "train loss:0.02695926457672651\n",
      "train loss:0.05259654284009643\n",
      "train loss:0.05716197393003647\n",
      "=== epoch:4, train acc:0.977, test acc:0.976 ===\n",
      "train loss:0.19363671844398625\n",
      "train loss:0.033963393595385714\n",
      "train loss:0.04318430874355611\n",
      "train loss:0.0380719588611997\n",
      "train loss:0.05437765186466637\n",
      "train loss:0.13530507850141657\n",
      "train loss:0.07344138515496472\n",
      "train loss:0.0309500994064318\n",
      "train loss:0.10202042253438373\n",
      "train loss:0.04582874053140931\n",
      "train loss:0.10069950846784366\n",
      "train loss:0.021776042585406902\n",
      "train loss:0.023922903437895257\n",
      "train loss:0.060014920733100385\n",
      "train loss:0.08698319419913504\n",
      "train loss:0.08064618529137706\n",
      "train loss:0.054718330931401445\n",
      "train loss:0.01669479044033328\n",
      "train loss:0.007210546653609027\n",
      "train loss:0.02735442975792018\n",
      "train loss:0.03525160504289212\n",
      "train loss:0.023837854807389244\n",
      "train loss:0.0665880730153629\n",
      "train loss:0.014030695032268059\n",
      "train loss:0.018924992108988632\n",
      "train loss:0.030336473010914897\n",
      "train loss:0.06121256108042394\n",
      "train loss:0.03435600145414171\n",
      "train loss:0.11562559143601378\n",
      "train loss:0.09636219148872302\n",
      "train loss:0.060156058990419176\n",
      "train loss:0.02994961972044742\n",
      "train loss:0.03965226449754463\n",
      "train loss:0.04361865872522218\n",
      "train loss:0.022479969924875758\n",
      "train loss:0.0292239903650488\n",
      "train loss:0.02870955409316551\n",
      "train loss:0.03174555993986493\n",
      "train loss:0.03148667257707669\n",
      "train loss:0.028334449304066592\n",
      "train loss:0.016302127817406177\n",
      "train loss:0.05553422820945914\n",
      "train loss:0.08789089776644105\n",
      "train loss:0.07560565891076526\n",
      "train loss:0.03429081768990164\n",
      "train loss:0.08208824779889644\n",
      "train loss:0.027015039741461182\n",
      "train loss:0.034463592966454265\n",
      "train loss:0.09778412827876166\n",
      "train loss:0.07633595617107253\n",
      "train loss:0.12044129208160305\n",
      "train loss:0.02753729168148912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.021395814699574633\n",
      "train loss:0.021214544811588073\n",
      "train loss:0.03913710760689348\n",
      "train loss:0.07543836524511187\n",
      "train loss:0.03527759393264099\n",
      "train loss:0.007213572132114863\n",
      "train loss:0.051932347381228317\n",
      "train loss:0.1140672266547647\n",
      "train loss:0.05873422708175599\n",
      "train loss:0.07655844132164472\n",
      "train loss:0.04446491355583977\n",
      "train loss:0.026183703016825627\n",
      "train loss:0.0381060884757619\n",
      "train loss:0.04504253175685182\n",
      "train loss:0.05154914556205774\n",
      "train loss:0.007613884903039443\n",
      "train loss:0.04701783021271425\n",
      "train loss:0.01859904758691661\n",
      "train loss:0.018651573737914845\n",
      "train loss:0.04745508903377811\n",
      "train loss:0.07642416115355907\n",
      "train loss:0.1051588152935748\n",
      "train loss:0.08254561491847777\n",
      "train loss:0.03624512569678559\n",
      "train loss:0.025234463499597178\n",
      "train loss:0.16513703783540074\n",
      "train loss:0.07492138901495907\n",
      "train loss:0.1058794419700168\n",
      "train loss:0.049799629728075084\n",
      "train loss:0.0389596466613054\n",
      "train loss:0.07245775676261045\n",
      "train loss:0.16293721264622682\n",
      "train loss:0.04488149741234308\n",
      "train loss:0.09001636571321503\n",
      "train loss:0.06549712662670873\n",
      "train loss:0.03163831723943851\n",
      "train loss:0.07528041838850273\n",
      "train loss:0.05116293499997604\n",
      "train loss:0.025134291111688897\n",
      "train loss:0.0276687647848297\n",
      "train loss:0.019675356945445376\n",
      "train loss:0.04825573051210334\n",
      "train loss:0.038942133116408637\n",
      "train loss:0.02997557255219101\n",
      "train loss:0.04425351775224679\n",
      "train loss:0.02273461222605931\n",
      "train loss:0.07671961106532571\n",
      "train loss:0.06746428250024726\n",
      "train loss:0.07624241511656857\n",
      "train loss:0.0435582893292564\n",
      "train loss:0.054391225627023296\n",
      "train loss:0.01884144569925365\n",
      "train loss:0.02401413432452608\n",
      "train loss:0.03179955867252402\n",
      "train loss:0.01979976935684731\n",
      "train loss:0.008138038588909225\n",
      "train loss:0.05621112067437267\n",
      "train loss:0.06518356078881883\n",
      "train loss:0.011563080306006208\n",
      "train loss:0.025907741745630132\n",
      "train loss:0.047277019380386476\n",
      "train loss:0.055680410552891066\n",
      "train loss:0.022936667295949554\n",
      "train loss:0.11397931480563651\n",
      "train loss:0.025351811270117635\n",
      "train loss:0.05535256840759303\n",
      "train loss:0.04489866518740916\n",
      "train loss:0.053192793845290944\n",
      "train loss:0.015490078792308687\n",
      "train loss:0.12958509926575856\n",
      "train loss:0.015160247046697925\n",
      "train loss:0.09283675423453187\n",
      "train loss:0.01012862151918852\n",
      "train loss:0.039807040087455434\n",
      "train loss:0.019689650502351233\n",
      "train loss:0.013991877052197352\n",
      "train loss:0.034145411423684636\n",
      "train loss:0.07162986539554762\n",
      "train loss:0.09802695823286699\n",
      "train loss:0.010099081066681148\n",
      "train loss:0.0788154845019567\n",
      "train loss:0.007078010559408859\n",
      "train loss:0.02738218202090893\n",
      "train loss:0.05969262232716315\n",
      "train loss:0.04963671268859431\n",
      "train loss:0.019348051953285678\n",
      "train loss:0.18892081757932677\n",
      "train loss:0.011334411669866309\n",
      "train loss:0.01863401070960105\n",
      "train loss:0.02508381287875071\n",
      "train loss:0.044502676541483134\n",
      "train loss:0.03235783021868186\n",
      "train loss:0.030591205701718093\n",
      "train loss:0.011047028274807564\n",
      "train loss:0.03448683604403807\n",
      "train loss:0.06838931770959183\n",
      "train loss:0.029885784195515387\n",
      "train loss:0.01154649663872973\n",
      "train loss:0.025548951842272672\n",
      "train loss:0.02039478684737396\n",
      "train loss:0.013986047644906326\n",
      "train loss:0.13681442034053706\n",
      "train loss:0.03191560854296939\n",
      "train loss:0.05338147161987972\n",
      "train loss:0.010241036848951753\n",
      "train loss:0.05328603817267976\n",
      "train loss:0.00834017306700606\n",
      "train loss:0.020811340322117355\n",
      "train loss:0.035342957833676\n",
      "train loss:0.020395382051941368\n",
      "train loss:0.03284318500464342\n",
      "train loss:0.00912311149560336\n",
      "train loss:0.03652331844777835\n",
      "train loss:0.01755732506963386\n",
      "train loss:0.019468124045315085\n",
      "train loss:0.044812662848807874\n",
      "train loss:0.07219475146348815\n",
      "train loss:0.16879217981180886\n",
      "train loss:0.04484899769070542\n",
      "train loss:0.04565515941475314\n",
      "train loss:0.017884013036885884\n",
      "train loss:0.0942349882691262\n",
      "train loss:0.06414758994901358\n",
      "train loss:0.03733917014191975\n",
      "train loss:0.04255274026208218\n",
      "train loss:0.10398278485482017\n",
      "train loss:0.07532782523758048\n",
      "train loss:0.04763719576067124\n",
      "train loss:0.008879613564789956\n",
      "train loss:0.08825055521024538\n",
      "train loss:0.08280151619770354\n",
      "train loss:0.040758930661982155\n",
      "train loss:0.09475126675646825\n",
      "train loss:0.05987193584357999\n",
      "train loss:0.02672473307053329\n",
      "train loss:0.03581990285877641\n",
      "train loss:0.03986709750689289\n",
      "train loss:0.04129801829157989\n",
      "train loss:0.02448841845568985\n",
      "train loss:0.05431695992930573\n",
      "train loss:0.06278209863229868\n",
      "train loss:0.020436968982652116\n",
      "train loss:0.08025797321015263\n",
      "train loss:0.07408784579992425\n",
      "train loss:0.035490781520419776\n",
      "train loss:0.018825676188290567\n",
      "train loss:0.056501423358603996\n",
      "train loss:0.05003950330826792\n",
      "train loss:0.05400497130569712\n",
      "train loss:0.053735884941916195\n",
      "train loss:0.027527389150626934\n",
      "train loss:0.03503580570795911\n",
      "train loss:0.02215461722092918\n",
      "train loss:0.028971461317148416\n",
      "train loss:0.06253966198221711\n",
      "train loss:0.03970265507741527\n",
      "train loss:0.1090399327477191\n",
      "train loss:0.022609102453861326\n",
      "train loss:0.09928479522726236\n",
      "train loss:0.019071067661822424\n",
      "train loss:0.043358104861010736\n",
      "train loss:0.01767740284671813\n",
      "train loss:0.05962920592153073\n",
      "train loss:0.012262584180056999\n",
      "train loss:0.1849966195126655\n",
      "train loss:0.012540497816791264\n",
      "train loss:0.10491560204748325\n",
      "train loss:0.02397955613336081\n",
      "train loss:0.025300128782661798\n",
      "train loss:0.051975475723490906\n",
      "train loss:0.03153704598782975\n",
      "train loss:0.017521062970714145\n",
      "train loss:0.01748269846501999\n",
      "train loss:0.04754683214555524\n",
      "train loss:0.060674542252925304\n",
      "train loss:0.04952047006513152\n",
      "train loss:0.032812748282812984\n",
      "train loss:0.02498076265302781\n",
      "train loss:0.07173078555810895\n",
      "train loss:0.06826794235812343\n",
      "train loss:0.024375053125468414\n",
      "train loss:0.01396257545707973\n",
      "train loss:0.07176954881130414\n",
      "train loss:0.025956321934832913\n",
      "train loss:0.0270230399249061\n",
      "train loss:0.06484524579760156\n",
      "train loss:0.05340054694968557\n",
      "train loss:0.04941646904748076\n",
      "train loss:0.02401566116270517\n",
      "train loss:0.044611963826090756\n",
      "train loss:0.04552141154553716\n",
      "train loss:0.035204471070681836\n",
      "train loss:0.041716336598621485\n",
      "train loss:0.04034687953848955\n",
      "train loss:0.013229009472765431\n",
      "train loss:0.03538817342820446\n",
      "train loss:0.01043956358516591\n",
      "train loss:0.007598106861351776\n",
      "train loss:0.08403252198829601\n",
      "train loss:0.05603625987155374\n",
      "train loss:0.07899011131928106\n",
      "train loss:0.010026093014845033\n",
      "train loss:0.023755432783410232\n",
      "train loss:0.02757692212801432\n",
      "train loss:0.0755086709347324\n",
      "train loss:0.0199198373629204\n",
      "train loss:0.015692016353816438\n",
      "train loss:0.02265249232440591\n",
      "train loss:0.032426357756413546\n",
      "train loss:0.05044223155542792\n",
      "train loss:0.062224078603021725\n",
      "train loss:0.05530567070440301\n",
      "train loss:0.025972160353895185\n",
      "train loss:0.02616165207818652\n",
      "train loss:0.009210214816470988\n",
      "train loss:0.013489109988733355\n",
      "train loss:0.046072354168986696\n",
      "train loss:0.11095614979007662\n",
      "train loss:0.021051656056975045\n",
      "train loss:0.013114057205150974\n",
      "train loss:0.005498324301762126\n",
      "train loss:0.014355368876138317\n",
      "train loss:0.03127861939961384\n",
      "train loss:0.021692911156917596\n",
      "train loss:0.10958416302373958\n",
      "train loss:0.026557716148052024\n",
      "train loss:0.05045855661713542\n",
      "train loss:0.09118950262496213\n",
      "train loss:0.026846643363782233\n",
      "train loss:0.013782600294108795\n",
      "train loss:0.0960974558300461\n",
      "train loss:0.01911146957283721\n",
      "train loss:0.05531223557497669\n",
      "train loss:0.039833381108829086\n",
      "train loss:0.0237776610594259\n",
      "train loss:0.08777261998334776\n",
      "train loss:0.05054428656026179\n",
      "train loss:0.012668257772741562\n",
      "train loss:0.017094050746354925\n",
      "train loss:0.08140218311782403\n",
      "train loss:0.06581754855830703\n",
      "train loss:0.042513730537601824\n",
      "train loss:0.04303022105200196\n",
      "train loss:0.0306152480698999\n",
      "train loss:0.03878217680693269\n",
      "train loss:0.013587308081701442\n",
      "train loss:0.026555598494288558\n",
      "train loss:0.03209819343591103\n",
      "train loss:0.016593619105774858\n",
      "train loss:0.029775762564929344\n",
      "train loss:0.015021892832595555\n",
      "train loss:0.06575543018010256\n",
      "train loss:0.020189102436691676\n",
      "train loss:0.038008494391687055\n",
      "train loss:0.12549873143398935\n",
      "train loss:0.03509276115579525\n",
      "train loss:0.026648559859445455\n",
      "train loss:0.007060538130890848\n",
      "train loss:0.04253050457164046\n",
      "train loss:0.022485344198443436\n",
      "train loss:0.0398714935117305\n",
      "train loss:0.07694054729911728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.039851811687240744\n",
      "train loss:0.025222594159501427\n",
      "train loss:0.04281469503534732\n",
      "train loss:0.023848384613265345\n",
      "train loss:0.035616489692015425\n",
      "train loss:0.06413824098070771\n",
      "train loss:0.1004930607181535\n",
      "train loss:0.0193073405281403\n",
      "train loss:0.049926865587476964\n",
      "train loss:0.016490188723462692\n",
      "train loss:0.03429269748208043\n",
      "train loss:0.07809286597387645\n",
      "train loss:0.05507761152328008\n",
      "train loss:0.02987352623298925\n",
      "train loss:0.024422171673058296\n",
      "train loss:0.014063284338443114\n",
      "train loss:0.03734300359352048\n",
      "train loss:0.08133527407134983\n",
      "train loss:0.039728507521342465\n",
      "train loss:0.011014985726830025\n",
      "train loss:0.07762907823491073\n",
      "train loss:0.10796641557690306\n",
      "train loss:0.021083927386499352\n",
      "train loss:0.05868158347151106\n",
      "train loss:0.10555209473827805\n",
      "train loss:0.023837605712031525\n",
      "train loss:0.03692529576689461\n",
      "train loss:0.027108116621934398\n",
      "train loss:0.047843051319258416\n",
      "train loss:0.03160412721972047\n",
      "train loss:0.036440775866265776\n",
      "train loss:0.0646516552301917\n",
      "train loss:0.021593814180952547\n",
      "train loss:0.025825980828620945\n",
      "train loss:0.033755527004541284\n",
      "train loss:0.049269108066829735\n",
      "train loss:0.028450772786206627\n",
      "train loss:0.07863679971123554\n",
      "train loss:0.06118452474837384\n",
      "train loss:0.020214938504729635\n",
      "train loss:0.03701795291880703\n",
      "train loss:0.08202500862065092\n",
      "train loss:0.014339482149990089\n",
      "train loss:0.012274241238950602\n",
      "train loss:0.009216716110551868\n",
      "train loss:0.004974654692010756\n",
      "train loss:0.023905241532149207\n",
      "train loss:0.07980769185476266\n",
      "train loss:0.0358117399703386\n",
      "train loss:0.030792805094585977\n",
      "train loss:0.021754078157352644\n",
      "train loss:0.07025227247896329\n",
      "train loss:0.03063588897433903\n",
      "train loss:0.05631557510850966\n",
      "train loss:0.03038605169482602\n",
      "train loss:0.00942401277228463\n",
      "train loss:0.020757123035705143\n",
      "train loss:0.026502253862225177\n",
      "train loss:0.059391450212581826\n",
      "train loss:0.017206759148509596\n",
      "train loss:0.03747813473644844\n",
      "train loss:0.018508070175651703\n",
      "train loss:0.017096580513253707\n",
      "train loss:0.09390059231423564\n",
      "train loss:0.03963840330191795\n",
      "train loss:0.056872774815560835\n",
      "train loss:0.045338013393648936\n",
      "train loss:0.017569029636695443\n",
      "train loss:0.10382349002228482\n",
      "train loss:0.04259431168070612\n",
      "train loss:0.01174533541358355\n",
      "train loss:0.002538502728315488\n",
      "train loss:0.011350676159724587\n",
      "train loss:0.09068105870593318\n",
      "train loss:0.05064052487010681\n",
      "train loss:0.009797182216638394\n",
      "train loss:0.01982691770887007\n",
      "train loss:0.012703357228574576\n",
      "train loss:0.013888590772312491\n",
      "train loss:0.03638836757273574\n",
      "train loss:0.04718814145006757\n",
      "train loss:0.028002139901417155\n",
      "train loss:0.010866762378968903\n",
      "train loss:0.016850612165240222\n",
      "train loss:0.03381240169603552\n",
      "train loss:0.008407947774595387\n",
      "train loss:0.02854691770413301\n",
      "train loss:0.06420620841193313\n",
      "train loss:0.038902007240798474\n",
      "train loss:0.04534358257096642\n",
      "train loss:0.01633145732206629\n",
      "train loss:0.04576750055854938\n",
      "train loss:0.02245497369260953\n",
      "train loss:0.015627951402390955\n",
      "train loss:0.006742446151141229\n",
      "train loss:0.007093308749853069\n",
      "train loss:0.020180747365355398\n",
      "train loss:0.03406296388109306\n",
      "train loss:0.05253395133164124\n",
      "train loss:0.02325051543807373\n",
      "train loss:0.017344306832746723\n",
      "train loss:0.020102233203601452\n",
      "train loss:0.089795718243656\n",
      "train loss:0.023893831632668908\n",
      "train loss:0.11245608230956057\n",
      "train loss:0.005422204577707142\n",
      "train loss:0.015516389423669879\n",
      "train loss:0.031239780652976314\n",
      "train loss:0.016694058158060344\n",
      "train loss:0.028580995087137292\n",
      "train loss:0.06375370330862032\n",
      "train loss:0.015786636718694368\n",
      "train loss:0.04664940880628908\n",
      "train loss:0.013590101619665484\n",
      "train loss:0.01731239263728936\n",
      "train loss:0.03212878372999319\n",
      "train loss:0.06163939429206047\n",
      "train loss:0.029782216654676726\n",
      "train loss:0.03300332714375979\n",
      "train loss:0.006353666301671196\n",
      "train loss:0.04836253412455689\n",
      "train loss:0.04713146441604042\n",
      "train loss:0.04254378152664956\n",
      "train loss:0.012096845319043177\n",
      "train loss:0.0367259786850859\n",
      "train loss:0.08345691928427362\n",
      "train loss:0.05949318016134976\n",
      "train loss:0.024859701307602112\n",
      "train loss:0.014899795954182879\n",
      "train loss:0.02562405843654444\n",
      "train loss:0.019888242853163544\n",
      "train loss:0.03345344906897056\n",
      "train loss:0.0973892199722045\n",
      "train loss:0.01718758021923068\n",
      "train loss:0.029339774943307844\n",
      "train loss:0.026435775022274833\n",
      "train loss:0.031201145822079942\n",
      "train loss:0.0710598455936689\n",
      "train loss:0.011443785568637897\n",
      "train loss:0.008270263213930278\n",
      "train loss:0.013512616190488014\n",
      "train loss:0.11894236788413498\n",
      "train loss:0.0035223927442900095\n",
      "train loss:0.004435298948318802\n",
      "train loss:0.0631554962399068\n",
      "train loss:0.019859475750252244\n",
      "train loss:0.0160470473257735\n",
      "train loss:0.022574473222605754\n",
      "train loss:0.021643593451783873\n",
      "train loss:0.04148438405444632\n",
      "train loss:0.02082607695020092\n",
      "train loss:0.032742390406116186\n",
      "train loss:0.03774179979983417\n",
      "train loss:0.01776600459601007\n",
      "train loss:0.03486606364576717\n",
      "train loss:0.009425024544650815\n",
      "train loss:0.038895509086064116\n",
      "train loss:0.01323827272100973\n",
      "train loss:0.07014146706880826\n",
      "train loss:0.07660786380101253\n",
      "train loss:0.03601795911368143\n",
      "train loss:0.03778684604737783\n",
      "train loss:0.030458466004117408\n",
      "train loss:0.016887141300018327\n",
      "train loss:0.034360126880508914\n",
      "train loss:0.022722908217144625\n",
      "train loss:0.02933798232410104\n",
      "train loss:0.03377392502440059\n",
      "train loss:0.13185462118833902\n",
      "train loss:0.059893040117155884\n",
      "train loss:0.030955050676693602\n",
      "train loss:0.0117498271205329\n",
      "train loss:0.011333826519249237\n",
      "train loss:0.03383685633506959\n",
      "train loss:0.1753231161442616\n",
      "train loss:0.044556314378339915\n",
      "train loss:0.024023589311078637\n",
      "train loss:0.038061133417277085\n",
      "train loss:0.010712019479388516\n",
      "train loss:0.0077284407919191896\n",
      "train loss:0.0742850057990555\n",
      "train loss:0.05810792649918252\n",
      "train loss:0.015707377585535486\n",
      "train loss:0.018758983215543326\n",
      "train loss:0.012154230242937138\n",
      "train loss:0.013800894907870532\n",
      "train loss:0.040654934706884874\n",
      "train loss:0.14780148332351903\n",
      "train loss:0.010800409023076132\n",
      "train loss:0.013682357736156149\n",
      "train loss:0.0463032588350875\n",
      "train loss:0.08716011469890567\n",
      "train loss:0.01580196467885671\n",
      "train loss:0.05783126027015161\n",
      "train loss:0.03917016445872017\n",
      "train loss:0.016946016133186217\n",
      "train loss:0.022339881662992337\n",
      "train loss:0.03915134095771158\n",
      "train loss:0.03798205432937226\n",
      "train loss:0.0780259356555898\n",
      "train loss:0.05630104653829029\n",
      "train loss:0.057864791095453096\n",
      "train loss:0.028622970938543903\n",
      "train loss:0.05260107499941359\n",
      "train loss:0.019258371046722275\n",
      "train loss:0.026670331857846695\n",
      "train loss:0.018450610093080994\n",
      "train loss:0.034367641150350126\n",
      "train loss:0.024890586999890562\n",
      "train loss:0.09388764049055602\n",
      "train loss:0.036579958567263905\n",
      "train loss:0.07157713098044473\n",
      "train loss:0.020253328026229193\n",
      "train loss:0.0061308513387722694\n",
      "train loss:0.023250723945329507\n",
      "train loss:0.0639018338209909\n",
      "train loss:0.06755017490675944\n",
      "train loss:0.024517755869455836\n",
      "train loss:0.013247160230058784\n",
      "train loss:0.026417547121500316\n",
      "train loss:0.04534178642575857\n",
      "train loss:0.08771818930917645\n",
      "train loss:0.03495141305432756\n",
      "train loss:0.05386849307713915\n",
      "train loss:0.023931903010079233\n",
      "train loss:0.03016958406840661\n",
      "train loss:0.015088386878593391\n",
      "train loss:0.016000621452876895\n",
      "train loss:0.01846151558911558\n",
      "train loss:0.056222296489365144\n",
      "train loss:0.011467522334343417\n",
      "train loss:0.02980358238551302\n",
      "train loss:0.01784865497325608\n",
      "train loss:0.07373318035559259\n",
      "train loss:0.01136167306634595\n",
      "train loss:0.02539041268865603\n",
      "train loss:0.016382199175151727\n",
      "train loss:0.02618080664754617\n",
      "train loss:0.015885348351910727\n",
      "train loss:0.03424228531946147\n",
      "train loss:0.02318422350327452\n",
      "train loss:0.01327487037749238\n",
      "train loss:0.03594846259271606\n",
      "train loss:0.013218439151664867\n",
      "train loss:0.010484836208635941\n",
      "train loss:0.012340683050225863\n",
      "train loss:0.04365162780732278\n",
      "train loss:0.03199595098530337\n",
      "train loss:0.05695805755469637\n",
      "train loss:0.010519651807038375\n",
      "train loss:0.022626699122431284\n",
      "train loss:0.01968536327203295\n",
      "train loss:0.06305058349216969\n",
      "train loss:0.022104775366166125\n",
      "train loss:0.00996171905659266\n",
      "train loss:0.010750591427794403\n",
      "train loss:0.01849831158989834\n",
      "train loss:0.038979252969545866\n",
      "train loss:0.00773408675109361\n",
      "train loss:0.08290463571032973\n",
      "train loss:0.01325702254417939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008994469458949357\n",
      "train loss:0.028569232633986294\n",
      "train loss:0.011041956984140767\n",
      "train loss:0.040523606106724966\n",
      "train loss:0.012092131560616453\n",
      "train loss:0.02357447949749213\n",
      "train loss:0.04678941695929412\n",
      "train loss:0.011335432012836474\n",
      "train loss:0.02127933224831975\n",
      "train loss:0.15401150126837523\n",
      "train loss:0.005474012040722418\n",
      "train loss:0.040744716703265495\n",
      "train loss:0.03236995163847623\n",
      "train loss:0.040321957043741384\n",
      "train loss:0.03434664037366138\n",
      "train loss:0.006335239997390179\n",
      "train loss:0.017272426636799395\n",
      "train loss:0.011376053810914269\n",
      "train loss:0.02509807274323791\n",
      "train loss:0.010629351041023664\n",
      "train loss:0.0074013023940050875\n",
      "train loss:0.022836299559837517\n",
      "train loss:0.08517602820080176\n",
      "train loss:0.01052704381062877\n",
      "train loss:0.03952803437694539\n",
      "=== epoch:5, train acc:0.99, test acc:0.979 ===\n",
      "train loss:0.07149996864754109\n",
      "train loss:0.023659796730187508\n",
      "train loss:0.037046145833909416\n",
      "train loss:0.03549812204411816\n",
      "train loss:0.02412452971514599\n",
      "train loss:0.01948991159246921\n",
      "train loss:0.004404606407066377\n",
      "train loss:0.008971132235799152\n",
      "train loss:0.04164286567404742\n",
      "train loss:0.015499050948461384\n",
      "train loss:0.038008346354319204\n",
      "train loss:0.007528402370521504\n",
      "train loss:0.0414065201523703\n",
      "train loss:0.008348860926781911\n",
      "train loss:0.09103188466969725\n",
      "train loss:0.0530299640960572\n",
      "train loss:0.022324342646063054\n",
      "train loss:0.014141697154619359\n",
      "train loss:0.041269975406238\n",
      "train loss:0.023108843685688756\n",
      "train loss:0.08269866293241118\n",
      "train loss:0.017375693355828323\n",
      "train loss:0.03295345776944165\n",
      "train loss:0.03440996959470232\n",
      "train loss:0.02247133515649919\n",
      "train loss:0.01860597854532241\n",
      "train loss:0.01918951635749199\n",
      "train loss:0.01967926831460988\n",
      "train loss:0.03615732635492007\n",
      "train loss:0.01453788135800974\n",
      "train loss:0.012997051431004358\n",
      "train loss:0.08118704474113009\n",
      "train loss:0.029693965222223034\n",
      "train loss:0.06424386132089444\n",
      "train loss:0.034785087204517826\n",
      "train loss:0.03478113568704427\n",
      "train loss:0.025870070495502016\n",
      "train loss:0.03014493384854171\n",
      "train loss:0.016027344642511304\n",
      "train loss:0.049510592121437276\n",
      "train loss:0.10226425338551788\n",
      "train loss:0.01740456486366402\n",
      "train loss:0.06962328799806833\n",
      "train loss:0.03909843516726622\n",
      "train loss:0.03138265212243004\n",
      "train loss:0.032883904807292\n",
      "train loss:0.02845625517148545\n",
      "train loss:0.033093125144706616\n",
      "train loss:0.00882857044330976\n",
      "train loss:0.007439969592410039\n",
      "train loss:0.042380932054874886\n",
      "train loss:0.03227804449772775\n",
      "train loss:0.015187747258842931\n",
      "train loss:0.017773294464985788\n",
      "train loss:0.025315046920171693\n",
      "train loss:0.062098265212124575\n",
      "train loss:0.040784717774100275\n",
      "train loss:0.02162423827571561\n",
      "train loss:0.007673104331026112\n",
      "train loss:0.025317568160112394\n",
      "train loss:0.0190384067081884\n",
      "train loss:0.01035337187477936\n",
      "train loss:0.024136123494751284\n",
      "train loss:0.011562037861056688\n",
      "train loss:0.019513888563748468\n",
      "train loss:0.02343628225218406\n",
      "train loss:0.01750505400105621\n",
      "train loss:0.012171790676724715\n",
      "train loss:0.028601306495919177\n",
      "train loss:0.0190962031460901\n",
      "train loss:0.04144830446191985\n",
      "train loss:0.006715644358690295\n",
      "train loss:0.01593920850303318\n",
      "train loss:0.034689206115396054\n",
      "train loss:0.004945481601693375\n",
      "train loss:0.053762093221421815\n",
      "train loss:0.04602679596791401\n",
      "train loss:0.011128821548852162\n",
      "train loss:0.07522796147384139\n",
      "train loss:0.03395345654947452\n",
      "train loss:0.02175520571376237\n",
      "train loss:0.11250302755471156\n",
      "train loss:0.037337541008565324\n",
      "train loss:0.028264619652316764\n",
      "train loss:0.06398331811307019\n",
      "train loss:0.030529243951876915\n",
      "train loss:0.020698640415875647\n",
      "train loss:0.019094919297204475\n",
      "train loss:0.013728136493524756\n",
      "train loss:0.04434293776992128\n",
      "train loss:0.013358799242024653\n",
      "train loss:0.029190909027089013\n",
      "train loss:0.04885378526314397\n",
      "train loss:0.013659803098581204\n",
      "train loss:0.061702237204248396\n",
      "train loss:0.02061719629280927\n",
      "train loss:0.08484024673701615\n",
      "train loss:0.019201896040952956\n",
      "train loss:0.061996680692587985\n",
      "train loss:0.040374581508767306\n",
      "train loss:0.0111709465641391\n",
      "train loss:0.052107495335356704\n",
      "train loss:0.016741807719279182\n",
      "train loss:0.10445967730330484\n",
      "train loss:0.05345364586062785\n",
      "train loss:0.10233464021547763\n",
      "train loss:0.09876846819419736\n",
      "train loss:0.02557013032909999\n",
      "train loss:0.023072476892882325\n",
      "train loss:0.03450478410846019\n",
      "train loss:0.029036974567431345\n",
      "train loss:0.025564151138144486\n",
      "train loss:0.015752133660535808\n",
      "train loss:0.05912281287636046\n",
      "train loss:0.03900470696268958\n",
      "train loss:0.004169846607814514\n",
      "train loss:0.03366338831756026\n",
      "train loss:0.024303995672636903\n",
      "train loss:0.015215342024445013\n",
      "train loss:0.014157282995802704\n",
      "train loss:0.01139218612437264\n",
      "train loss:0.016237161956832686\n",
      "train loss:0.02879491343560425\n",
      "train loss:0.010839497313048533\n",
      "train loss:0.07272478178474887\n",
      "train loss:0.06278218823160812\n",
      "train loss:0.01707710632277561\n",
      "train loss:0.0860510423498134\n",
      "train loss:0.029521326056624435\n",
      "train loss:0.011945188131467187\n",
      "train loss:0.02402024070752947\n",
      "train loss:0.10901512722181521\n",
      "train loss:0.01094162978023304\n",
      "train loss:0.02221155275911843\n",
      "train loss:0.02575110292567771\n",
      "train loss:0.029835132522298826\n",
      "train loss:0.01002435904146663\n",
      "train loss:0.038504415363182456\n",
      "train loss:0.19196344459624928\n",
      "train loss:0.016777601810763737\n",
      "train loss:0.04080292568223845\n",
      "train loss:0.040827627968047765\n",
      "train loss:0.049616151200246206\n",
      "train loss:0.03202509795056335\n",
      "train loss:0.06409959711624452\n",
      "train loss:0.008583910572948838\n",
      "train loss:0.043753151729814144\n",
      "train loss:0.01970867560039828\n",
      "train loss:0.05704630392179664\n",
      "train loss:0.013914554164827293\n",
      "train loss:0.012494148162527863\n",
      "train loss:0.01957282522651575\n",
      "train loss:0.03270698367426002\n",
      "train loss:0.011439452828696024\n",
      "train loss:0.11023549737264332\n",
      "train loss:0.08930574817826312\n",
      "train loss:0.012962309409683402\n",
      "train loss:0.027749531046658022\n",
      "train loss:0.008635304582884468\n",
      "train loss:0.02186703563181073\n",
      "train loss:0.007114998280752852\n",
      "train loss:0.011673533766922522\n",
      "train loss:0.03224765373591004\n",
      "train loss:0.04069500727045484\n",
      "train loss:0.0135393887503798\n",
      "train loss:0.019407071418221757\n",
      "train loss:0.019031805994567406\n",
      "train loss:0.012726055663556219\n",
      "train loss:0.008228874677139134\n",
      "train loss:0.05257316630208203\n",
      "train loss:0.00901102451372973\n",
      "train loss:0.022363568496067396\n",
      "train loss:0.005090061723946256\n",
      "train loss:0.005922713280648357\n",
      "train loss:0.0264929369126904\n",
      "train loss:0.009951460705834352\n",
      "train loss:0.00811785523700182\n",
      "train loss:0.0415723169410018\n",
      "train loss:0.009238872484467848\n",
      "train loss:0.012416847198385806\n",
      "train loss:0.048493663065068346\n",
      "train loss:0.00399451156203087\n",
      "train loss:0.03324654335830933\n",
      "train loss:0.08742355471254734\n",
      "train loss:0.021256455802829595\n",
      "train loss:0.020253076328854994\n",
      "train loss:0.04844736744063601\n",
      "train loss:0.011683933530569617\n",
      "train loss:0.02076173791872856\n",
      "train loss:0.008593119849153204\n",
      "train loss:0.007262790581653673\n",
      "train loss:0.04596830559668839\n",
      "train loss:0.01589467756879887\n",
      "train loss:0.010110427368386233\n",
      "train loss:0.03326161813129678\n",
      "train loss:0.007837523611344002\n",
      "train loss:0.031135053160756532\n",
      "train loss:0.07323887884777044\n",
      "train loss:0.00975925140327751\n",
      "train loss:0.13419525881849242\n",
      "train loss:0.014490147133150723\n",
      "train loss:0.03148078666693276\n",
      "train loss:0.021622501654159246\n",
      "train loss:0.006000669760410475\n",
      "train loss:0.05117046831700972\n",
      "train loss:0.0450353741527623\n",
      "train loss:0.019277164826080072\n",
      "train loss:0.012084271128586796\n",
      "train loss:0.036702540535307554\n",
      "train loss:0.02754537112576783\n",
      "train loss:0.007021266378069485\n",
      "train loss:0.06160043645158736\n",
      "train loss:0.01334620018927231\n",
      "train loss:0.020127700373758536\n",
      "train loss:0.01382040804417168\n",
      "train loss:0.026430059303699863\n",
      "train loss:0.02433316064188864\n",
      "train loss:0.020917433002724518\n",
      "train loss:0.047434783614107016\n",
      "train loss:0.05413647776561385\n",
      "train loss:0.08214483301902174\n",
      "train loss:0.0038564104539228557\n",
      "train loss:0.018222929561312707\n",
      "train loss:0.0330918584022684\n",
      "train loss:0.07530655195779147\n",
      "train loss:0.017620444160324683\n",
      "train loss:0.04684561157647999\n",
      "train loss:0.010860321529857837\n",
      "train loss:0.0456121674292396\n",
      "train loss:0.007404335724916488\n",
      "train loss:0.023608925865790928\n",
      "train loss:0.005955433908444923\n",
      "train loss:0.034121968204192034\n",
      "train loss:0.03702046564502202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10048480688496504\n",
      "train loss:0.060654426796462095\n",
      "train loss:0.0049272117418620795\n",
      "train loss:0.014576390134183815\n",
      "train loss:0.00917947719418181\n",
      "train loss:0.03663174110482233\n",
      "train loss:0.01651642371297405\n",
      "train loss:0.00583482829873114\n",
      "train loss:0.06159814624744027\n",
      "train loss:0.011692865611457291\n",
      "train loss:0.0072219346130503815\n",
      "train loss:0.029574006070493278\n",
      "train loss:0.017944168308458717\n",
      "train loss:0.009024169706530133\n",
      "train loss:0.015200127963808555\n",
      "train loss:0.08152459456478851\n",
      "train loss:0.0636043477544988\n",
      "train loss:0.05225935268582026\n",
      "train loss:0.023334184213214267\n",
      "train loss:0.023198939899065345\n",
      "train loss:0.03955395404757348\n",
      "train loss:0.019739443183333892\n",
      "train loss:0.026456627130262374\n",
      "train loss:0.07690966546078751\n",
      "train loss:0.026632045747663997\n",
      "train loss:0.016468629695899906\n",
      "train loss:0.02801334196202587\n",
      "train loss:0.01662057103922318\n",
      "train loss:0.011199696973801234\n",
      "train loss:0.031125163326036116\n",
      "train loss:0.030710926936232136\n",
      "train loss:0.024433922919586796\n",
      "train loss:0.05695938448697081\n",
      "train loss:0.02161496041689575\n",
      "train loss:0.0380421491602374\n",
      "train loss:0.0825806078356477\n",
      "train loss:0.03948383434054792\n",
      "train loss:0.017322223542095817\n",
      "train loss:0.033864004176838776\n",
      "train loss:0.01220097818238394\n",
      "train loss:0.03201942981675493\n",
      "train loss:0.022420200416428622\n",
      "train loss:0.022151936480121436\n",
      "train loss:0.04164150277868725\n",
      "train loss:0.028284011886979998\n",
      "train loss:0.02426068648627306\n",
      "train loss:0.022609692836994627\n",
      "train loss:0.033439267282255936\n",
      "train loss:0.013739055669920307\n",
      "train loss:0.039780009655589976\n",
      "train loss:0.03845901399773494\n",
      "train loss:0.015877653304019756\n",
      "train loss:0.04699993436992442\n",
      "train loss:0.01813934978861224\n",
      "train loss:0.00733993711506754\n",
      "train loss:0.05407205248442279\n",
      "train loss:0.049416429818826456\n",
      "train loss:0.03692531957854103\n",
      "train loss:0.007315867827305046\n",
      "train loss:0.02205426328579501\n",
      "train loss:0.015392942988564156\n",
      "train loss:0.013719613758855706\n",
      "train loss:0.03330171903201454\n",
      "train loss:0.033188498945418976\n",
      "train loss:0.015774532304661623\n",
      "train loss:0.009672689964361594\n",
      "train loss:0.09055562495137608\n",
      "train loss:0.06518116982951958\n",
      "train loss:0.01823868438323044\n",
      "train loss:0.01687043391991162\n",
      "train loss:0.041949095577411395\n",
      "train loss:0.007884615229749103\n",
      "train loss:0.012602873037730309\n",
      "train loss:0.023453487383843025\n",
      "train loss:0.010870668498700291\n",
      "train loss:0.0068718654736142385\n",
      "train loss:0.01888063856653154\n",
      "train loss:0.004668512489735956\n",
      "train loss:0.01677907008977778\n",
      "train loss:0.03818988707058779\n",
      "train loss:0.016034301866878424\n",
      "train loss:0.010584225597297658\n",
      "train loss:0.04353749714627758\n",
      "train loss:0.010679631836682532\n",
      "train loss:0.03290606178306892\n",
      "train loss:0.00199080617345748\n",
      "train loss:0.005548382161837142\n",
      "train loss:0.09050618548165142\n",
      "train loss:0.03665927519389927\n",
      "train loss:0.029751255100976096\n",
      "train loss:0.011500014833227445\n",
      "train loss:0.022899126854408786\n",
      "train loss:0.046001275206662376\n",
      "train loss:0.06255030036306555\n",
      "train loss:0.03823714382071378\n",
      "train loss:0.009738114977246071\n",
      "train loss:0.03737437775429917\n",
      "train loss:0.00419349590289091\n",
      "train loss:0.025935240896508407\n",
      "train loss:0.021325969276897883\n",
      "train loss:0.029935683448945656\n",
      "train loss:0.04029021502212291\n",
      "train loss:0.007088252381847059\n",
      "train loss:0.012883093896284914\n",
      "train loss:0.020493342811153014\n",
      "train loss:0.034884467314149986\n",
      "train loss:0.034180822128982366\n",
      "train loss:0.021609601632201148\n",
      "train loss:0.019991183723032335\n",
      "train loss:0.03747251731037384\n",
      "train loss:0.041652093349019745\n",
      "train loss:0.06025776600765845\n",
      "train loss:0.038163459494325584\n",
      "train loss:0.04787999344641272\n",
      "train loss:0.009974948560089798\n",
      "train loss:0.019984714405929697\n",
      "train loss:0.015447691855836393\n",
      "train loss:0.017361386896793424\n",
      "train loss:0.013098514968652726\n",
      "train loss:0.017536745314895286\n",
      "train loss:0.02328467212159605\n",
      "train loss:0.017357394005980045\n",
      "train loss:0.028230777741208933\n",
      "train loss:0.01678300150274768\n",
      "train loss:0.035861244136461363\n",
      "train loss:0.03050063410108882\n",
      "train loss:0.011038184198867183\n",
      "train loss:0.028767842583512934\n",
      "train loss:0.004866438285675668\n",
      "train loss:0.02745457734429786\n",
      "train loss:0.021811377825419056\n",
      "train loss:0.029126217803853893\n",
      "train loss:0.015283038987814286\n",
      "train loss:0.013718675600910396\n",
      "train loss:0.10808567304202263\n",
      "train loss:0.01984654950727558\n",
      "train loss:0.017292188104231145\n",
      "train loss:0.014101997022629648\n",
      "train loss:0.05837773914875527\n",
      "train loss:0.010270281795274503\n",
      "train loss:0.05860279548177773\n",
      "train loss:0.03900537976421441\n",
      "train loss:0.01591941774598109\n",
      "train loss:0.05133219762541546\n",
      "train loss:0.032151489997645985\n",
      "train loss:0.03155799603466535\n",
      "train loss:0.01632536877997183\n",
      "train loss:0.032283493281428724\n",
      "train loss:0.01330141563842753\n",
      "train loss:0.028420912956890056\n",
      "train loss:0.033845156163132446\n",
      "train loss:0.0042398310759298955\n",
      "train loss:0.027910323156096803\n",
      "train loss:0.0210951232778574\n",
      "train loss:0.031216285033987153\n",
      "train loss:0.031705218352696816\n",
      "train loss:0.012266633215814315\n",
      "train loss:0.023262255422250085\n",
      "train loss:0.05662296719776399\n",
      "train loss:0.06430992318316905\n",
      "train loss:0.03138881201745548\n",
      "train loss:0.02762467015209926\n",
      "train loss:0.0300034462185832\n",
      "train loss:0.007692017192805732\n",
      "train loss:0.11382575387907386\n",
      "train loss:0.05363540535545885\n",
      "train loss:0.02299024919076527\n",
      "train loss:0.012179170366011847\n",
      "train loss:0.017787124873939283\n",
      "train loss:0.011032341278865699\n",
      "train loss:0.037891378355608275\n",
      "train loss:0.01127350136021968\n",
      "train loss:0.03519768288480119\n",
      "train loss:0.0063621231815392185\n",
      "train loss:0.06616162750550014\n",
      "train loss:0.04298257743840602\n",
      "train loss:0.08082145387384515\n",
      "train loss:0.005049729841942492\n",
      "train loss:0.012766386791426342\n",
      "train loss:0.03675389580117287\n",
      "train loss:0.04122088328294594\n",
      "train loss:0.03047912246378194\n",
      "train loss:0.01086208144564172\n",
      "train loss:0.06788522944992298\n",
      "train loss:0.022461088421314227\n",
      "train loss:0.004311845416078831\n",
      "train loss:0.0490315145946326\n",
      "train loss:0.010675522588457916\n",
      "train loss:0.013748935899259306\n",
      "train loss:0.035428537130318995\n",
      "train loss:0.050869834758466584\n",
      "train loss:0.03246046310242135\n",
      "train loss:0.035055869460036526\n",
      "train loss:0.006665327836114824\n",
      "train loss:0.014846841296327936\n",
      "train loss:0.006735915413752573\n",
      "train loss:0.01307104352173903\n",
      "train loss:0.039079903928221804\n",
      "train loss:0.018924149647004344\n",
      "train loss:0.0331210923775031\n",
      "train loss:0.01772863330018358\n",
      "train loss:0.04623551726752566\n",
      "train loss:0.05272644081508618\n",
      "train loss:0.00952274299230216\n",
      "train loss:0.006612362086881149\n",
      "train loss:0.019012990282536318\n",
      "train loss:0.007154492294078646\n",
      "train loss:0.010293395575904776\n",
      "train loss:0.007941984170560131\n",
      "train loss:0.020102842861013905\n",
      "train loss:0.02303102866887778\n",
      "train loss:0.025716899793146647\n",
      "train loss:0.017003689620982653\n",
      "train loss:0.03621769270207027\n",
      "train loss:0.023128647256300768\n",
      "train loss:0.017394404677813127\n",
      "train loss:0.014933587315844725\n",
      "train loss:0.04711409171624162\n",
      "train loss:0.01709116801836994\n",
      "train loss:0.009514849256174674\n",
      "train loss:0.007668338688622529\n",
      "train loss:0.014447198285155206\n",
      "train loss:0.013626945998130042\n",
      "train loss:0.017047924512829972\n",
      "train loss:0.06539325672956822\n",
      "train loss:0.02625283132269188\n",
      "train loss:0.025384686393538445\n",
      "train loss:0.023482347188120683\n",
      "train loss:0.015161742833263494\n",
      "train loss:0.010483924583933116\n",
      "train loss:0.02934507080844781\n",
      "train loss:0.018659424647717665\n",
      "train loss:0.016397857740060993\n",
      "train loss:0.030604690592875218\n",
      "train loss:0.013008189363440139\n",
      "train loss:0.005287614187748132\n",
      "train loss:0.013704738249649094\n",
      "train loss:0.006552704351551665\n",
      "train loss:0.0215867844352471\n",
      "train loss:0.013952737945254291\n",
      "train loss:0.06176058875674498\n",
      "train loss:0.03880326816810681\n",
      "train loss:0.03428723816997428\n",
      "train loss:0.03218555347093517\n",
      "train loss:0.004899132254694658\n",
      "train loss:0.03660771583767651\n",
      "train loss:0.04814327816469292\n",
      "train loss:0.0335927737250203\n",
      "train loss:0.016836822101824196\n",
      "train loss:0.03389544675744071\n",
      "train loss:0.0252364527501213\n",
      "train loss:0.01602441188369102\n",
      "train loss:0.012754784400098654\n",
      "train loss:0.025605085258125306\n",
      "train loss:0.02335414073094907\n",
      "train loss:0.05266244022642209\n",
      "train loss:0.013730854030381467\n",
      "train loss:0.008556771034085878\n",
      "train loss:0.004026160881277466\n",
      "train loss:0.045370365857102087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006884697575044867\n",
      "train loss:0.005670849266810549\n",
      "train loss:0.031642579519776545\n",
      "train loss:0.014467716038026568\n",
      "train loss:0.032462806229565745\n",
      "train loss:0.017301632704232555\n",
      "train loss:0.009954073377255443\n",
      "train loss:0.004670176403715366\n",
      "train loss:0.002780822634486214\n",
      "train loss:0.06733863590715251\n",
      "train loss:0.009831237668069932\n",
      "train loss:0.014694959660789472\n",
      "train loss:0.0038575888992179023\n",
      "train loss:0.006864124846710113\n",
      "train loss:0.012261350699610511\n",
      "train loss:0.017389403402982995\n",
      "train loss:0.02851012554715585\n",
      "train loss:0.0030038091038429105\n",
      "train loss:0.05382451409752896\n",
      "train loss:0.010599652951885658\n",
      "train loss:0.04851160773697056\n",
      "train loss:0.01361134639066745\n",
      "train loss:0.005463068753976951\n",
      "train loss:0.04838260950197906\n",
      "train loss:0.009707083817297802\n",
      "train loss:0.01647404841539155\n",
      "train loss:0.04014789307915869\n",
      "train loss:0.10021868387984112\n",
      "train loss:0.011867372922860659\n",
      "train loss:0.007520191252013729\n",
      "train loss:0.015823709394340295\n",
      "train loss:0.011989290355529304\n",
      "train loss:0.05953556991533908\n",
      "train loss:0.012079008158487366\n",
      "train loss:0.03153883382252785\n",
      "train loss:0.05460437733304425\n",
      "train loss:0.011483440557812974\n",
      "train loss:0.004797319414342059\n",
      "train loss:0.008639946526815306\n",
      "train loss:0.005633381825333894\n",
      "train loss:0.011285975401845637\n",
      "train loss:0.006108104489097788\n",
      "train loss:0.011269741905326253\n",
      "train loss:0.007803199527287383\n",
      "train loss:0.016170800097234247\n",
      "train loss:0.003782034244781857\n",
      "train loss:0.05803555370420649\n",
      "train loss:0.019851007587769743\n",
      "train loss:0.01657384378137738\n",
      "train loss:0.007256583563874607\n",
      "train loss:0.027552675885895085\n",
      "train loss:0.0064183651883971925\n",
      "train loss:0.027047174103055655\n",
      "train loss:0.010176764280290735\n",
      "train loss:0.02350621782945173\n",
      "train loss:0.008143960963867205\n",
      "train loss:0.0031896429587555297\n",
      "train loss:0.03505702638835783\n",
      "train loss:0.04115422254253676\n",
      "train loss:0.06024090206831668\n",
      "train loss:0.008482224298335717\n",
      "train loss:0.013213659143746477\n",
      "train loss:0.036934632319409196\n",
      "train loss:0.006246604382826052\n",
      "train loss:0.017792268890290352\n",
      "train loss:0.05408536682808119\n",
      "train loss:0.023552120277748147\n",
      "train loss:0.0036378564386906217\n",
      "train loss:0.0062007062477055655\n",
      "train loss:0.009811298062926327\n",
      "train loss:0.007584764393919598\n",
      "train loss:0.009293242126299329\n",
      "train loss:0.010860443287668704\n",
      "train loss:0.014025078516431023\n",
      "train loss:0.0104155593370602\n",
      "train loss:0.013504264386860388\n",
      "train loss:0.06453018715078236\n",
      "train loss:0.015759957651656036\n",
      "train loss:0.011637261831250346\n",
      "train loss:0.0055473029750322134\n",
      "train loss:0.002723328383848894\n",
      "train loss:0.00459676643374603\n",
      "train loss:0.027675555345090523\n",
      "train loss:0.019258233762708958\n",
      "train loss:0.05211448445366904\n",
      "train loss:0.008930980395093865\n",
      "train loss:0.0075086768761363646\n",
      "train loss:0.004160904589589276\n",
      "train loss:0.06967260780613914\n",
      "train loss:0.012754146784211712\n",
      "train loss:0.03099372327470008\n",
      "train loss:0.035422477805064884\n",
      "train loss:0.019002660054597074\n",
      "train loss:0.07459894646659182\n",
      "train loss:0.007195251840153568\n",
      "train loss:0.002210642458680799\n",
      "train loss:0.0076656803387910415\n",
      "train loss:0.011045844533883083\n",
      "train loss:0.029748103842473478\n",
      "train loss:0.015267690995573048\n",
      "train loss:0.011034907533362313\n",
      "train loss:0.025027293189538356\n",
      "train loss:0.056346836986068766\n",
      "train loss:0.004076172484750944\n",
      "train loss:0.009024707763863158\n",
      "train loss:0.014836300059012306\n",
      "=== epoch:6, train acc:0.986, test acc:0.98 ===\n",
      "train loss:0.02503777799589671\n",
      "train loss:0.01754426020816891\n",
      "train loss:0.042839510684914865\n",
      "train loss:0.042874022239651116\n",
      "train loss:0.015513148213049563\n",
      "train loss:0.08625288386006577\n",
      "train loss:0.020611644429227784\n",
      "train loss:0.024024205649822872\n",
      "train loss:0.011273963605470188\n",
      "train loss:0.041909590162125906\n",
      "train loss:0.005533028964675941\n",
      "train loss:0.044848321762595775\n",
      "train loss:0.006432720076920627\n",
      "train loss:0.03533111893719823\n",
      "train loss:0.052772439760285964\n",
      "train loss:0.007817769709875305\n",
      "train loss:0.024023905783054248\n",
      "train loss:0.028968724639808083\n",
      "train loss:0.01566562017743235\n",
      "train loss:0.008906901358663752\n",
      "train loss:0.030931114070784478\n",
      "train loss:0.008402064560695534\n",
      "train loss:0.004513859479119125\n",
      "train loss:0.007061527261500448\n",
      "train loss:0.07236433967278683\n",
      "train loss:0.13684863636133027\n",
      "train loss:0.1226252939906429\n",
      "train loss:0.06606391310117415\n",
      "train loss:0.007071147126849593\n",
      "train loss:0.004695235086194622\n",
      "train loss:0.07732172881254007\n",
      "train loss:0.010376299724103515\n",
      "train loss:0.026900981574672453\n",
      "train loss:0.03545774417706106\n",
      "train loss:0.015160358570943933\n",
      "train loss:0.03434201268464341\n",
      "train loss:0.015207028022017295\n",
      "train loss:0.023052868268944305\n",
      "train loss:0.016602869582861068\n",
      "train loss:0.017219505187624908\n",
      "train loss:0.014500377581433445\n",
      "train loss:0.02924601039683475\n",
      "train loss:0.04448514272244455\n",
      "train loss:0.006312457075244322\n",
      "train loss:0.016153971304021315\n",
      "train loss:0.012929622184419311\n",
      "train loss:0.07878187917456442\n",
      "train loss:0.015626298240692532\n",
      "train loss:0.0328735159683948\n",
      "train loss:0.009738052501798117\n",
      "train loss:0.015612581719353676\n",
      "train loss:0.03218173992454548\n",
      "train loss:0.022064486864866208\n",
      "train loss:0.09021348647602728\n",
      "train loss:0.017898226187139217\n",
      "train loss:0.01029753011820171\n",
      "train loss:0.018080634574423913\n",
      "train loss:0.0028940874503257125\n",
      "train loss:0.03910616793820395\n",
      "train loss:0.016610589914755187\n",
      "train loss:0.033591254046113746\n",
      "train loss:0.06788825426970839\n",
      "train loss:0.006410145876993318\n",
      "train loss:0.08717445896644162\n",
      "train loss:0.03127156201218036\n",
      "train loss:0.02878189352617254\n",
      "train loss:0.012135614653117301\n",
      "train loss:0.07825642988849238\n",
      "train loss:0.007432822265040511\n",
      "train loss:0.009824318195380637\n",
      "train loss:0.02923107364312599\n",
      "train loss:0.06114324870196759\n",
      "train loss:0.023959478792455746\n",
      "train loss:0.0524910768035976\n",
      "train loss:0.023313332976639237\n",
      "train loss:0.014461307020030784\n",
      "train loss:0.012167212480609106\n",
      "train loss:0.018360699943473578\n",
      "train loss:0.016661959845049458\n",
      "train loss:0.009570625983467047\n",
      "train loss:0.00893406622128724\n",
      "train loss:0.024376671143437095\n",
      "train loss:0.017989041024926388\n",
      "train loss:0.08432861324329745\n",
      "train loss:0.0677036036454457\n",
      "train loss:0.013259965874192495\n",
      "train loss:0.028835108398320618\n",
      "train loss:0.01657020728846038\n",
      "train loss:0.00986200623531484\n",
      "train loss:0.019157095385091562\n",
      "train loss:0.008576511423991571\n",
      "train loss:0.009557198923867267\n",
      "train loss:0.04483898887122418\n",
      "train loss:0.028093294622416755\n",
      "train loss:0.008981624504084865\n",
      "train loss:0.04965382191584622\n",
      "train loss:0.012647573820158546\n",
      "train loss:0.002624594757118198\n",
      "train loss:0.026687078714737463\n",
      "train loss:0.034515802733069714\n",
      "train loss:0.010845259484235932\n",
      "train loss:0.022195548558016087\n",
      "train loss:0.00504108673838266\n",
      "train loss:0.02212419568175957\n",
      "train loss:0.03391411728446789\n",
      "train loss:0.019139628450381696\n",
      "train loss:0.04251037049870773\n",
      "train loss:0.018670386598791392\n",
      "train loss:0.07317455676408313\n",
      "train loss:0.009745384716273658\n",
      "train loss:0.03645238834749819\n",
      "train loss:0.028654944478126002\n",
      "train loss:0.007349118721132765\n",
      "train loss:0.01953505727847842\n",
      "train loss:0.0032286784614100057\n",
      "train loss:0.004474170610783933\n",
      "train loss:0.023386421706647828\n",
      "train loss:0.012081899849343937\n",
      "train loss:0.02962826174434999\n",
      "train loss:0.02533044466167789\n",
      "train loss:0.025342961971564545\n",
      "train loss:0.007569569868475785\n",
      "train loss:0.06253184405025243\n",
      "train loss:0.04579290158182807\n",
      "train loss:0.011779518655698889\n",
      "train loss:0.013986820981629183\n",
      "train loss:0.11239740711671713\n",
      "train loss:0.01888983983580422\n",
      "train loss:0.01083845883485226\n",
      "train loss:0.027548069015703683\n",
      "train loss:0.07239703051244367\n",
      "train loss:0.08858253219233275\n",
      "train loss:0.03403775135301673\n",
      "train loss:0.03984324255996878\n",
      "train loss:0.036412858469996076\n",
      "train loss:0.005904236526872458\n",
      "train loss:0.035246243007549964\n",
      "train loss:0.009467149854751947\n",
      "train loss:0.00798190957688676\n",
      "train loss:0.06452906821737532\n",
      "train loss:0.03736465035595343\n",
      "train loss:0.1089419511481975\n",
      "train loss:0.00857661416944544\n",
      "train loss:0.033452580633937294\n",
      "train loss:0.012009337063365213\n",
      "train loss:0.017945062608520152\n",
      "train loss:0.04619203027615699\n",
      "train loss:0.032747746366452175\n",
      "train loss:0.013367438498016533\n",
      "train loss:0.023992110200609495\n",
      "train loss:0.041066928952404734\n",
      "train loss:0.06278062169579371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04072220830819094\n",
      "train loss:0.011432490551128391\n",
      "train loss:0.011105317632567072\n",
      "train loss:0.01235720851245369\n",
      "train loss:0.004336995458151554\n",
      "train loss:0.06191611002491695\n",
      "train loss:0.009209782510986222\n",
      "train loss:0.01652030854985973\n",
      "train loss:0.01164758619219852\n",
      "train loss:0.03387994141068948\n",
      "train loss:0.009765526007898139\n",
      "train loss:0.010431912337453815\n",
      "train loss:0.005263285006009954\n",
      "train loss:0.009462311006630931\n",
      "train loss:0.005608540064234296\n",
      "train loss:0.05532506513479467\n",
      "train loss:0.00799641103428426\n",
      "train loss:0.025876749332074164\n",
      "train loss:0.007719741874485614\n",
      "train loss:0.05133729322616164\n",
      "train loss:0.03372115442557299\n",
      "train loss:0.04615057362123534\n",
      "train loss:0.012665687042938998\n",
      "train loss:0.01716722273539435\n",
      "train loss:0.002280525288051525\n",
      "train loss:0.01824444702133887\n",
      "train loss:0.020576000207423825\n",
      "train loss:0.003366385656692805\n",
      "train loss:0.05393939571623278\n",
      "train loss:0.012192818755048733\n",
      "train loss:0.021193376801315267\n",
      "train loss:0.004735288569399471\n",
      "train loss:0.021345737965182604\n",
      "train loss:0.004919568477636651\n",
      "train loss:0.030479615143382613\n",
      "train loss:0.025387334127265994\n",
      "train loss:0.025975662381179574\n",
      "train loss:0.005507715448621134\n",
      "train loss:0.015014998107579112\n",
      "train loss:0.005450425856505899\n",
      "train loss:0.009663368928778313\n",
      "train loss:0.009317250528820898\n",
      "train loss:0.018420274707051588\n",
      "train loss:0.01132999618261582\n",
      "train loss:0.02142391273834518\n",
      "train loss:0.03498688916475803\n",
      "train loss:0.008764832503438708\n",
      "train loss:0.02302507130882734\n",
      "train loss:0.012880437883558265\n",
      "train loss:0.03189684371791036\n",
      "train loss:0.022816376522264342\n",
      "train loss:0.03475221566512545\n",
      "train loss:0.0025429859396110454\n",
      "train loss:0.005964788277999819\n",
      "train loss:0.0038481203804801383\n",
      "train loss:0.024660852310933654\n",
      "train loss:0.00975341421240573\n",
      "train loss:0.016161516162439434\n",
      "train loss:0.02182571917688733\n",
      "train loss:0.01361738976764731\n",
      "train loss:0.006367413527292499\n",
      "train loss:0.01254911925378906\n",
      "train loss:0.02063812889052271\n",
      "train loss:0.05066983340084439\n",
      "train loss:0.006747913556822868\n",
      "train loss:0.013583216443459127\n",
      "train loss:0.023708049265385115\n",
      "train loss:0.01269690040060354\n",
      "train loss:0.00863089092128807\n",
      "train loss:0.013807796379511475\n",
      "train loss:0.003918945372497897\n",
      "train loss:0.010432292797956327\n",
      "train loss:0.013508567672820803\n",
      "train loss:0.013529888874040288\n",
      "train loss:0.01795476579307336\n",
      "train loss:0.03706174898156035\n",
      "train loss:0.024686353820435412\n",
      "train loss:0.011542082584241798\n",
      "train loss:0.013944918427370712\n",
      "train loss:0.05331447142539654\n",
      "train loss:0.01033041184630207\n",
      "train loss:0.009073428527170413\n",
      "train loss:0.012155307147290108\n",
      "train loss:0.014850077815085839\n",
      "train loss:0.022698098172415717\n",
      "train loss:0.02079278876221504\n",
      "train loss:0.004398259251796179\n",
      "train loss:0.021707399715163132\n",
      "train loss:0.0089920545982981\n",
      "train loss:0.003921856721049694\n",
      "train loss:0.05840792457070955\n",
      "train loss:0.03541338223981171\n",
      "train loss:0.019146107077046778\n",
      "train loss:0.012013800963867637\n",
      "train loss:0.07148167514479768\n",
      "train loss:0.04569635209589254\n",
      "train loss:0.005697480758650333\n",
      "train loss:0.0954203495734921\n",
      "train loss:0.031893057740121425\n",
      "train loss:0.11190156418981496\n",
      "train loss:0.0021387747195061855\n",
      "train loss:0.0032550736144661492\n",
      "train loss:0.060243431622007675\n",
      "train loss:0.013388981778105071\n",
      "train loss:0.06789075811669366\n",
      "train loss:0.012300616900100399\n",
      "train loss:0.014286857348313533\n",
      "train loss:0.02979193410735841\n",
      "train loss:0.020600027049747213\n",
      "train loss:0.028253249718491615\n",
      "train loss:0.0446091685273268\n",
      "train loss:0.013544424583726945\n",
      "train loss:0.06435596343674481\n",
      "train loss:0.06027802031354754\n",
      "train loss:0.010677836246742902\n",
      "train loss:0.006802811124190147\n",
      "train loss:0.07274999902461506\n",
      "train loss:0.07224364787912162\n",
      "train loss:0.013367138134799736\n",
      "train loss:0.023180371907566832\n",
      "train loss:0.017725398204966204\n",
      "train loss:0.047225839227865024\n",
      "train loss:0.014929536554638854\n",
      "train loss:0.010955209317684867\n",
      "train loss:0.023384119233026253\n",
      "train loss:0.005309526456144001\n",
      "train loss:0.011500083861521659\n",
      "train loss:0.022373632169957247\n",
      "train loss:0.028657099082443807\n",
      "train loss:0.02224534745363325\n",
      "train loss:0.016232584599570957\n",
      "train loss:0.014865649474154214\n",
      "train loss:0.005751684953292966\n",
      "train loss:0.005945190285794444\n",
      "train loss:0.036719973132763005\n",
      "train loss:0.023400153133725645\n",
      "train loss:0.018348154859295626\n",
      "train loss:0.14776573716438587\n",
      "train loss:0.00875889535172509\n",
      "train loss:0.010952461769459708\n",
      "train loss:0.004192595505266438\n",
      "train loss:0.04271497331320732\n",
      "train loss:0.006836057600667503\n",
      "train loss:0.07754778633181109\n",
      "train loss:0.026268194170572117\n",
      "train loss:0.06508853196672254\n",
      "train loss:0.020691455875747774\n",
      "train loss:0.0034409734984754705\n",
      "train loss:0.011982496990996842\n",
      "train loss:0.05778799979177844\n",
      "train loss:0.028076821533943384\n",
      "train loss:0.004525012326624448\n",
      "train loss:0.03341102371842894\n",
      "train loss:0.12096496670091693\n",
      "train loss:0.006062031930677586\n",
      "train loss:0.011867228617395033\n",
      "train loss:0.015652717521711344\n",
      "train loss:0.0615247498707189\n",
      "train loss:0.01708923878884224\n",
      "train loss:0.10529112396440496\n",
      "train loss:0.005999980766614712\n",
      "train loss:0.01769961087479271\n",
      "train loss:0.061646731400561865\n",
      "train loss:0.026599314721023407\n",
      "train loss:0.0336615951478858\n",
      "train loss:0.013906810565908694\n",
      "train loss:0.05350248224053642\n",
      "train loss:0.06070584379202607\n",
      "train loss:0.024836496199580747\n",
      "train loss:0.02275846115540814\n",
      "train loss:0.03076361962153873\n",
      "train loss:0.01497989776657678\n",
      "train loss:0.012909576160743428\n",
      "train loss:0.013111125749985884\n",
      "train loss:0.03524838041756812\n",
      "train loss:0.019172439492544206\n",
      "train loss:0.04868378771302938\n",
      "train loss:0.018566229893754078\n",
      "train loss:0.004749892548932554\n",
      "train loss:0.007575134313128827\n",
      "train loss:0.0157044061876033\n",
      "train loss:0.015726883913801816\n",
      "train loss:0.04732577755467397\n",
      "train loss:0.03458879894042197\n",
      "train loss:0.019253985871307396\n",
      "train loss:0.029869459997599202\n",
      "train loss:0.01647526387200042\n",
      "train loss:0.02092011035897762\n",
      "train loss:0.012351078517104215\n",
      "train loss:0.042506075031970146\n",
      "train loss:0.031538225490615364\n",
      "train loss:0.046574523247211175\n",
      "train loss:0.029077227489322528\n",
      "train loss:0.013493005707163523\n",
      "train loss:0.05253413050875762\n",
      "train loss:0.039763494388918914\n",
      "train loss:0.01290653303776897\n",
      "train loss:0.04769527287649354\n",
      "train loss:0.052296226377848455\n",
      "train loss:0.02779833165629683\n",
      "train loss:0.02225362551196798\n",
      "train loss:0.016658643471058956\n",
      "train loss:0.05489032327330381\n",
      "train loss:0.01919460202751036\n",
      "train loss:0.053698228042801624\n",
      "train loss:0.02853567363638501\n",
      "train loss:0.012035105164300912\n",
      "train loss:0.021934718576377236\n",
      "train loss:0.02418138068577428\n",
      "train loss:0.01602659937845712\n",
      "train loss:0.09870595153414985\n",
      "train loss:0.05551282906923328\n",
      "train loss:0.01311410321194587\n",
      "train loss:0.008206832000227655\n",
      "train loss:0.010309571256139481\n",
      "train loss:0.031815987424493535\n",
      "train loss:0.017401768434615973\n",
      "train loss:0.020819272982782654\n",
      "train loss:0.010329928873373695\n",
      "train loss:0.012241405902499017\n",
      "train loss:0.01561001865802554\n",
      "train loss:0.00978436732434685\n",
      "train loss:0.00885385486369803\n",
      "train loss:0.025999657116668323\n",
      "train loss:0.03571749797002814\n",
      "train loss:0.01814025299946022\n",
      "train loss:0.05966517641773133\n",
      "train loss:0.025276803501277086\n",
      "train loss:0.02435182059299297\n",
      "train loss:0.0401441713074959\n",
      "train loss:0.032971757330639756\n",
      "train loss:0.009955632310147552\n",
      "train loss:0.06730340963571836\n",
      "train loss:0.004428184365509207\n",
      "train loss:0.02710577535722987\n",
      "train loss:0.03765962491653074\n",
      "train loss:0.011739432618248013\n",
      "train loss:0.015421181456706543\n",
      "train loss:0.004556702901108132\n",
      "train loss:0.015234838957485891\n",
      "train loss:0.030680358342629496\n",
      "train loss:0.09516636667336441\n",
      "train loss:0.007868365804494477\n",
      "train loss:0.07091966170688485\n",
      "train loss:0.039850965528967136\n",
      "train loss:0.002251182498270743\n",
      "train loss:0.045928782966994326\n",
      "train loss:0.029750461727854224\n",
      "train loss:0.01843486010129747\n",
      "train loss:0.017342615762184408\n",
      "train loss:0.01390643258805715\n",
      "train loss:0.0776533783151423\n",
      "train loss:0.011351040661489252\n",
      "train loss:0.007855896499823949\n",
      "train loss:0.04312182353309385\n",
      "train loss:0.003395611954993114\n",
      "train loss:0.00832756359641534\n",
      "train loss:0.0050248196657407315\n",
      "train loss:0.006349414476021233\n",
      "train loss:0.020081181126578404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.023057147562487685\n",
      "train loss:0.020951519453765107\n",
      "train loss:0.00897945298803742\n",
      "train loss:0.013350073404907195\n",
      "train loss:0.02400702814525645\n",
      "train loss:0.025098406844674067\n",
      "train loss:0.040432006693669614\n",
      "train loss:0.015874110965558005\n",
      "train loss:0.010445547274715767\n",
      "train loss:0.04567113231052185\n",
      "train loss:0.011295588298516996\n",
      "train loss:0.019139973365469794\n",
      "train loss:0.07091326633684719\n",
      "train loss:0.027975880511324522\n",
      "train loss:0.010525682459757215\n",
      "train loss:0.06623606262563674\n",
      "train loss:0.01517135623324501\n",
      "train loss:0.0123956629076705\n",
      "train loss:0.06921710110614442\n",
      "train loss:0.013235775048898784\n",
      "train loss:0.03946465102484307\n",
      "train loss:0.021966065471289924\n",
      "train loss:0.047735591105303114\n",
      "train loss:0.031561700710188184\n",
      "train loss:0.006331122463003935\n",
      "train loss:0.041033956002002145\n",
      "train loss:0.00835278318503148\n",
      "train loss:0.006202627846690646\n",
      "train loss:0.02257696294462092\n",
      "train loss:0.008183999415880723\n",
      "train loss:0.02505628062747017\n",
      "train loss:0.012678893273632887\n",
      "train loss:0.023076990743154682\n",
      "train loss:0.026033543288658714\n",
      "train loss:0.014532540712614091\n",
      "train loss:0.007650123450557514\n",
      "train loss:0.026186325029789025\n",
      "train loss:0.028863986891485643\n",
      "train loss:0.08123738539794635\n",
      "train loss:0.0822880790350445\n",
      "train loss:0.029010821810818935\n",
      "train loss:0.028311688906387057\n",
      "train loss:0.029844666661831103\n",
      "train loss:0.0081814956970257\n",
      "train loss:0.005800957155751914\n",
      "train loss:0.010991520049786218\n",
      "train loss:0.013437463516547779\n",
      "train loss:0.0009445762496612822\n",
      "train loss:0.03949867938626389\n",
      "train loss:0.061899968561227814\n",
      "train loss:0.02691810783010995\n",
      "train loss:0.0027850784716924497\n",
      "train loss:0.013795738633854953\n",
      "train loss:0.020965577633167358\n",
      "train loss:0.021903361740278342\n",
      "train loss:0.023973069743711887\n",
      "train loss:0.007693569056884751\n",
      "train loss:0.02655026576910269\n",
      "train loss:0.013193574315468031\n",
      "train loss:0.06108004754659329\n",
      "train loss:0.024942680864571246\n",
      "train loss:0.00759759338058499\n",
      "train loss:0.021923414095463275\n",
      "train loss:0.002562647789656867\n",
      "train loss:0.003235653475793691\n",
      "train loss:0.04041410197647233\n",
      "train loss:0.09751253135690838\n",
      "train loss:0.023134611799107654\n",
      "train loss:0.01866819098981769\n",
      "train loss:0.008883661375341382\n",
      "train loss:0.00399311573607414\n",
      "train loss:0.004406958995715908\n",
      "train loss:0.022685140109554483\n",
      "train loss:0.018442092123822907\n",
      "train loss:0.027063209366002688\n",
      "train loss:0.020658485147043888\n",
      "train loss:0.04203040938107473\n",
      "train loss:0.014068112146142613\n",
      "train loss:0.00847066890534152\n",
      "train loss:0.008130327803185494\n",
      "train loss:0.0072610215760547615\n",
      "train loss:0.01911243593020947\n",
      "train loss:0.18316137355473086\n",
      "train loss:0.057331651285051057\n",
      "train loss:0.006692064094639203\n",
      "train loss:0.0652398321102461\n",
      "train loss:0.014659591275457018\n",
      "train loss:0.011318877688636975\n",
      "train loss:0.0360040801006746\n",
      "train loss:0.05879740498446535\n",
      "train loss:0.020376322851288885\n",
      "train loss:0.010285282918631577\n",
      "train loss:0.027031160240932925\n",
      "train loss:0.047640137986010724\n",
      "train loss:0.006513175080056941\n",
      "train loss:0.04429892703110395\n",
      "train loss:0.01164752561255739\n",
      "train loss:0.012477713047546806\n",
      "train loss:0.005963799116863729\n",
      "train loss:0.005403352168204673\n",
      "train loss:0.02934067682493753\n",
      "train loss:0.019859362837930862\n",
      "train loss:0.010522329688062408\n",
      "train loss:0.008167660027198355\n",
      "train loss:0.009744132108639959\n",
      "train loss:0.01304931379998505\n",
      "train loss:0.00835802385185259\n",
      "train loss:0.014718567522241398\n",
      "train loss:0.018375672458317126\n",
      "train loss:0.004093048690645952\n",
      "train loss:0.019642075163273053\n",
      "train loss:0.013832172192365521\n",
      "train loss:0.010357680671423548\n",
      "train loss:0.009554458582994108\n",
      "train loss:0.034174250004668866\n",
      "train loss:0.028230636838141376\n",
      "train loss:0.004623500645811355\n",
      "train loss:0.011570194998246536\n",
      "train loss:0.006087390963457955\n",
      "train loss:0.002623988727601719\n",
      "train loss:0.003739670293017423\n",
      "train loss:0.002732932162834783\n",
      "train loss:0.016608692898604352\n",
      "train loss:0.02086042958630785\n",
      "train loss:0.006740521358308617\n",
      "train loss:0.054544245881247996\n",
      "train loss:0.019588362511533862\n",
      "train loss:0.06933587593604316\n",
      "train loss:0.004524611866725591\n",
      "train loss:0.03368349648874264\n",
      "train loss:0.025298099918057496\n",
      "train loss:0.006920627195633178\n",
      "train loss:0.003469043609361811\n",
      "train loss:0.013315338580149456\n",
      "train loss:0.023612566321728038\n",
      "train loss:0.007840221152014604\n",
      "train loss:0.007224784307085345\n",
      "train loss:0.01507103676741991\n",
      "train loss:0.03373528342982805\n",
      "train loss:0.025029295539850175\n",
      "train loss:0.049251795841192214\n",
      "train loss:0.01444733564029019\n",
      "train loss:0.02981525105842083\n",
      "train loss:0.04237604976898282\n",
      "train loss:0.010340125409741824\n",
      "train loss:0.021283885322368457\n",
      "train loss:0.051150316544561425\n",
      "train loss:0.03326630331931976\n",
      "train loss:0.06365416588966863\n",
      "train loss:0.004740474694477826\n",
      "train loss:0.036686805415500394\n",
      "train loss:0.005714486799941509\n",
      "train loss:0.0028098943891423697\n",
      "train loss:0.019867203527471823\n",
      "train loss:0.0108155315474401\n",
      "train loss:0.0022140751987635766\n",
      "train loss:0.02453278648625109\n",
      "train loss:0.01234108657150437\n",
      "train loss:0.011285426078934896\n",
      "train loss:0.0421309913781242\n",
      "train loss:0.039428009661951625\n",
      "train loss:0.028770672178550602\n",
      "train loss:0.006350272429337932\n",
      "train loss:0.012700587421664198\n",
      "train loss:0.0041982449943281305\n",
      "train loss:0.05099578760982811\n",
      "train loss:0.026513926338218172\n",
      "train loss:0.00821438686532483\n",
      "train loss:0.019209932061919226\n",
      "train loss:0.017702711784132116\n",
      "train loss:0.05459452858764573\n",
      "train loss:0.00942665481079754\n",
      "train loss:0.007803423739323733\n",
      "train loss:0.013548544274655858\n",
      "train loss:0.014768308473329779\n",
      "train loss:0.026143625243039956\n",
      "train loss:0.013462927313269701\n",
      "train loss:0.09332950094701425\n",
      "train loss:0.003680019782387563\n",
      "train loss:0.01911363791605595\n",
      "train loss:0.025360628739455056\n",
      "train loss:0.0099808809515174\n",
      "train loss:0.07447541697753873\n",
      "train loss:0.022078635657510164\n",
      "train loss:0.039828559114873346\n",
      "train loss:0.02938917926990335\n",
      "train loss:0.058017265717143066\n",
      "train loss:0.008722896454756563\n",
      "=== epoch:7, train acc:0.986, test acc:0.977 ===\n",
      "train loss:0.048985964373550225\n",
      "train loss:0.019808141394844558\n",
      "train loss:0.004116442996009609\n",
      "train loss:0.0383512209940896\n",
      "train loss:0.008391004858851839\n",
      "train loss:0.012832353009388661\n",
      "train loss:0.029349094376430518\n",
      "train loss:0.020712879819254897\n",
      "train loss:0.026220360201941975\n",
      "train loss:0.05256633890128324\n",
      "train loss:0.030840130897084754\n",
      "train loss:0.009980420053820998\n",
      "train loss:0.049708369580382286\n",
      "train loss:0.014352322773938941\n",
      "train loss:0.04982850425880683\n",
      "train loss:0.05419482134978378\n",
      "train loss:0.03319181433582066\n",
      "train loss:0.014458797196395255\n",
      "train loss:0.01701999909925591\n",
      "train loss:0.034554309716743774\n",
      "train loss:0.015215325370027564\n",
      "train loss:0.07877699086551945\n",
      "train loss:0.016458222479542154\n",
      "train loss:0.03388736631815726\n",
      "train loss:0.02543678381207366\n",
      "train loss:0.03137595843433613\n",
      "train loss:0.0017054350546142393\n",
      "train loss:0.012840022792816062\n",
      "train loss:0.02151357556257856\n",
      "train loss:0.12990718315044888\n",
      "train loss:0.005929067229291555\n",
      "train loss:0.04479249566332198\n",
      "train loss:0.018368082975882296\n",
      "train loss:0.03728218147083424\n",
      "train loss:0.04012245943580578\n",
      "train loss:0.010322193006195494\n",
      "train loss:0.025263534443604973\n",
      "train loss:0.013673984930762528\n",
      "train loss:0.0023342132588832255\n",
      "train loss:0.0049418274667961245\n",
      "train loss:0.015549178556808558\n",
      "train loss:0.0247912687212678\n",
      "train loss:0.018614319413748266\n",
      "train loss:0.026727840040396564\n",
      "train loss:0.012554417323178859\n",
      "train loss:0.005837800355748221\n",
      "train loss:0.016397692160001687\n",
      "train loss:0.019925483753469236\n",
      "train loss:0.06178481150670082\n",
      "train loss:0.005129016280358398\n",
      "train loss:0.009051430586844838\n",
      "train loss:0.011836736018769216\n",
      "train loss:0.02583774477157697\n",
      "train loss:0.02451931221186489\n",
      "train loss:0.009156540152876421\n",
      "train loss:0.0351034290741518\n",
      "train loss:0.008513236358683889\n",
      "train loss:0.021279583645613234\n",
      "train loss:0.00649943149406216\n",
      "train loss:0.014989920919297024\n",
      "train loss:0.05078849171131879\n",
      "train loss:0.011178145130483288\n",
      "train loss:0.013783965023709089\n",
      "train loss:0.005803064885684172\n",
      "train loss:0.005538730161900321\n",
      "train loss:0.005897886463809868\n",
      "train loss:0.0033824377239942073\n",
      "train loss:0.04665203324866028\n",
      "train loss:0.006503076771398536\n",
      "train loss:0.005978807362360546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.028820389734680547\n",
      "train loss:0.016183625129927888\n",
      "train loss:0.004699965417972699\n",
      "train loss:0.00757422236861007\n",
      "train loss:0.008444006839868907\n",
      "train loss:0.004184020716801328\n",
      "train loss:0.021210715151019053\n",
      "train loss:0.043865323259186226\n",
      "train loss:0.005636873845704045\n",
      "train loss:0.02103764896395587\n",
      "train loss:0.015667858040582645\n",
      "train loss:0.020117501202240443\n",
      "train loss:0.004867222036852622\n",
      "train loss:0.04028950550023927\n",
      "train loss:0.004599730900077136\n",
      "train loss:0.062358864827199566\n",
      "train loss:0.0038043603191888335\n",
      "train loss:0.007816886415741377\n",
      "train loss:0.005590869713234667\n",
      "train loss:0.022379408623419552\n",
      "train loss:0.013654587396933746\n",
      "train loss:0.0021916355148584067\n",
      "train loss:0.0060126471519619295\n",
      "train loss:0.008740185817338724\n",
      "train loss:0.00782140591811534\n",
      "train loss:0.0425297268920093\n",
      "train loss:0.009631708323849276\n",
      "train loss:0.0040251547889251955\n",
      "train loss:0.011249965054564158\n",
      "train loss:0.0014986282422344058\n",
      "train loss:0.002338476947606907\n",
      "train loss:0.003685970931764222\n",
      "train loss:0.04002055036519932\n",
      "train loss:0.023213250061464654\n",
      "train loss:0.019037756521092145\n",
      "train loss:0.007696096331566118\n",
      "train loss:0.004199525037620941\n",
      "train loss:0.018294593230881884\n",
      "train loss:0.007898668891699063\n",
      "train loss:0.009088189145618786\n",
      "train loss:0.01129499862447811\n",
      "train loss:0.0032406110970122463\n",
      "train loss:0.009341276445105216\n",
      "train loss:0.009586412302989117\n",
      "train loss:0.004057423682248696\n",
      "train loss:0.007802039553146396\n",
      "train loss:0.017883078592189395\n",
      "train loss:0.04135138556213877\n",
      "train loss:0.010770345033491549\n",
      "train loss:0.013511337041599243\n",
      "train loss:0.005846375873558244\n",
      "train loss:0.008792110447204992\n",
      "train loss:0.023436969551080152\n",
      "train loss:0.04439642794986928\n",
      "train loss:0.003650388253915079\n",
      "train loss:0.06649086081154643\n",
      "train loss:0.015523036179200258\n",
      "train loss:0.01979915727742257\n",
      "train loss:0.03307950896896781\n",
      "train loss:0.00883344985424699\n",
      "train loss:0.011811363977514797\n",
      "train loss:0.01300520702552186\n",
      "train loss:0.02060399185914343\n",
      "train loss:0.01996431222444441\n",
      "train loss:0.04592054431831759\n",
      "train loss:0.03668938179927358\n",
      "train loss:0.009950900565634455\n",
      "train loss:0.0056096999295815455\n",
      "train loss:0.011577428051786081\n",
      "train loss:0.010958587511526858\n",
      "train loss:0.011616870034634083\n",
      "train loss:0.01799018461570321\n",
      "train loss:0.00994967914726403\n",
      "train loss:0.037250649561553786\n",
      "train loss:0.007990257160600794\n",
      "train loss:0.019212232089981865\n",
      "train loss:0.013023778819258052\n",
      "train loss:0.014198034837232486\n",
      "train loss:0.009901157403154073\n",
      "train loss:0.05324282583639578\n",
      "train loss:0.008049683795788463\n",
      "train loss:0.024182138643906073\n",
      "train loss:0.014360523308653545\n",
      "train loss:0.012973196868806259\n",
      "train loss:0.004576495477534348\n",
      "train loss:0.0058663656950489924\n",
      "train loss:0.03180280371511923\n",
      "train loss:0.011470957913549108\n",
      "train loss:0.026250780664587584\n",
      "train loss:0.015582854794206314\n",
      "train loss:0.07647880909410155\n",
      "train loss:0.005231649003563999\n",
      "train loss:0.030953311492900884\n",
      "train loss:0.0040506632892509074\n",
      "train loss:0.013801182672583779\n",
      "train loss:0.03387762384365503\n",
      "train loss:0.05418669945088495\n",
      "train loss:0.00318456976070927\n",
      "train loss:0.011349097774461237\n",
      "train loss:0.0035168873604244167\n",
      "train loss:0.00988148279905029\n",
      "train loss:0.032529395960977675\n",
      "train loss:0.03566289926622641\n",
      "train loss:0.01550873986964842\n",
      "train loss:0.007970272173809854\n",
      "train loss:0.015910651607226246\n",
      "train loss:0.020026196933505016\n",
      "train loss:0.013970263357662112\n",
      "train loss:0.012268674841445839\n",
      "train loss:0.009153278384832835\n",
      "train loss:0.007015541789155667\n",
      "train loss:0.051667221716373765\n",
      "train loss:0.030719431031747114\n",
      "train loss:0.013312263742847934\n",
      "train loss:0.02615406498851739\n",
      "train loss:0.04048299368680563\n",
      "train loss:0.024795587005074556\n",
      "train loss:0.006990775573851702\n",
      "train loss:0.038087229995642256\n",
      "train loss:0.024091520483972947\n",
      "train loss:0.00982447577624049\n",
      "train loss:0.029516212088877617\n",
      "train loss:0.011792783631894666\n",
      "train loss:0.015971064786127587\n",
      "train loss:0.04270011175569083\n",
      "train loss:0.04317116045904018\n",
      "train loss:0.005016608860849047\n",
      "train loss:0.010052333490689425\n",
      "train loss:0.0025085511126970127\n",
      "train loss:0.049173907368556764\n",
      "train loss:0.07523447493462293\n",
      "train loss:0.04503346253250665\n",
      "train loss:0.010554406148395321\n",
      "train loss:0.006862784397544538\n",
      "train loss:0.005638448533179078\n",
      "train loss:0.042769371085608306\n",
      "train loss:0.01332424468101099\n",
      "train loss:0.05424050654217352\n",
      "train loss:0.02185305784483784\n",
      "train loss:0.018541799688007784\n",
      "train loss:0.024131625919998484\n",
      "train loss:0.028014840723833694\n",
      "train loss:0.04259836851617806\n",
      "train loss:0.006819101822471401\n",
      "train loss:0.014916142930098051\n",
      "train loss:0.07106492790307549\n",
      "train loss:0.006390644398995779\n",
      "train loss:0.006136321274785152\n",
      "train loss:0.011184332211768153\n",
      "train loss:0.008290112026013851\n",
      "train loss:0.051953144863782726\n",
      "train loss:0.006597973541490355\n",
      "train loss:0.06366696944027848\n",
      "train loss:0.013314870556821823\n",
      "train loss:0.05445557531284409\n",
      "train loss:0.05063695847532139\n",
      "train loss:0.11078048086733627\n",
      "train loss:0.05680778294828431\n",
      "train loss:0.07781387175943982\n",
      "train loss:0.006707149800255781\n",
      "train loss:0.006574786205896695\n",
      "train loss:0.013394873125952098\n",
      "train loss:0.014589050341415121\n",
      "train loss:0.01342860048854594\n",
      "train loss:0.025370708972972156\n",
      "train loss:0.033862098395749315\n",
      "train loss:0.019994368815866005\n",
      "train loss:0.00859544595446778\n",
      "train loss:0.030827624955431777\n",
      "train loss:0.009795609633983814\n",
      "train loss:0.01866085487314016\n",
      "train loss:0.00910215471922643\n",
      "train loss:0.011810458421765422\n",
      "train loss:0.007686367383775507\n",
      "train loss:0.05017365165445268\n",
      "train loss:0.015277001585263121\n",
      "train loss:0.002541873837919991\n",
      "train loss:0.016084249354508688\n",
      "train loss:0.02256527850171242\n",
      "train loss:0.012268719804631066\n",
      "train loss:0.01607004172193868\n",
      "train loss:0.017831575049747486\n",
      "train loss:0.026067808536883973\n",
      "train loss:0.004993156576607144\n",
      "train loss:0.014763918562910417\n",
      "train loss:0.020136810627452033\n",
      "train loss:0.009227731457055443\n",
      "train loss:0.013677130644263036\n",
      "train loss:0.00873220714824161\n",
      "train loss:0.0175080584977454\n",
      "train loss:0.01071419256539118\n",
      "train loss:0.014578569244119178\n",
      "train loss:0.023878069765031137\n",
      "train loss:0.025892697214206437\n",
      "train loss:0.010410084562808463\n",
      "train loss:0.014289034783616133\n",
      "train loss:0.00879175629354816\n",
      "train loss:0.010760067309452807\n",
      "train loss:0.0222141902028958\n",
      "train loss:0.006739678076808223\n",
      "train loss:0.009798758866249922\n",
      "train loss:0.029049735075246125\n",
      "train loss:0.06468978408937141\n",
      "train loss:0.008114365831394632\n",
      "train loss:0.026701711627960253\n",
      "train loss:0.020371100800055664\n",
      "train loss:0.014229133602241739\n",
      "train loss:0.02003612738040127\n",
      "train loss:0.004284161574833187\n",
      "train loss:0.02592180402978427\n",
      "train loss:0.012682733341435427\n",
      "train loss:0.04542481402209044\n",
      "train loss:0.023734799995199073\n",
      "train loss:0.010393134843250038\n",
      "train loss:0.017380325177219807\n",
      "train loss:0.004542241829825923\n",
      "train loss:0.02447595662270944\n",
      "train loss:0.07104458755817417\n",
      "train loss:0.003528531165198208\n",
      "train loss:0.004408086584205539\n",
      "train loss:0.006765469763859556\n",
      "train loss:0.009207676035470602\n",
      "train loss:0.00522237543051043\n",
      "train loss:0.024681114612834162\n",
      "train loss:0.012409504303728645\n",
      "train loss:0.00440086113918988\n",
      "train loss:0.00768138558315265\n",
      "train loss:0.008698406174268166\n",
      "train loss:0.02298494677041157\n",
      "train loss:0.001582353973573629\n",
      "train loss:0.024857407481468093\n",
      "train loss:0.0025520489302816047\n",
      "train loss:0.002842265927695381\n",
      "train loss:0.010417765841213858\n",
      "train loss:0.006366966702581093\n",
      "train loss:0.008755268458439214\n",
      "train loss:0.06303624989202056\n",
      "train loss:0.016251579413757163\n",
      "train loss:0.011406269141446547\n",
      "train loss:0.007544012687253559\n",
      "train loss:0.01594243661568019\n",
      "train loss:0.005265906723083567\n",
      "train loss:0.032603353343242686\n",
      "train loss:0.12617545316899703\n",
      "train loss:0.003295656276822984\n",
      "train loss:0.030648781484315525\n",
      "train loss:0.0049889040655787\n",
      "train loss:0.010420645726682434\n",
      "train loss:0.010871239729980154\n",
      "train loss:0.006403992780113793\n",
      "train loss:0.017264767703877592\n",
      "train loss:0.009602436023872795\n",
      "train loss:0.0061399590165388575\n",
      "train loss:0.015781099421430297\n",
      "train loss:0.00859076108474395\n",
      "train loss:0.013137029219689964\n",
      "train loss:0.02665590424697106\n",
      "train loss:0.020573998138328\n",
      "train loss:0.0029916077291860864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015808384432060122\n",
      "train loss:0.01998054798042943\n",
      "train loss:0.022105326174657183\n",
      "train loss:0.014074018783358766\n",
      "train loss:0.0037425709938831908\n",
      "train loss:0.0028509428149486506\n",
      "train loss:0.014785019459715824\n",
      "train loss:0.0019403151465302848\n",
      "train loss:0.003213975083564237\n",
      "train loss:0.005093226806958672\n",
      "train loss:0.022391921644776453\n",
      "train loss:0.005088734110747383\n",
      "train loss:0.004023897592399672\n",
      "train loss:0.008676297814305905\n",
      "train loss:0.01692339027151225\n",
      "train loss:0.013509985255333297\n",
      "train loss:0.033833072996343104\n",
      "train loss:0.008146609177292161\n",
      "train loss:0.011090961876511297\n",
      "train loss:0.013796220335838301\n",
      "train loss:0.023391303315816264\n",
      "train loss:0.008492151859833099\n",
      "train loss:0.011275778287201787\n",
      "train loss:0.005911253203276487\n",
      "train loss:0.029603924374469365\n",
      "train loss:0.010300801481029768\n",
      "train loss:0.031187281546218235\n",
      "train loss:0.004665414010487381\n",
      "train loss:0.00614998497372507\n",
      "train loss:0.007805475280428515\n",
      "train loss:0.02207794203381349\n",
      "train loss:0.0192686951074565\n",
      "train loss:0.026186906861434087\n",
      "train loss:0.008998987843212984\n",
      "train loss:0.015887265709305685\n",
      "train loss:0.005124751460251045\n",
      "train loss:0.006421626559397653\n",
      "train loss:0.008485071926785777\n",
      "train loss:0.017553203905225755\n",
      "train loss:0.009744662267724113\n",
      "train loss:0.02049645728633819\n",
      "train loss:0.01835926296018949\n",
      "train loss:0.002207676435814995\n",
      "train loss:0.026043692954703605\n",
      "train loss:0.006415409277062055\n",
      "train loss:0.001788616163632851\n",
      "train loss:0.0028012051442898793\n",
      "train loss:0.021034361779386265\n",
      "train loss:0.0029952226821737277\n",
      "train loss:0.008154636926867628\n",
      "train loss:0.009169348420272385\n",
      "train loss:0.004650103095024444\n",
      "train loss:0.0014517101004571308\n",
      "train loss:0.019137185062260517\n",
      "train loss:0.01134612655599393\n",
      "train loss:0.008727881736348147\n",
      "train loss:0.012999595880077763\n",
      "train loss:0.0036669706315803534\n",
      "train loss:0.006396756006315748\n",
      "train loss:0.004340982093952044\n",
      "train loss:0.016929577105226933\n",
      "train loss:0.027868856378696086\n",
      "train loss:0.023416990582598288\n",
      "train loss:0.017090771142284335\n",
      "train loss:0.0031806140871908735\n",
      "train loss:0.012786420599988586\n",
      "train loss:0.014821698828963344\n",
      "train loss:0.008617901663675966\n",
      "train loss:0.03378939248879484\n",
      "train loss:0.022532893492542633\n",
      "train loss:0.01416929793129497\n",
      "train loss:0.016587988589094084\n",
      "train loss:0.03246849725378751\n",
      "train loss:0.050115641906288665\n",
      "train loss:0.004842941023251543\n",
      "train loss:0.0009300853599709233\n",
      "train loss:0.004559085883434702\n",
      "train loss:0.029990184984173992\n",
      "train loss:0.006507418539440027\n",
      "train loss:0.009513848465400125\n",
      "train loss:0.008018345647640585\n",
      "train loss:0.040322600553098734\n",
      "train loss:0.02239721390375728\n",
      "train loss:0.006916681530045221\n",
      "train loss:0.008291453584126168\n",
      "train loss:0.037868224263911926\n",
      "train loss:0.008530115601611231\n",
      "train loss:0.0071559578704287405\n",
      "train loss:0.052752828780450844\n",
      "train loss:0.022709388373539863\n",
      "train loss:0.028677158043900766\n",
      "train loss:0.01278356151229284\n",
      "train loss:0.007135066906798922\n",
      "train loss:0.009526587109912419\n",
      "train loss:0.02924701141451673\n",
      "train loss:0.010174743097502626\n",
      "train loss:0.013579444766824012\n",
      "train loss:0.028669633090997605\n",
      "train loss:0.007419961043590435\n",
      "train loss:0.03209001521361415\n",
      "train loss:0.046648738680254105\n",
      "train loss:0.005555566110207239\n",
      "train loss:0.003401400840546357\n",
      "train loss:0.010580837542697128\n",
      "train loss:0.022889112199666207\n",
      "train loss:0.010223297029948454\n",
      "train loss:0.005824990342738951\n",
      "train loss:0.019884177428663278\n",
      "train loss:0.05301328209792376\n",
      "train loss:0.012173466514886454\n",
      "train loss:0.0035761680436905948\n",
      "train loss:0.019657213178220608\n",
      "train loss:0.009920830347933276\n",
      "train loss:0.011398653065969615\n",
      "train loss:0.007450019436181785\n",
      "train loss:0.005524057299619849\n",
      "train loss:0.028154232617363394\n",
      "train loss:0.008230186249385292\n",
      "train loss:0.02264193496815007\n",
      "train loss:0.004233708504594203\n",
      "train loss:0.002424871525614525\n",
      "train loss:0.011758239766511374\n",
      "train loss:0.005271308640432646\n",
      "train loss:0.007496011212586102\n",
      "train loss:0.005285023256336666\n",
      "train loss:0.014033215589478074\n",
      "train loss:0.026826665448792288\n",
      "train loss:0.001337494367454094\n",
      "train loss:0.01004919211823053\n",
      "train loss:0.0039055965363771813\n",
      "train loss:0.009560616722718488\n",
      "train loss:0.0147335233686591\n",
      "train loss:0.03143847006435898\n",
      "train loss:0.00485269737244067\n",
      "train loss:0.004147409204367567\n",
      "train loss:0.011643428433901242\n",
      "train loss:0.006651302835018818\n",
      "train loss:0.030483120660789207\n",
      "train loss:0.00395058187642849\n",
      "train loss:0.0027489104631063157\n",
      "train loss:0.02819099848709463\n",
      "train loss:0.006150462333281786\n",
      "train loss:0.0018245222753170561\n",
      "train loss:0.06171501900642672\n",
      "train loss:0.007901727532521977\n",
      "train loss:0.013570210141420805\n",
      "train loss:0.013961870181834035\n",
      "train loss:0.01275373520560371\n",
      "train loss:0.003963045624826947\n",
      "train loss:0.006229836702531462\n",
      "train loss:0.003974745479907279\n",
      "train loss:0.02210281036216905\n",
      "train loss:0.027642904861168615\n",
      "train loss:0.014618777990026744\n",
      "train loss:0.02044902046274928\n",
      "train loss:0.0072474904528112664\n",
      "train loss:0.013317248564489412\n",
      "train loss:0.009227980615453197\n",
      "train loss:0.008289288720258609\n",
      "train loss:0.004832540425043108\n",
      "train loss:0.011060589818007994\n",
      "train loss:0.002938622405732904\n",
      "train loss:0.004334722418943504\n",
      "train loss:0.04348758364707115\n",
      "train loss:0.0055520360161605935\n",
      "train loss:0.007974059191320534\n",
      "train loss:0.0014803926900655753\n",
      "train loss:0.0016878209526210066\n",
      "train loss:0.01908779684314537\n",
      "train loss:0.010905406403402223\n",
      "train loss:0.003838671006088425\n",
      "train loss:0.011158623963277431\n",
      "train loss:0.005894461704121211\n",
      "train loss:0.07975286031554463\n",
      "train loss:0.01651595080121291\n",
      "train loss:0.00863941483037537\n",
      "train loss:0.011562246075898158\n",
      "train loss:0.009867304285225904\n",
      "train loss:0.004478929531057068\n",
      "train loss:0.049383708501814866\n",
      "train loss:0.011018325665841934\n",
      "train loss:0.02061016124742555\n",
      "train loss:0.01463795039805326\n",
      "train loss:0.0025173469977459095\n",
      "train loss:0.020350897982361015\n",
      "train loss:0.0036755280920844373\n",
      "train loss:0.003181684231523228\n",
      "train loss:0.00801453278905502\n",
      "train loss:0.015508126295673313\n",
      "train loss:0.007688543254470595\n",
      "train loss:0.004914430390218904\n",
      "train loss:0.0022364493087969352\n",
      "train loss:0.009032099831502563\n",
      "train loss:0.0017152490713657315\n",
      "train loss:0.02706083498291551\n",
      "train loss:0.00528558085562257\n",
      "train loss:0.009255614876325811\n",
      "train loss:0.03163069263475676\n",
      "train loss:0.015302042248736675\n",
      "train loss:0.009946956549879302\n",
      "train loss:0.06146747568130618\n",
      "train loss:0.18345118013758507\n",
      "train loss:0.0226290592497566\n",
      "train loss:0.005922947270555678\n",
      "train loss:0.005164954743218981\n",
      "train loss:0.0123561658336667\n",
      "train loss:0.004224173792160075\n",
      "train loss:0.03955924299422116\n",
      "train loss:0.00645028596355357\n",
      "train loss:0.012650079776594016\n",
      "train loss:0.022433270933467264\n",
      "train loss:0.03647544685277157\n",
      "train loss:0.006079845915065045\n",
      "train loss:0.010378063838216947\n",
      "train loss:0.012309034006475594\n",
      "train loss:0.054186818877404654\n",
      "train loss:0.0048112686022818195\n",
      "train loss:0.010930441228541763\n",
      "train loss:0.006530328774792051\n",
      "train loss:0.021066112954660068\n",
      "train loss:0.029825253211570018\n",
      "train loss:0.009860107656086978\n",
      "train loss:0.0031475661087589217\n",
      "train loss:0.03413506267801589\n",
      "train loss:0.01036980015979535\n",
      "train loss:0.006291761849798901\n",
      "train loss:0.004538428665088685\n",
      "train loss:0.02943808551560322\n",
      "train loss:0.0023692857271919447\n",
      "train loss:0.011896235116730857\n",
      "train loss:0.008392364356053355\n",
      "train loss:0.006800789257668005\n",
      "train loss:0.00331211705228874\n",
      "train loss:0.002656840301665478\n",
      "train loss:0.007158130569722777\n",
      "train loss:0.0052270918528084355\n",
      "train loss:0.004865860896506455\n",
      "train loss:0.004983551490350947\n",
      "train loss:0.01591103584237424\n",
      "train loss:0.006930867274046162\n",
      "train loss:0.00798705116602425\n",
      "train loss:0.00882791097444086\n",
      "train loss:0.002082284868277594\n",
      "train loss:0.0038154861906770036\n",
      "train loss:0.04471978218050208\n",
      "train loss:0.025427278909968515\n",
      "train loss:0.007938571482034716\n",
      "train loss:0.010200304231171351\n",
      "train loss:0.0071517844477197\n",
      "train loss:0.002526072053185092\n",
      "train loss:0.01740632238203978\n",
      "train loss:0.025870556085812776\n",
      "train loss:0.031039862571767374\n",
      "train loss:0.007768809768380037\n",
      "train loss:0.009292352908718517\n",
      "train loss:0.010437434865147954\n",
      "train loss:0.00537872948989905\n",
      "train loss:0.003624832427538567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001445128957699138\n",
      "train loss:0.019836289830319022\n",
      "train loss:0.008508764197643088\n",
      "train loss:0.014071819956654172\n",
      "train loss:0.0027306027389663273\n",
      "train loss:0.02228255677177401\n",
      "train loss:0.004266185106773845\n",
      "train loss:0.0037683618413899118\n",
      "train loss:0.015876747325161436\n",
      "train loss:0.006002006539026361\n",
      "train loss:0.010464262798395916\n",
      "train loss:0.00838438762957193\n",
      "train loss:0.007357071323605377\n",
      "=== epoch:8, train acc:0.992, test acc:0.981 ===\n",
      "train loss:0.0013145853435412448\n",
      "train loss:0.03503787164653563\n",
      "train loss:0.053171508211306555\n",
      "train loss:0.010580569922342528\n",
      "train loss:0.1437900883332695\n",
      "train loss:0.004919920017410578\n",
      "train loss:0.013683157962615253\n",
      "train loss:0.004729671264492457\n",
      "train loss:0.008764746529180953\n",
      "train loss:0.0015069512214417396\n",
      "train loss:0.00665005114167038\n",
      "train loss:0.03691310156922281\n",
      "train loss:0.03452513870855783\n",
      "train loss:0.06778359214070073\n",
      "train loss:0.004684960478244788\n",
      "train loss:0.029450581122015946\n",
      "train loss:0.003172075684195424\n",
      "train loss:0.01648587699802878\n",
      "train loss:0.015618568973429886\n",
      "train loss:0.013655638256599312\n",
      "train loss:0.007044430861176195\n",
      "train loss:0.0013102299928794937\n",
      "train loss:0.027641554935959715\n",
      "train loss:0.004091613945808528\n",
      "train loss:0.02400285631870605\n",
      "train loss:0.03678273577706371\n",
      "train loss:0.010349597122412\n",
      "train loss:0.008382612530399527\n",
      "train loss:0.008796287819373494\n",
      "train loss:0.006380602767317678\n",
      "train loss:0.005998787493139085\n",
      "train loss:0.008104498303472214\n",
      "train loss:0.01844624938691427\n",
      "train loss:0.007225769030456511\n",
      "train loss:0.008778515403899428\n",
      "train loss:0.020332869879429293\n",
      "train loss:0.019383075995260145\n",
      "train loss:0.006790895810730255\n",
      "train loss:0.002774937180956916\n",
      "train loss:0.006553326558200209\n",
      "train loss:0.013075462473189534\n",
      "train loss:0.02365394344528236\n",
      "train loss:0.020558084736623863\n",
      "train loss:0.0015843700411984608\n",
      "train loss:0.012681052848296579\n",
      "train loss:0.005547697435039714\n",
      "train loss:0.018756527376683013\n",
      "train loss:0.01661081663960077\n",
      "train loss:0.01167500056022542\n",
      "train loss:0.00609892906193996\n",
      "train loss:0.008949647636875814\n",
      "train loss:0.005466484670422549\n",
      "train loss:0.040925546507403175\n",
      "train loss:0.02207843324256743\n",
      "train loss:0.0035569493085347444\n",
      "train loss:0.03675705555090386\n",
      "train loss:0.014739747404392958\n",
      "train loss:0.005495736428981438\n",
      "train loss:0.01111647988243677\n",
      "train loss:0.013989527963763935\n",
      "train loss:0.00907258315047935\n",
      "train loss:0.015694715683884884\n",
      "train loss:0.017689946617028683\n",
      "train loss:0.017670670941704512\n",
      "train loss:0.014414932686736475\n",
      "train loss:0.004510247602495736\n",
      "train loss:0.01568600733771256\n",
      "train loss:0.010179917478181139\n",
      "train loss:0.004675213282669521\n",
      "train loss:0.03534398186755427\n",
      "train loss:0.0410358200658168\n",
      "train loss:0.010926488202152593\n",
      "train loss:0.04200671743055087\n",
      "train loss:0.009868638965095019\n",
      "train loss:0.012152349365156467\n",
      "train loss:0.039139994238766816\n",
      "train loss:0.010937645547640339\n",
      "train loss:0.07179609290512355\n",
      "train loss:0.016643528779098513\n",
      "train loss:0.028364677499615097\n",
      "train loss:0.019413941013948225\n",
      "train loss:0.00498816640602552\n",
      "train loss:0.018008712959551188\n",
      "train loss:0.008172008408867438\n",
      "train loss:0.016499506499899418\n",
      "train loss:0.010444878464799327\n",
      "train loss:0.021305757258968577\n",
      "train loss:0.01968364628897839\n",
      "train loss:0.017924955160629585\n",
      "train loss:0.0023143795431029394\n",
      "train loss:0.014173849053402708\n",
      "train loss:0.007384992158823291\n",
      "train loss:0.012924938717092792\n",
      "train loss:0.009582021657002752\n",
      "train loss:0.009768928489791608\n",
      "train loss:0.008225961675665201\n",
      "train loss:0.005852752710200313\n",
      "train loss:0.00383338481748776\n",
      "train loss:0.035769800471995385\n",
      "train loss:0.004429651690506538\n",
      "train loss:0.022896600193967557\n",
      "train loss:0.010534805458946264\n",
      "train loss:0.018684774997122785\n",
      "train loss:0.008214240886688762\n",
      "train loss:0.007220169756816557\n",
      "train loss:0.014550959772478653\n",
      "train loss:0.0014114641003812197\n",
      "train loss:0.002489054471232457\n",
      "train loss:0.006957914415364153\n",
      "train loss:0.036106905510571725\n",
      "train loss:0.024361202519988447\n",
      "train loss:0.007959629915801208\n",
      "train loss:0.0050836315707602974\n",
      "train loss:0.030317846263144523\n",
      "train loss:0.0033776738061089607\n",
      "train loss:0.009791547288652945\n",
      "train loss:0.015007222317311124\n",
      "train loss:0.006108799693240886\n",
      "train loss:0.0006287539240504715\n",
      "train loss:0.012849410511356008\n",
      "train loss:0.004318688230686955\n",
      "train loss:0.020199992513202016\n",
      "train loss:0.0037792048159487044\n",
      "train loss:0.05344075985351275\n",
      "train loss:0.01121825885348552\n",
      "train loss:0.006933670809623156\n",
      "train loss:0.04344852986558201\n",
      "train loss:0.001427649375114696\n",
      "train loss:0.05183174358666719\n",
      "train loss:0.007567241381370017\n",
      "train loss:0.04467692803470749\n",
      "train loss:0.0017044755822907302\n",
      "train loss:0.00801116223121813\n",
      "train loss:0.006039237068629877\n",
      "train loss:0.015140982774769478\n",
      "train loss:0.04081594536549114\n",
      "train loss:0.004002975359644093\n",
      "train loss:0.019167593325529083\n",
      "train loss:0.0024898523064347676\n",
      "train loss:0.0030056732730330635\n",
      "train loss:0.017354697030545662\n",
      "train loss:0.035540346887449344\n",
      "train loss:0.013296919219012725\n",
      "train loss:0.004430890740105546\n",
      "train loss:0.0022691864866486635\n",
      "train loss:0.08430964860961616\n",
      "train loss:0.010822849416042855\n",
      "train loss:0.01761688261339926\n",
      "train loss:0.009418736002403852\n",
      "train loss:0.004315380534394278\n",
      "train loss:0.014620772354520528\n",
      "train loss:0.01569813138468084\n",
      "train loss:0.056157232505646144\n",
      "train loss:0.004346531614919127\n",
      "train loss:0.004225058907110379\n",
      "train loss:0.0020331380098580656\n",
      "train loss:0.008125159605113659\n",
      "train loss:0.008530833755364857\n",
      "train loss:0.0117644257515639\n",
      "train loss:0.050701125917796734\n",
      "train loss:0.010870866724481282\n",
      "train loss:0.012907690331125966\n",
      "train loss:0.02082098638320204\n",
      "train loss:0.01510710717586806\n",
      "train loss:0.0020686212411738557\n",
      "train loss:0.00552135840493859\n",
      "train loss:0.005076481868377053\n",
      "train loss:0.0068899432018722905\n",
      "train loss:0.0025129713865351087\n",
      "train loss:0.02104932427048075\n",
      "train loss:0.020158195970410752\n",
      "train loss:0.04175353688922605\n",
      "train loss:0.005116262130533387\n",
      "train loss:0.007230529709296876\n",
      "train loss:0.007335688577437703\n",
      "train loss:0.04166900253169071\n",
      "train loss:0.002791939943017723\n",
      "train loss:0.003295960667225154\n",
      "train loss:0.022954482769365212\n",
      "train loss:0.008682391396991987\n",
      "train loss:0.03334641722631876\n",
      "train loss:0.012048908873684275\n",
      "train loss:0.028041353444938535\n",
      "train loss:0.04393948318098867\n",
      "train loss:0.005312391732160835\n",
      "train loss:0.02180268793063013\n",
      "train loss:0.010562944233146849\n",
      "train loss:0.05981212607305842\n",
      "train loss:0.0028563111646579616\n",
      "train loss:0.005974744301180969\n",
      "train loss:0.014444408039832012\n",
      "train loss:0.010801943853024645\n",
      "train loss:0.010202914867384451\n",
      "train loss:0.0018285224649366688\n",
      "train loss:0.013242985364983785\n",
      "train loss:0.005736928709047302\n",
      "train loss:0.015361635572394205\n",
      "train loss:0.01086014634387784\n",
      "train loss:0.012667098063871507\n",
      "train loss:0.02940766669941275\n",
      "train loss:0.017337968199822376\n",
      "train loss:0.08567889379894571\n",
      "train loss:0.018555536407506304\n",
      "train loss:0.008050620318400804\n",
      "train loss:0.036942256816038875\n",
      "train loss:0.011120553297882429\n",
      "train loss:0.017385304112604763\n",
      "train loss:0.0036312387587770626\n",
      "train loss:0.005159278740180162\n",
      "train loss:0.013013173388582268\n",
      "train loss:0.010288480909347579\n",
      "train loss:0.007062074661189981\n",
      "train loss:0.008344146737841493\n",
      "train loss:0.03561984886952261\n",
      "train loss:0.017719048557278773\n",
      "train loss:0.019437244733002124\n",
      "train loss:0.048648563138052686\n",
      "train loss:0.0146530398176351\n",
      "train loss:0.004931295672143146\n",
      "train loss:0.026578181711075587\n",
      "train loss:0.004666727365671298\n",
      "train loss:0.012643698747936263\n",
      "train loss:0.010352615991113472\n",
      "train loss:0.010770357792006597\n",
      "train loss:0.009317218187681555\n",
      "train loss:0.010585040254393075\n",
      "train loss:0.004434882290710377\n",
      "train loss:0.004835936541684527\n",
      "train loss:0.0037851501465179255\n",
      "train loss:0.00720388345646281\n",
      "train loss:0.03605147851618038\n",
      "train loss:0.01327141650894427\n",
      "train loss:0.000776934288619261\n",
      "train loss:0.03912796798062161\n",
      "train loss:0.012492803026583675\n",
      "train loss:0.010382670309085145\n",
      "train loss:0.0056039199225051935\n",
      "train loss:0.0051931019782991625\n",
      "train loss:0.010154939587958163\n",
      "train loss:0.002494806253463699\n",
      "train loss:0.002720740612092446\n",
      "train loss:0.009905164136526335\n",
      "train loss:0.00210061864649575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004868017500022773\n",
      "train loss:0.08851792099115878\n",
      "train loss:0.019886421323696418\n",
      "train loss:0.003610758874637396\n",
      "train loss:0.0027756347277347088\n",
      "train loss:0.0021544426723688085\n",
      "train loss:0.009020644060555706\n",
      "train loss:0.008602790869575726\n",
      "train loss:0.004813243242643239\n",
      "train loss:0.0016821728033986566\n",
      "train loss:0.014562437197969005\n",
      "train loss:0.015068086375753029\n",
      "train loss:0.006023646899595093\n",
      "train loss:0.009999503051250875\n",
      "train loss:0.027949169018800086\n",
      "train loss:0.001985779910661283\n",
      "train loss:0.05235222717304557\n",
      "train loss:0.008219228663674083\n",
      "train loss:0.0044393622599017725\n",
      "train loss:0.02387177793071923\n",
      "train loss:0.018631924234634077\n",
      "train loss:0.03213347398140209\n",
      "train loss:0.009087429425426669\n",
      "train loss:0.0017574274229456136\n",
      "train loss:0.009825539876858318\n",
      "train loss:0.021962616783477298\n",
      "train loss:0.006271121225634102\n",
      "train loss:0.012327534910732714\n",
      "train loss:0.009309766570889047\n",
      "train loss:0.006020575456154702\n",
      "train loss:0.02594135818371482\n",
      "train loss:0.0079969454055211\n",
      "train loss:0.001274674295977806\n",
      "train loss:0.004109448510563\n",
      "train loss:0.004621491789048986\n",
      "train loss:0.0171431583704596\n",
      "train loss:0.005406361106705577\n",
      "train loss:0.004462421894260702\n",
      "train loss:0.013213231897575988\n",
      "train loss:0.011933676099009445\n",
      "train loss:0.010615490499562223\n",
      "train loss:0.006077661950984562\n",
      "train loss:0.0038054701527733027\n",
      "train loss:0.011344615131497341\n",
      "train loss:0.008813881420590053\n",
      "train loss:0.008540202924521675\n",
      "train loss:0.010133958669232963\n",
      "train loss:0.039791829620919456\n",
      "train loss:0.006684100921322659\n",
      "train loss:0.012046382337276649\n",
      "train loss:0.0023959302814111484\n",
      "train loss:0.03028795090914677\n",
      "train loss:0.015528253367885119\n",
      "train loss:0.024877689387136706\n",
      "train loss:0.02580006008674509\n",
      "train loss:0.006120439398869849\n",
      "train loss:0.024069466496011785\n",
      "train loss:0.0005494546457193425\n",
      "train loss:0.010409649063171843\n",
      "train loss:0.006597669955302789\n",
      "train loss:0.0010389115248600424\n",
      "train loss:0.006920012542426279\n",
      "train loss:0.0038412518118421833\n",
      "train loss:0.0024938388067199477\n",
      "train loss:0.019539607299743123\n",
      "train loss:0.009707564107982247\n",
      "train loss:0.004794007974946513\n",
      "train loss:0.0006804622556522784\n",
      "train loss:0.04050200098798459\n",
      "train loss:0.000737834786784265\n",
      "train loss:0.006187535795886062\n",
      "train loss:0.014253894895606262\n",
      "train loss:0.036562385842764236\n",
      "train loss:0.003420090845268731\n",
      "train loss:0.0037004744239095494\n",
      "train loss:0.05203062270930516\n",
      "train loss:0.0083195401649929\n",
      "train loss:0.003260597695156911\n",
      "train loss:0.03473718665008176\n",
      "train loss:0.0060949562234579625\n",
      "train loss:0.011117482800973308\n",
      "train loss:0.05615453545682524\n",
      "train loss:0.008172127805632158\n",
      "train loss:0.019091341527190563\n",
      "train loss:0.0034360381574318906\n",
      "train loss:0.07930462249562419\n",
      "train loss:0.002950358083934538\n",
      "train loss:0.005146912571289056\n",
      "train loss:0.017262520216271435\n",
      "train loss:0.017566885427989846\n",
      "train loss:0.004791689481499549\n",
      "train loss:0.02075353390024158\n",
      "train loss:0.004723452435050876\n",
      "train loss:0.004042671143790182\n",
      "train loss:0.007029989790508974\n",
      "train loss:0.009085845814552667\n",
      "train loss:0.008014024543126443\n",
      "train loss:0.010179092858557654\n",
      "train loss:0.0048401421105211\n",
      "train loss:0.0038424888537087944\n",
      "train loss:0.008877590173499124\n",
      "train loss:0.005314860699306145\n",
      "train loss:0.09092819233681851\n",
      "train loss:0.007181182035703822\n",
      "train loss:0.0067359792319268965\n",
      "train loss:0.002237895969449279\n",
      "train loss:0.010038754685577618\n",
      "train loss:0.007593505476735144\n",
      "train loss:0.006718454694608823\n",
      "train loss:0.007604929270747785\n",
      "train loss:0.008673114266282603\n",
      "train loss:0.01931777707966133\n",
      "train loss:0.01754454198101846\n",
      "train loss:0.002235032485150889\n",
      "train loss:0.006067406446735639\n",
      "train loss:0.007743807280747873\n",
      "train loss:0.01075198227508949\n",
      "train loss:0.006810396128578041\n",
      "train loss:0.004782772118550374\n",
      "train loss:0.008774389480437577\n",
      "train loss:0.006889618022831465\n",
      "train loss:0.0034945242583557658\n",
      "train loss:0.01997905858287554\n",
      "train loss:0.008299803496541781\n",
      "train loss:0.0032960444015902365\n",
      "train loss:0.01327807096672885\n",
      "train loss:0.003119619777640276\n",
      "train loss:0.019216568827676937\n",
      "train loss:0.00981986674263054\n",
      "train loss:0.028310756472577615\n",
      "train loss:0.014837938322645038\n",
      "train loss:0.026247042098146274\n",
      "train loss:0.002183858212034363\n",
      "train loss:0.016804282870257883\n",
      "train loss:0.009012278075419843\n",
      "train loss:0.0028805825426781993\n",
      "train loss:0.010182128857989041\n",
      "train loss:0.021316425372752645\n",
      "train loss:0.011199055709586996\n",
      "train loss:0.008004272638862324\n",
      "train loss:0.021468505787174772\n",
      "train loss:0.013606718128797895\n",
      "train loss:0.12117896880502775\n",
      "train loss:0.0025725169122970378\n",
      "train loss:0.01753267072081217\n",
      "train loss:0.02486429544950403\n",
      "train loss:0.006172025587990183\n",
      "train loss:0.01695616446933695\n",
      "train loss:0.008550951392608546\n",
      "train loss:0.010578225198845794\n",
      "train loss:0.01188664766523345\n",
      "train loss:0.0032153195636826044\n",
      "train loss:0.0245281655754195\n",
      "train loss:0.009745189541700266\n",
      "train loss:0.004056229892686926\n",
      "train loss:0.003080480322262406\n",
      "train loss:0.018886905250252675\n",
      "train loss:0.00376852200466041\n",
      "train loss:0.019628550781405053\n",
      "train loss:0.0024456483854980253\n",
      "train loss:0.002143385984155321\n",
      "train loss:0.021071479239946102\n",
      "train loss:0.01613856226294849\n",
      "train loss:0.02091212085802349\n",
      "train loss:0.008826846501000974\n",
      "train loss:0.003352896536957914\n",
      "train loss:0.006509971101179188\n",
      "train loss:0.0030616797021902693\n",
      "train loss:0.008835512402367672\n",
      "train loss:0.014683628157774848\n",
      "train loss:0.009865403374548852\n",
      "train loss:0.036017881158458186\n",
      "train loss:0.01555222745773732\n",
      "train loss:0.002316402963194651\n",
      "train loss:0.006369962925875638\n",
      "train loss:0.004398485465806724\n",
      "train loss:0.005301122718362956\n",
      "train loss:0.004127388347064324\n",
      "train loss:0.007942122908420534\n",
      "train loss:0.0013174183759266064\n",
      "train loss:0.07503436240572543\n",
      "train loss:0.052064706527884044\n",
      "train loss:0.013746671022094011\n",
      "train loss:0.004992235230687145\n",
      "train loss:0.01592941098691675\n",
      "train loss:0.024929152065379205\n",
      "train loss:0.013837114924945083\n",
      "train loss:0.00476585616246679\n",
      "train loss:0.006750885215916812\n",
      "train loss:0.005988882522956568\n",
      "train loss:0.008209898947191487\n",
      "train loss:0.01952810972025723\n",
      "train loss:0.007633468544989434\n",
      "train loss:0.07546236027895203\n",
      "train loss:0.017013898727724953\n",
      "train loss:0.0036464334518305757\n",
      "train loss:0.003772055020299854\n",
      "train loss:0.012251370017335932\n",
      "train loss:0.016812796898313054\n",
      "train loss:0.0520911616226159\n",
      "train loss:0.009746948023741733\n",
      "train loss:0.0101802660208311\n",
      "train loss:0.02223335912108558\n",
      "train loss:0.009154430548622161\n",
      "train loss:0.007258941769645501\n",
      "train loss:0.056291916682249254\n",
      "train loss:0.006246276079367056\n",
      "train loss:0.006592974715696748\n",
      "train loss:0.012393476191944001\n",
      "train loss:0.0024172098813577563\n",
      "train loss:0.005700859093126334\n",
      "train loss:0.0049542594772277035\n",
      "train loss:0.015715225898662026\n",
      "train loss:0.008604810323213318\n",
      "train loss:0.011411787927057208\n",
      "train loss:0.0047500184975920404\n",
      "train loss:0.03578464430773393\n",
      "train loss:0.005408949175929609\n",
      "train loss:0.02196428145320202\n",
      "train loss:0.026333511597804886\n",
      "train loss:0.005034483096744516\n",
      "train loss:0.007002176242287408\n",
      "train loss:0.053760634716529504\n",
      "train loss:0.002886336036299347\n",
      "train loss:0.09938259480425747\n",
      "train loss:0.006472404115770739\n",
      "train loss:0.02218229063378116\n",
      "train loss:0.02093951943974123\n",
      "train loss:0.010153708902328423\n",
      "train loss:0.008627222154860469\n",
      "train loss:0.0055653071248749\n",
      "train loss:0.007017902032401498\n",
      "train loss:0.0035306074072567386\n",
      "train loss:0.0023937456956869317\n",
      "train loss:0.049439210654171756\n",
      "train loss:0.0062473390679683724\n",
      "train loss:0.002287595646104269\n",
      "train loss:0.03693379228907045\n",
      "train loss:0.033039326002303804\n",
      "train loss:0.0072765754367908175\n",
      "train loss:0.0057052098626077866\n",
      "train loss:0.002074906601236062\n",
      "train loss:0.0169357944598698\n",
      "train loss:0.003786958281231212\n",
      "train loss:0.008303743591477538\n",
      "train loss:0.014393417567088293\n",
      "train loss:0.004505173020102985\n",
      "train loss:0.012313832251648383\n",
      "train loss:0.0365423091429951\n",
      "train loss:0.07062130532153192\n",
      "train loss:0.006401126622426313\n",
      "train loss:0.014322403597371233\n",
      "train loss:0.023179319627527454\n",
      "train loss:0.005269887786109115\n",
      "train loss:0.013730044524212606\n",
      "train loss:0.051982999484610805\n",
      "train loss:0.0398139981672516\n",
      "train loss:0.016441823055868242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0070526781067686535\n",
      "train loss:0.0070599221453483026\n",
      "train loss:0.004301999004280046\n",
      "train loss:0.007396737719459502\n",
      "train loss:0.01702315589069336\n",
      "train loss:0.008733817969354806\n",
      "train loss:0.0025845947254421885\n",
      "train loss:0.02425142839560858\n",
      "train loss:0.004478169233805472\n",
      "train loss:0.023046013522190774\n",
      "train loss:0.009905167986960098\n",
      "train loss:0.005040680838883438\n",
      "train loss:0.010420158799409074\n",
      "train loss:0.0067984753482836155\n",
      "train loss:0.0010592288815398185\n",
      "train loss:0.024403632290798564\n",
      "train loss:0.0165987899734903\n",
      "train loss:0.0050420334912579835\n",
      "train loss:0.0007585443608096508\n",
      "train loss:0.0015981354038134548\n",
      "train loss:0.005237631277562605\n",
      "train loss:0.004909060293109524\n",
      "train loss:0.014260033831833092\n",
      "train loss:0.007839752021859216\n",
      "train loss:0.010971037711342991\n",
      "train loss:0.009681703550142362\n",
      "train loss:0.01585892081533503\n",
      "train loss:0.023572169485666497\n",
      "train loss:0.03201426709910442\n",
      "train loss:0.011482758443311189\n",
      "train loss:0.024893383840638154\n",
      "train loss:0.008467901329376836\n",
      "train loss:0.012655342684924697\n",
      "train loss:0.03442552379474802\n",
      "train loss:0.012152105148504193\n",
      "train loss:0.022670023667056435\n",
      "train loss:0.0025066613147212893\n",
      "train loss:0.005502690297642188\n",
      "train loss:0.004520526182885548\n",
      "train loss:0.016285427045260103\n",
      "train loss:0.00593760433170557\n",
      "train loss:0.038662475889580106\n",
      "train loss:0.012996798013120812\n",
      "train loss:0.005930350669346111\n",
      "train loss:0.01115168375893474\n",
      "train loss:0.005101287935650643\n",
      "train loss:0.09920439936692221\n",
      "train loss:0.0019848191191789836\n",
      "train loss:0.005363753993005833\n",
      "train loss:0.004205555306567865\n",
      "train loss:0.0034094640595778132\n",
      "train loss:0.016099506365202652\n",
      "train loss:0.010125090181797525\n",
      "train loss:0.009838500693502101\n",
      "train loss:0.005696336303711603\n",
      "train loss:0.0012303811023659105\n",
      "train loss:0.006794464806409836\n",
      "train loss:0.04832454125272024\n",
      "train loss:0.005144403680164184\n",
      "train loss:0.012455336152771524\n",
      "train loss:0.044825861871061294\n",
      "train loss:0.018810026237057357\n",
      "train loss:0.023082101775350736\n",
      "train loss:0.006481525927367999\n",
      "train loss:0.02240637915108937\n",
      "train loss:0.0071243520568652265\n",
      "train loss:0.01311013714202473\n",
      "train loss:0.0027580277906088025\n",
      "train loss:0.020849070454291633\n",
      "train loss:0.008189715620647273\n",
      "train loss:0.04517680446704154\n",
      "train loss:0.004336482455852123\n",
      "train loss:0.018176013721054568\n",
      "train loss:0.019151761782621228\n",
      "train loss:0.010005673132853783\n",
      "train loss:0.07471082816002544\n",
      "train loss:0.006743952404356487\n",
      "train loss:0.014806768203317808\n",
      "train loss:0.004421901390728792\n",
      "train loss:0.008992506894600062\n",
      "train loss:0.022084540964697728\n",
      "train loss:0.010218648466409503\n",
      "train loss:0.0009507422650013747\n",
      "train loss:0.006337742768399741\n",
      "train loss:0.006110172200716085\n",
      "train loss:0.005959621757866136\n",
      "train loss:0.0016310577635919247\n",
      "train loss:0.003244815920809886\n",
      "train loss:0.011876205027041217\n",
      "train loss:0.0024794014293509727\n",
      "train loss:0.007261482657034687\n",
      "train loss:0.009505669653623214\n",
      "train loss:0.00821019679651818\n",
      "train loss:0.00506059968270005\n",
      "train loss:0.0018553433842306694\n",
      "train loss:0.0150238934143945\n",
      "train loss:0.012336179728035544\n",
      "train loss:0.023366939971468964\n",
      "train loss:0.0021604587091415836\n",
      "=== epoch:9, train acc:0.995, test acc:0.986 ===\n",
      "train loss:0.007825957728409199\n",
      "train loss:0.01169729991982911\n",
      "train loss:0.0026695197095288636\n",
      "train loss:0.006147596013242965\n",
      "train loss:0.0009526117774831965\n",
      "train loss:0.005959046651481169\n",
      "train loss:0.009827190395361694\n",
      "train loss:0.01911468886008939\n",
      "train loss:0.004349271829176304\n",
      "train loss:0.007961585445244586\n",
      "train loss:0.004417185447278526\n",
      "train loss:0.0028051973782046756\n",
      "train loss:0.004548494467281187\n",
      "train loss:0.01687941193644787\n",
      "train loss:0.010270868199449588\n",
      "train loss:0.005481029036743391\n",
      "train loss:0.010864405661593819\n",
      "train loss:0.01251588794108162\n",
      "train loss:0.006354277185787165\n",
      "train loss:0.003761941880663211\n",
      "train loss:0.004744833550209932\n",
      "train loss:0.0372441403784748\n",
      "train loss:0.013092377237761844\n",
      "train loss:0.00139872671377865\n",
      "train loss:0.020243264266572934\n",
      "train loss:0.001316334133443154\n",
      "train loss:0.005807890752436138\n",
      "train loss:0.004852742205954464\n",
      "train loss:0.010337344852549698\n",
      "train loss:0.009652203971193034\n",
      "train loss:0.004885438746238774\n",
      "train loss:0.0025123686756615654\n",
      "train loss:0.01260623862056631\n",
      "train loss:0.004716466931430217\n",
      "train loss:0.0021336147390969506\n",
      "train loss:0.002126946963055931\n",
      "train loss:0.0014521106373279816\n",
      "train loss:0.006441062850627717\n",
      "train loss:0.03383766608319425\n",
      "train loss:0.0047610992448721655\n",
      "train loss:0.0035065954320071613\n",
      "train loss:0.01306435676131406\n",
      "train loss:0.009382879062916585\n",
      "train loss:0.0005775042616487303\n",
      "train loss:0.012282038910776543\n",
      "train loss:0.0007618150384293856\n",
      "train loss:0.003968088569928508\n",
      "train loss:0.0014307441056999614\n",
      "train loss:0.032446946645273235\n",
      "train loss:0.0041671207018171945\n",
      "train loss:0.01162374807374847\n",
      "train loss:0.0009697865949377542\n",
      "train loss:0.0031056455722807096\n",
      "train loss:0.006549999213915953\n",
      "train loss:0.003976448904740908\n",
      "train loss:0.0061439358302979455\n",
      "train loss:0.00298023362061217\n",
      "train loss:0.01471711491371158\n",
      "train loss:0.009252846146564722\n",
      "train loss:0.014706903884052696\n",
      "train loss:0.0038727175339839538\n",
      "train loss:0.01087266096039677\n",
      "train loss:0.022095505577069293\n",
      "train loss:0.05802014753991634\n",
      "train loss:0.006421841691094234\n",
      "train loss:0.013984879437221053\n",
      "train loss:0.0111771928300908\n",
      "train loss:0.008043434799862928\n",
      "train loss:0.0006598870084619576\n",
      "train loss:0.013186885034703461\n",
      "train loss:0.018351758497077236\n",
      "train loss:0.005372931774874026\n",
      "train loss:0.0017223005931079566\n",
      "train loss:0.0017363343339659354\n",
      "train loss:0.003842463604838111\n",
      "train loss:0.005168056646340248\n",
      "train loss:0.008354958255125612\n",
      "train loss:0.00653073268144453\n",
      "train loss:0.0032435147007008973\n",
      "train loss:0.019231813355723656\n",
      "train loss:0.043170395480487275\n",
      "train loss:0.002590484876016541\n",
      "train loss:0.07700860199488396\n",
      "train loss:0.004626111823301512\n",
      "train loss:0.006063736405938621\n",
      "train loss:0.010096877754337936\n",
      "train loss:0.015614449469765333\n",
      "train loss:0.014224121384126107\n",
      "train loss:0.027785925460116614\n",
      "train loss:0.009320303512631073\n",
      "train loss:0.0044695926650077395\n",
      "train loss:0.008227867103959525\n",
      "train loss:0.007516173610306214\n",
      "train loss:0.050813456079410194\n",
      "train loss:0.016422755769516614\n",
      "train loss:0.0025803973198405337\n",
      "train loss:0.04466836664515703\n",
      "train loss:0.002930115858137368\n",
      "train loss:0.010007277129319307\n",
      "train loss:0.0034830488842031086\n",
      "train loss:0.0020174010141911173\n",
      "train loss:0.027741258242084246\n",
      "train loss:0.012582936278930366\n",
      "train loss:0.011004364165298269\n",
      "train loss:0.015820897648783642\n",
      "train loss:0.014785329475294736\n",
      "train loss:0.007425131948080477\n",
      "train loss:0.002916366676210046\n",
      "train loss:0.005501141794551468\n",
      "train loss:0.012009337350099354\n",
      "train loss:0.005612809554539264\n",
      "train loss:0.0029420364629901908\n",
      "train loss:0.011088071073548866\n",
      "train loss:0.003283153475440426\n",
      "train loss:0.0046577493347225345\n",
      "train loss:0.0038358522986529004\n",
      "train loss:0.0053826725267530455\n",
      "train loss:0.005588379510901484\n",
      "train loss:0.0022826031872742207\n",
      "train loss:0.005382643476179406\n",
      "train loss:0.019465381020456255\n",
      "train loss:0.007922250888687357\n",
      "train loss:0.007797117640506537\n",
      "train loss:0.00376049127853739\n",
      "train loss:0.007767172630186573\n",
      "train loss:0.0021927950340923552\n",
      "train loss:0.011892496686307808\n",
      "train loss:0.007110480120156681\n",
      "train loss:0.007716455589646779\n",
      "train loss:0.00674403773491462\n",
      "train loss:0.0015648762593358484\n",
      "train loss:0.004341826832504236\n",
      "train loss:0.017103574414199192\n",
      "train loss:0.010520191963485186\n",
      "train loss:0.011905514605169183\n",
      "train loss:0.006529485257263878\n",
      "train loss:0.008818506720841751\n",
      "train loss:0.0036222574483251602\n",
      "train loss:0.003942991944163787\n",
      "train loss:0.015295692174772417\n",
      "train loss:0.016284233547600613\n",
      "train loss:0.007527461725688693\n",
      "train loss:0.00097310525442022\n",
      "train loss:0.007252438538112002\n",
      "train loss:0.039158827963799096\n",
      "train loss:0.006531285140362255\n",
      "train loss:0.0025965771297574896\n",
      "train loss:0.004728639773920671\n",
      "train loss:0.012035618864497586\n",
      "train loss:0.014331602250566145\n",
      "train loss:0.006087780015077823\n",
      "train loss:0.0030715559009122802\n",
      "train loss:0.025077186349386504\n",
      "train loss:0.01645743615706632\n",
      "train loss:0.001849920475315387\n",
      "train loss:0.008747917415553837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005935144438777844\n",
      "train loss:0.020722413653862782\n",
      "train loss:0.005199008547290024\n",
      "train loss:0.001100884103956931\n",
      "train loss:0.0017023544087839968\n",
      "train loss:0.0036777229772668417\n",
      "train loss:0.004597827408820122\n",
      "train loss:0.0034506708069882127\n",
      "train loss:0.030219098954577923\n",
      "train loss:0.0418549312595758\n",
      "train loss:0.0009118950337951611\n",
      "train loss:0.009586373400535161\n",
      "train loss:0.01470646429630274\n",
      "train loss:0.006983366654707231\n",
      "train loss:0.0006415777398492005\n",
      "train loss:0.005940952432294203\n",
      "train loss:0.0024978339908175596\n",
      "train loss:0.024667223841992027\n",
      "train loss:0.007660434191671152\n",
      "train loss:0.002672324704008343\n",
      "train loss:0.08366021119535709\n",
      "train loss:0.00281924386279772\n",
      "train loss:0.031231608869209296\n",
      "train loss:0.008235352998977933\n",
      "train loss:0.0021516379247993765\n",
      "train loss:0.0028871868888135947\n",
      "train loss:0.0015587838587055602\n",
      "train loss:0.0014971496851663448\n",
      "train loss:0.03823962481804092\n",
      "train loss:0.012851703951942583\n",
      "train loss:0.019375221550691192\n",
      "train loss:0.011208373027865341\n",
      "train loss:0.03619084852917077\n",
      "train loss:0.0028155977837586183\n",
      "train loss:0.005160351251795708\n",
      "train loss:0.008428033464444816\n",
      "train loss:0.012334391559958604\n",
      "train loss:0.003018585428015766\n",
      "train loss:0.001407567309685877\n",
      "train loss:0.02066621035768441\n",
      "train loss:0.04635437145064818\n",
      "train loss:0.0011590191039459446\n",
      "train loss:0.005612447837333457\n",
      "train loss:0.0191672700769136\n",
      "train loss:0.005690009102252508\n",
      "train loss:0.010695469196560422\n",
      "train loss:0.02505966157411776\n",
      "train loss:0.002404325766594699\n",
      "train loss:0.003803869463885695\n",
      "train loss:0.01189196681251334\n",
      "train loss:0.06560830445397155\n",
      "train loss:0.012882457000896847\n",
      "train loss:0.00479023031050951\n",
      "train loss:0.004566644056138331\n",
      "train loss:0.005967447962815494\n",
      "train loss:0.02464933041957426\n",
      "train loss:0.015456057967082335\n",
      "train loss:0.002771579414020453\n",
      "train loss:0.0012846353898796781\n",
      "train loss:0.16373595137263414\n",
      "train loss:0.009652658231562992\n",
      "train loss:0.048362002270684365\n",
      "train loss:0.004436605913095698\n",
      "train loss:0.007527591474302253\n",
      "train loss:0.00223994132607031\n",
      "train loss:0.007182638870668266\n",
      "train loss:0.00882355818463204\n",
      "train loss:0.01128106976043402\n",
      "train loss:0.011503005026061172\n",
      "train loss:0.009273459633781664\n",
      "train loss:0.02350636687275423\n",
      "train loss:0.01241924210497879\n",
      "train loss:0.0034463487997466163\n",
      "train loss:0.009343037854111332\n",
      "train loss:0.0366522138324796\n",
      "train loss:0.022046753168856733\n",
      "train loss:0.0013545550568878834\n",
      "train loss:0.00781768466945065\n",
      "train loss:0.017789516186665445\n",
      "train loss:0.0016058311432816626\n",
      "train loss:0.04207484486609576\n",
      "train loss:0.018851499269314623\n",
      "train loss:0.0016882384596599803\n",
      "train loss:0.0034724991454521564\n",
      "train loss:0.01299400272135275\n",
      "train loss:0.0036174728938810794\n",
      "train loss:0.0017978385194277794\n",
      "train loss:0.002367882436808308\n",
      "train loss:0.009519863715768868\n",
      "train loss:0.0613055457356417\n",
      "train loss:0.014489458876662078\n",
      "train loss:0.006100426091947196\n",
      "train loss:0.010602982142814339\n",
      "train loss:0.001908850408203772\n",
      "train loss:0.01765236363718057\n",
      "train loss:0.011633716038735937\n",
      "train loss:0.0016165358981515235\n",
      "train loss:0.01247299944289426\n",
      "train loss:0.008654879811155624\n",
      "train loss:0.004681799497707433\n",
      "train loss:0.01837487581019001\n",
      "train loss:0.012718163066595203\n",
      "train loss:0.010237665829753034\n",
      "train loss:0.010066762565593846\n",
      "train loss:0.009451428763756507\n",
      "train loss:0.011286154367718735\n",
      "train loss:0.018992678426829872\n",
      "train loss:0.08159929297462265\n",
      "train loss:0.006316751045607475\n",
      "train loss:0.002521022566014429\n",
      "train loss:0.008676250443514397\n",
      "train loss:0.013549420373693648\n",
      "train loss:0.003997605487837185\n",
      "train loss:0.009928007381604605\n",
      "train loss:0.010771900293835866\n",
      "train loss:0.034066211867968044\n",
      "train loss:0.010647602494967219\n",
      "train loss:0.004635788747393539\n",
      "train loss:0.0015761817815969107\n",
      "train loss:0.00311004632278211\n",
      "train loss:0.0024742858448165393\n",
      "train loss:0.0008910346538470311\n",
      "train loss:0.017529079489736487\n",
      "train loss:0.005473665270397559\n",
      "train loss:0.004326130007922202\n",
      "train loss:0.015644335719197235\n",
      "train loss:0.005336671153467065\n",
      "train loss:0.003992585543582019\n",
      "train loss:0.0033722906550851762\n",
      "train loss:0.007333643889893296\n",
      "train loss:0.007741806172698694\n",
      "train loss:0.005876512538266221\n",
      "train loss:0.005864493083978116\n",
      "train loss:0.0027509784910694757\n",
      "train loss:0.04014853362028672\n",
      "train loss:0.027871985284876374\n",
      "train loss:0.006773947734640757\n",
      "train loss:0.008811971544947839\n",
      "train loss:0.008556490475196738\n",
      "train loss:0.004922936548249569\n",
      "train loss:0.033779561743488895\n",
      "train loss:0.007320884200530207\n",
      "train loss:0.007226878253497049\n",
      "train loss:0.006703426236739213\n",
      "train loss:0.005831144859471255\n",
      "train loss:0.0036944898717389714\n",
      "train loss:0.035662261138933254\n",
      "train loss:0.0275968433404917\n",
      "train loss:0.02930386354224536\n",
      "train loss:0.006903022685370869\n",
      "train loss:0.006404926241036439\n",
      "train loss:0.012556368689040349\n",
      "train loss:0.002445361632581962\n",
      "train loss:0.012816776314913578\n",
      "train loss:0.016560021512322484\n",
      "train loss:0.0035656880827296066\n",
      "train loss:0.005601331772676419\n",
      "train loss:0.0059264225251644785\n",
      "train loss:0.017574319010829644\n",
      "train loss:0.014969383973489837\n",
      "train loss:0.01172260353198443\n",
      "train loss:0.006835431371679316\n",
      "train loss:0.003190914742221962\n",
      "train loss:0.004358596359246829\n",
      "train loss:0.004303383227197242\n",
      "train loss:0.0023344954522627713\n",
      "train loss:0.004583248549532742\n",
      "train loss:0.029012419789512016\n",
      "train loss:0.009666199579268274\n",
      "train loss:0.004297548431837858\n",
      "train loss:0.0030951430497321653\n",
      "train loss:0.0028527943341026905\n",
      "train loss:0.013045015559008617\n",
      "train loss:0.011261325079401294\n",
      "train loss:0.0022682697454000644\n",
      "train loss:0.001593112699081031\n",
      "train loss:0.005758636297043124\n",
      "train loss:0.0018336200757221536\n",
      "train loss:0.022724053853238946\n",
      "train loss:0.0071326786136230854\n",
      "train loss:0.003784947451090719\n",
      "train loss:0.003202548938909115\n",
      "train loss:0.03369124865411797\n",
      "train loss:0.00989473844433598\n",
      "train loss:0.003167122105106944\n",
      "train loss:0.004599278209964098\n",
      "train loss:0.002240792870011625\n",
      "train loss:0.008668373084272358\n",
      "train loss:0.015548549729512756\n",
      "train loss:0.006666321050594574\n",
      "train loss:0.00295115521301022\n",
      "train loss:0.001252734334886286\n",
      "train loss:0.009466067517781037\n",
      "train loss:0.010243169652635185\n",
      "train loss:0.018976443489897167\n",
      "train loss:0.02018019097274501\n",
      "train loss:0.008439563758420273\n",
      "train loss:0.003003639776856282\n",
      "train loss:0.006665683182515056\n",
      "train loss:0.01611424744953745\n",
      "train loss:0.0017200703956668007\n",
      "train loss:0.005129648447051205\n",
      "train loss:0.005473068439525464\n",
      "train loss:0.0025079339300329794\n",
      "train loss:0.0023472612606601443\n",
      "train loss:0.007880851869505082\n",
      "train loss:0.0011741070723347486\n",
      "train loss:0.014470147272407063\n",
      "train loss:0.0147826201508782\n",
      "train loss:0.013842624796814291\n",
      "train loss:0.007122700177005317\n",
      "train loss:0.002256878917085971\n",
      "train loss:0.01196536315796497\n",
      "train loss:0.005197066245456254\n",
      "train loss:0.0055632941046878815\n",
      "train loss:0.01002258864272979\n",
      "train loss:0.00506516442926806\n",
      "train loss:0.00580988939109262\n",
      "train loss:0.0313385039568782\n",
      "train loss:0.0027500004423456565\n",
      "train loss:0.004224555857792201\n",
      "train loss:0.016506093235481325\n",
      "train loss:0.012641667414695634\n",
      "train loss:0.011397911907272337\n",
      "train loss:0.0021047702348347213\n",
      "train loss:0.010593957818114945\n",
      "train loss:0.010945888959150161\n",
      "train loss:0.0031920808559592253\n",
      "train loss:0.0010826299963582794\n",
      "train loss:0.019362840569799995\n",
      "train loss:0.02403554641918854\n",
      "train loss:0.05454448039094921\n",
      "train loss:0.0041246053924701535\n",
      "train loss:0.0077804090072862075\n",
      "train loss:0.0014912154568825346\n",
      "train loss:0.03058116953834293\n",
      "train loss:0.005522565170865314\n",
      "train loss:0.002026655627567667\n",
      "train loss:0.010823205745789242\n",
      "train loss:0.02169726483562643\n",
      "train loss:0.014575462475397715\n",
      "train loss:0.0034070305659982727\n",
      "train loss:0.006061229658259983\n",
      "train loss:0.008637227013842473\n",
      "train loss:0.0007774186481853658\n",
      "train loss:0.006182569091366884\n",
      "train loss:0.054052331592298664\n",
      "train loss:0.0014750538542978257\n",
      "train loss:0.026456914498643923\n",
      "train loss:0.0027304996104888617\n",
      "train loss:0.005146260058105624\n",
      "train loss:0.022755353484957833\n",
      "train loss:0.0026266974308676626\n",
      "train loss:0.008086083212903826\n",
      "train loss:0.005299557287585929\n",
      "train loss:0.0013057729867723786\n",
      "train loss:0.010598221241753518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05654496045121661\n",
      "train loss:0.009036419245781205\n",
      "train loss:0.005641182070377868\n",
      "train loss:0.00048448236856792065\n",
      "train loss:0.002025415036772245\n",
      "train loss:0.013402044002301407\n",
      "train loss:0.00794628819018473\n",
      "train loss:0.0076793452782081524\n",
      "train loss:0.03542979636534396\n",
      "train loss:0.0009940216002481577\n",
      "train loss:0.007237643665998848\n",
      "train loss:0.0017647754133138093\n",
      "train loss:0.003553440924506566\n",
      "train loss:0.04863436055597597\n",
      "train loss:0.014384987911962457\n",
      "train loss:0.006817704728178148\n",
      "train loss:0.020814053430228387\n",
      "train loss:0.01174170717840788\n",
      "train loss:0.011862431071699346\n",
      "train loss:0.00295536813939713\n",
      "train loss:0.008418285462292676\n",
      "train loss:0.0012648406887890372\n",
      "train loss:0.002244328351547956\n",
      "train loss:0.016016828931883394\n",
      "train loss:0.011967294558881077\n",
      "train loss:0.002232211915919239\n",
      "train loss:0.010852190770640185\n",
      "train loss:0.00676008059184232\n",
      "train loss:0.002019201477233403\n",
      "train loss:0.007156998396961893\n",
      "train loss:0.011860432826839643\n",
      "train loss:0.0018335691682111574\n",
      "train loss:0.021154019593668236\n",
      "train loss:0.036312633914368966\n",
      "train loss:0.04115127925553038\n",
      "train loss:0.003689849814764004\n",
      "train loss:0.00111029572895921\n",
      "train loss:0.010013041355713794\n",
      "train loss:0.003862472305373785\n",
      "train loss:0.003309948939740555\n",
      "train loss:0.011662712824358023\n",
      "train loss:0.009389044718106143\n",
      "train loss:0.04188012692782559\n",
      "train loss:0.020737594549160798\n",
      "train loss:0.0023201082530148963\n",
      "train loss:0.00557349074430259\n",
      "train loss:0.006613988762247102\n",
      "train loss:0.0025087455628791046\n",
      "train loss:0.022040500047033715\n",
      "train loss:0.014550755167486414\n",
      "train loss:0.00393292079249035\n",
      "train loss:0.012256740169560982\n",
      "train loss:0.0013870968563832308\n",
      "train loss:0.0052352832228273905\n",
      "train loss:0.04062453583466348\n",
      "train loss:0.0021923622091525713\n",
      "train loss:0.014686771765873834\n",
      "train loss:0.008642183285635997\n",
      "train loss:0.001168403339420766\n",
      "train loss:0.007872531432069518\n",
      "train loss:0.014812510542224185\n",
      "train loss:0.02678422889139831\n",
      "train loss:0.0066767671644628965\n",
      "train loss:0.006392058776552744\n",
      "train loss:0.005566917006081595\n",
      "train loss:0.005144376466616485\n",
      "train loss:0.007702519893337222\n",
      "train loss:0.06101749701139537\n",
      "train loss:0.0054933671952067465\n",
      "train loss:0.015726532000979534\n",
      "train loss:0.010242274873637216\n",
      "train loss:0.01306319251148471\n",
      "train loss:0.003331771377440074\n",
      "train loss:0.001578441247419467\n",
      "train loss:0.003981254732662245\n",
      "train loss:0.01050490294125921\n",
      "train loss:0.005134822401092033\n",
      "train loss:0.0020692515136287604\n",
      "train loss:0.0022260844202668445\n",
      "train loss:0.0075655768010860335\n",
      "train loss:0.0009286343702874784\n",
      "train loss:0.0035952504131485574\n",
      "train loss:0.011879394669029647\n",
      "train loss:0.0011821817529631077\n",
      "train loss:0.004411935681732781\n",
      "train loss:0.048704794117999856\n",
      "train loss:0.0027629887206321495\n",
      "train loss:0.004786640657481905\n",
      "train loss:0.011436755068193584\n",
      "train loss:0.011096021569737371\n",
      "train loss:0.0013313892813959889\n",
      "train loss:0.007658252003094922\n",
      "train loss:0.022498175069567528\n",
      "train loss:0.007711499263378834\n",
      "train loss:0.07419922984027884\n",
      "train loss:0.004027551604498434\n",
      "train loss:0.044951853176818775\n",
      "train loss:0.0041863504879159795\n",
      "train loss:0.0015118671176707749\n",
      "train loss:0.004655974495754863\n",
      "train loss:0.008917767343522367\n",
      "train loss:0.003952667333677515\n",
      "train loss:0.006566322028172514\n",
      "train loss:0.006654429219983784\n",
      "train loss:0.006556274745400735\n",
      "train loss:0.0007372090447268703\n",
      "train loss:0.03204849238095228\n",
      "train loss:0.006250325825103625\n",
      "train loss:0.0032110135893774873\n",
      "train loss:0.006415382303972725\n",
      "train loss:0.00695718769926174\n",
      "train loss:0.016660308331721854\n",
      "train loss:0.018558594565139513\n",
      "train loss:0.023559134859540306\n",
      "train loss:0.02505152466998213\n",
      "train loss:0.003988346650377358\n",
      "train loss:0.0011348415876833299\n",
      "train loss:0.003790942420801469\n",
      "train loss:0.008357954451706246\n",
      "train loss:0.012215733910664878\n",
      "train loss:0.009995391940013703\n",
      "train loss:0.0015165877359825067\n",
      "train loss:0.0024828487997311907\n",
      "train loss:0.010204766331024427\n",
      "train loss:0.011081331313653513\n",
      "train loss:0.01658867706651449\n",
      "train loss:0.003909839708047045\n",
      "train loss:0.011069511096294157\n",
      "train loss:0.003635112305035609\n",
      "train loss:0.0026538715842874833\n",
      "train loss:0.009414611104469601\n",
      "train loss:0.015483122244013756\n",
      "train loss:0.02419949797593798\n",
      "train loss:0.008641713163160905\n",
      "train loss:0.0033253786114346012\n",
      "train loss:0.006697505353313336\n",
      "train loss:0.05741911248997052\n",
      "train loss:0.002919820906933321\n",
      "train loss:0.010089872715295099\n",
      "train loss:0.014634525867262665\n",
      "train loss:0.02118520561698402\n",
      "train loss:0.05492692720105854\n",
      "train loss:0.015774435787629767\n",
      "train loss:0.0024209874145387665\n",
      "train loss:0.001371522599631747\n",
      "train loss:0.004171293524167636\n",
      "train loss:0.012004694596347974\n",
      "train loss:0.00507657808005925\n",
      "train loss:0.004369796800300765\n",
      "train loss:0.006679643395950746\n",
      "train loss:0.007110672222725683\n",
      "train loss:0.014906163895120308\n",
      "train loss:0.011339171045762259\n",
      "train loss:0.00442644993771357\n",
      "train loss:0.02042464122406645\n",
      "train loss:0.0029744345105657054\n",
      "train loss:0.025178447777971322\n",
      "train loss:0.008479365624986064\n",
      "train loss:0.015347161123170592\n",
      "train loss:0.0072863785112522676\n",
      "train loss:0.009644710458023273\n",
      "train loss:0.0014001223378355516\n",
      "train loss:0.0028262158699995255\n",
      "train loss:0.0017488445927345442\n",
      "train loss:0.006816163611706758\n",
      "train loss:0.015541813005817837\n",
      "train loss:0.006426760886642355\n",
      "train loss:0.02189681907330205\n",
      "train loss:0.006208265777756547\n",
      "train loss:0.009195553800998174\n",
      "train loss:0.006314612557805628\n",
      "train loss:0.0015154677864354343\n",
      "train loss:0.01180001498317914\n",
      "train loss:0.0025807122455662897\n",
      "train loss:0.02408611264514748\n",
      "train loss:0.007890561324960797\n",
      "train loss:0.004877965453530026\n",
      "train loss:0.01096303463306162\n",
      "train loss:0.04624621493560167\n",
      "train loss:0.004312576197273808\n",
      "train loss:0.006442197879718437\n",
      "train loss:0.007095256019944171\n",
      "train loss:0.009815176248995425\n",
      "train loss:0.03143211444967435\n",
      "train loss:0.005897730154266299\n",
      "train loss:0.006475945790669581\n",
      "train loss:0.005828177704856767\n",
      "=== epoch:10, train acc:0.992, test acc:0.991 ===\n",
      "train loss:0.001577492726753072\n",
      "train loss:0.009089056151622558\n",
      "train loss:0.0052655169233057604\n",
      "train loss:0.01660637725606215\n",
      "train loss:0.013614031599380436\n",
      "train loss:0.005000422046332168\n",
      "train loss:0.009050529540443289\n",
      "train loss:0.006746978133239447\n",
      "train loss:0.005415366736504449\n",
      "train loss:0.0006319310899739927\n",
      "train loss:0.0026553836448653073\n",
      "train loss:0.001894480636838512\n",
      "train loss:0.0061391070644561015\n",
      "train loss:0.0033114317528369214\n",
      "train loss:0.0010870992629829954\n",
      "train loss:0.0015395535777367791\n",
      "train loss:0.061840594305045606\n",
      "train loss:0.013822672802299502\n",
      "train loss:0.0009688893897800648\n",
      "train loss:0.00419475528650927\n",
      "train loss:0.0015652082051272958\n",
      "train loss:0.005753374702369574\n",
      "train loss:0.008098899237292382\n",
      "train loss:0.03156942595565532\n",
      "train loss:0.003034927591025508\n",
      "train loss:0.004860704060236859\n",
      "train loss:0.008744727660730813\n",
      "train loss:0.0032181348121848646\n",
      "train loss:0.009530672550362716\n",
      "train loss:0.03986253483465073\n",
      "train loss:0.006038134075890683\n",
      "train loss:0.01139758229943033\n",
      "train loss:0.0042841837224378\n",
      "train loss:0.0028295995307687\n",
      "train loss:0.0030738290352109957\n",
      "train loss:0.0032211774894158455\n",
      "train loss:0.0012115787593588998\n",
      "train loss:0.0037292950433197975\n",
      "train loss:0.007835194805594895\n",
      "train loss:0.017215989959593943\n",
      "train loss:0.003759962869749957\n",
      "train loss:0.004282141490044236\n",
      "train loss:0.00454909912673693\n",
      "train loss:0.009019414796509789\n",
      "train loss:0.011435671046394693\n",
      "train loss:0.030956062628612016\n",
      "train loss:0.0033596005756899943\n",
      "train loss:0.0023392782648818887\n",
      "train loss:0.020283306343023774\n",
      "train loss:0.03708453652158347\n",
      "train loss:0.0009222371951587074\n",
      "train loss:0.000691158208024819\n",
      "train loss:0.021661622523252242\n",
      "train loss:0.006648547343156702\n",
      "train loss:0.004205296847935829\n",
      "train loss:0.009983794094199073\n",
      "train loss:0.0032253619502069873\n",
      "train loss:0.007142407242915773\n",
      "train loss:0.0013413748238877087\n",
      "train loss:0.007688215269490658\n",
      "train loss:0.009030394902226919\n",
      "train loss:0.001293632288600431\n",
      "train loss:0.013052238794276425\n",
      "train loss:0.04829125877065419\n",
      "train loss:0.036386879904287434\n",
      "train loss:0.008155811847036988\n",
      "train loss:0.0009274333975213378\n",
      "train loss:0.026254945646107024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004115069972925866\n",
      "train loss:0.006120023106241006\n",
      "train loss:0.0003979643051348308\n",
      "train loss:0.0021954711814446736\n",
      "train loss:0.0027848215594338\n",
      "train loss:0.016499773384396562\n",
      "train loss:0.003396652069619046\n",
      "train loss:0.009781798183324785\n",
      "train loss:0.011392259134454569\n",
      "train loss:0.0034924626513231447\n",
      "train loss:0.07707593197630082\n",
      "train loss:0.00455323249983915\n",
      "train loss:0.02177711191376646\n",
      "train loss:0.0502456275132898\n",
      "train loss:0.0037259728361697204\n",
      "train loss:0.02387919467976869\n",
      "train loss:0.0036877048769208796\n",
      "train loss:0.003307268884214579\n",
      "train loss:0.0005667556810128168\n",
      "train loss:0.008247652779596996\n",
      "train loss:0.0005677941944030793\n",
      "train loss:0.03144278111863905\n",
      "train loss:0.004888432675616863\n",
      "train loss:0.001910893096530617\n",
      "train loss:0.001626559291541814\n",
      "train loss:0.0033914543032193796\n",
      "train loss:0.001945763140953807\n",
      "train loss:0.009723679340773207\n",
      "train loss:0.01005874150986483\n",
      "train loss:0.007105347966388561\n",
      "train loss:0.016623227805310507\n",
      "train loss:0.0010084082313531744\n",
      "train loss:0.008861532081024165\n",
      "train loss:0.0022488968967691427\n",
      "train loss:0.007295626709116897\n",
      "train loss:0.0025121362529361775\n",
      "train loss:0.010783623743882318\n",
      "train loss:0.0014945462012527185\n",
      "train loss:0.012306894839454347\n",
      "train loss:0.008164890572418293\n",
      "train loss:0.002058805603071897\n",
      "train loss:0.007823331272692404\n",
      "train loss:0.0014567826619409116\n",
      "train loss:0.003694540454287309\n",
      "train loss:0.0033047825553220306\n",
      "train loss:0.013144631134138423\n",
      "train loss:0.004739550279759454\n",
      "train loss:0.01345028619372484\n",
      "train loss:0.0033066498385997426\n",
      "train loss:0.008779644348231735\n",
      "train loss:0.0019577703088133995\n",
      "train loss:0.0034881207777820596\n",
      "train loss:0.006078148584318401\n",
      "train loss:0.005138270664028364\n",
      "train loss:0.004497885224862077\n",
      "train loss:0.0015215082273715\n",
      "train loss:0.0017792836566731234\n",
      "train loss:0.009513162168408881\n",
      "train loss:0.0012218995090757243\n",
      "train loss:0.005966801729897296\n",
      "train loss:0.010561513951926711\n",
      "train loss:0.0032477206649429184\n",
      "train loss:0.005148990617193262\n",
      "train loss:0.018849871015135185\n",
      "train loss:0.0030990188372374615\n",
      "train loss:0.0069157665279310785\n",
      "train loss:0.015058464919369909\n",
      "train loss:0.02675140695729146\n",
      "train loss:0.004778321260105686\n",
      "train loss:0.02713444894343474\n",
      "train loss:0.06647937452833202\n",
      "train loss:0.0019374448165454805\n",
      "train loss:0.004474321968358503\n",
      "train loss:0.0012164593489509719\n",
      "train loss:0.0040031406074959915\n",
      "train loss:0.0023389594890420667\n",
      "train loss:0.0030980502028779026\n",
      "train loss:0.0033257325459435634\n",
      "train loss:0.005521201037445616\n",
      "train loss:0.009184185188195412\n",
      "train loss:0.012863402886570972\n",
      "train loss:0.0031816529795231584\n",
      "train loss:0.004162576681051658\n",
      "train loss:0.013864364484337815\n",
      "train loss:0.0005781900458015618\n",
      "train loss:0.0021914738992122275\n",
      "train loss:0.0009251923536498682\n",
      "train loss:0.012116943713794317\n",
      "train loss:0.009389783468788894\n",
      "train loss:0.0027735543597390737\n",
      "train loss:0.006601810638681694\n",
      "train loss:0.01972781669777443\n",
      "train loss:0.0025959211563835244\n",
      "train loss:0.011112929942110352\n",
      "train loss:0.004172943254806824\n",
      "train loss:0.02075224641407981\n",
      "train loss:0.005263930220102986\n",
      "train loss:0.0029168753552495214\n",
      "train loss:0.0025969655934226644\n",
      "train loss:0.0022015457706358924\n",
      "train loss:0.001830574135619611\n",
      "train loss:0.038087756450068275\n",
      "train loss:0.01500579340872877\n",
      "train loss:0.0037509997335017143\n",
      "train loss:0.015576626014842034\n",
      "train loss:0.002670464963142676\n",
      "train loss:0.009297190740924936\n",
      "train loss:0.004143348537145596\n",
      "train loss:0.0032795599425803307\n",
      "train loss:0.0007116576682551678\n",
      "train loss:0.005628194140220085\n",
      "train loss:0.005198526804193141\n",
      "train loss:0.01695877765568546\n",
      "train loss:0.014892884978635779\n",
      "train loss:0.02896400308206855\n",
      "train loss:0.010397285620374794\n",
      "train loss:0.009177462233418452\n",
      "train loss:0.009877437387948516\n",
      "train loss:0.009207780158976052\n",
      "train loss:0.006079127882303411\n",
      "train loss:0.052756805776064813\n",
      "train loss:0.0009593691578935978\n",
      "train loss:0.001366422705403253\n",
      "train loss:0.005682006316939723\n",
      "train loss:0.014397550677991495\n",
      "train loss:0.0023137633212073558\n",
      "train loss:0.007608582822618403\n",
      "train loss:0.012857807480383563\n",
      "train loss:0.007921455123477627\n",
      "train loss:0.005996124930454664\n",
      "train loss:0.0372635989904283\n",
      "train loss:0.023737454239290173\n",
      "train loss:0.009392523390263915\n",
      "train loss:0.004097822118166686\n",
      "train loss:0.03904119799356455\n",
      "train loss:0.013357708933419355\n",
      "train loss:0.0015250081491924557\n",
      "train loss:0.0022130407284569934\n",
      "train loss:0.00308232386088321\n",
      "train loss:0.0072551618787753125\n",
      "train loss:0.028699996553491244\n",
      "train loss:0.006269972427651148\n",
      "train loss:0.005597616709330455\n",
      "train loss:0.019764920113921433\n",
      "train loss:0.0019695580617908235\n",
      "train loss:0.009368097746288315\n",
      "train loss:0.025839258610693822\n",
      "train loss:0.013937871737359863\n",
      "train loss:0.005561799329849234\n",
      "train loss:0.0050346379614968585\n",
      "train loss:0.008961127825204796\n",
      "train loss:0.019646952131524443\n",
      "train loss:0.0012037425628675992\n",
      "train loss:0.018024989810946877\n",
      "train loss:0.002472973915324059\n",
      "train loss:0.06966798397584383\n",
      "train loss:0.0031258941653295484\n",
      "train loss:0.0008362479390770927\n",
      "train loss:0.007157699808780521\n",
      "train loss:0.010810769400100308\n",
      "train loss:0.004793688899219389\n",
      "train loss:0.004480335169041873\n",
      "train loss:0.004010582289138379\n",
      "train loss:0.005528197921096962\n",
      "train loss:0.0029054491856106445\n",
      "train loss:0.002651406949554724\n",
      "train loss:0.0022192650275302205\n",
      "train loss:0.007128607066889229\n",
      "train loss:0.014135597383095333\n",
      "train loss:0.006098711218271515\n",
      "train loss:0.028190424825076804\n",
      "train loss:0.008608217347145683\n",
      "train loss:0.0015590915480087637\n",
      "train loss:0.0038636272358402723\n",
      "train loss:0.0017323985174504772\n",
      "train loss:0.004945530815874028\n",
      "train loss:0.004410817746744589\n",
      "train loss:0.011441676291114417\n",
      "train loss:0.0041016697936173754\n",
      "train loss:0.011354979804678578\n",
      "train loss:0.003728702532468522\n",
      "train loss:0.008354150697519817\n",
      "train loss:0.006867917878525572\n",
      "train loss:0.016263031925203675\n",
      "train loss:0.012862903160817708\n",
      "train loss:0.0012443259571136786\n",
      "train loss:0.004385402503644495\n",
      "train loss:0.0008204230842175108\n",
      "train loss:0.006626775923898027\n",
      "train loss:0.001614123386096364\n",
      "train loss:0.0300093449680113\n",
      "train loss:0.001938461782173319\n",
      "train loss:0.02321094769858076\n",
      "train loss:0.009992882913504619\n",
      "train loss:0.004582236797240385\n",
      "train loss:0.002877770458598223\n",
      "train loss:0.0008465672393875117\n",
      "train loss:0.00268246943342949\n",
      "train loss:0.012501298595538788\n",
      "train loss:0.007246591242774318\n",
      "train loss:0.009883704394625666\n",
      "train loss:0.0023593086913511795\n",
      "train loss:0.005201914540526567\n",
      "train loss:0.0050346730319781145\n",
      "train loss:0.005407158338146898\n",
      "train loss:0.002567294767213935\n",
      "train loss:0.0012571096826819032\n",
      "train loss:0.006083035616422277\n",
      "train loss:0.00930073576649581\n",
      "train loss:0.005369734506817885\n",
      "train loss:0.0003086158355019025\n",
      "train loss:0.003782767238008256\n",
      "train loss:0.02203995468455922\n",
      "train loss:0.0033048436614245384\n",
      "train loss:0.0009122481113663463\n",
      "train loss:0.0022144569227716595\n",
      "train loss:0.00634879831151796\n",
      "train loss:0.029716314900468315\n",
      "train loss:0.0038588168951024654\n",
      "train loss:0.006168637240277834\n",
      "train loss:0.003561615614454511\n",
      "train loss:0.0008303200001694393\n",
      "train loss:0.0017917766785160805\n",
      "train loss:0.0017345423783475503\n",
      "train loss:0.010871336333284442\n",
      "train loss:0.004032919554429182\n",
      "train loss:0.011142783826263958\n",
      "train loss:0.03214769457936052\n",
      "train loss:0.001490769297047996\n",
      "train loss:0.014384123746372076\n",
      "train loss:0.0055309922484945975\n",
      "train loss:0.007782891495441068\n",
      "train loss:0.006248966709991212\n",
      "train loss:0.043049721995194495\n",
      "train loss:0.002226121482494001\n",
      "train loss:0.007829854428024195\n",
      "train loss:0.003226977527056527\n",
      "train loss:0.009275349384094128\n",
      "train loss:0.006842873295334997\n",
      "train loss:0.006623448899770751\n",
      "train loss:0.0030708433303217614\n",
      "train loss:0.004675289949219353\n",
      "train loss:0.010191861504863247\n",
      "train loss:0.005740574248641775\n",
      "train loss:0.006032559649331878\n",
      "train loss:0.010830188974783774\n",
      "train loss:0.0034367362938080336\n",
      "train loss:0.007900853580092192\n",
      "train loss:0.0013722848518943303\n",
      "train loss:0.001639626795017842\n",
      "train loss:0.016883967469493492\n",
      "train loss:0.03451157031691504\n",
      "train loss:0.031433646565017515\n",
      "train loss:0.003483570516468302\n",
      "train loss:0.015184533219202545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.025970815578128928\n",
      "train loss:0.0017955139733650605\n",
      "train loss:0.009366921034404112\n",
      "train loss:0.005572757399010326\n",
      "train loss:0.0024701361456444795\n",
      "train loss:0.002586219887174902\n",
      "train loss:0.005360967155796681\n",
      "train loss:0.0018237442915121818\n",
      "train loss:0.002013657143995567\n",
      "train loss:0.010384789675286481\n",
      "train loss:0.00470879627921071\n",
      "train loss:0.0008245014029170372\n",
      "train loss:0.01715260664702938\n",
      "train loss:0.02046976609059804\n",
      "train loss:0.020743665488643592\n",
      "train loss:0.0016557492891644979\n",
      "train loss:0.005666828244811885\n",
      "train loss:0.0017028833320203915\n",
      "train loss:0.024776040570138064\n",
      "train loss:0.001615014491229214\n",
      "train loss:0.003777893034567154\n",
      "train loss:0.003616159286104206\n",
      "train loss:0.0012815940887871797\n",
      "train loss:0.0048808176251103836\n",
      "train loss:0.004474000463143612\n",
      "train loss:0.0046616145607423715\n",
      "train loss:0.006638966380828262\n",
      "train loss:0.00516232594591588\n",
      "train loss:0.0008743633218662784\n",
      "train loss:0.0018230956134108111\n",
      "train loss:0.02519976548003327\n",
      "train loss:0.01957916930531169\n",
      "train loss:0.010468278709042312\n",
      "train loss:0.008341689648192104\n",
      "train loss:0.057830925568258695\n",
      "train loss:0.0016784693207068922\n",
      "train loss:0.04262181461603185\n",
      "train loss:0.00821097639678382\n",
      "train loss:0.027099044085852772\n",
      "train loss:0.006642101624186429\n",
      "train loss:0.0029118932540911874\n",
      "train loss:0.006130225103073333\n",
      "train loss:0.0026005375172273837\n",
      "train loss:0.012236585275332586\n",
      "train loss:0.004194228003036288\n",
      "train loss:0.005008165880896441\n",
      "train loss:0.015169114770578241\n",
      "train loss:0.016123103762424\n",
      "train loss:0.004370472341493793\n",
      "train loss:0.006141219745771207\n",
      "train loss:0.00566009917082264\n",
      "train loss:0.006239109976169256\n",
      "train loss:0.006390829960254393\n",
      "train loss:0.007289992954837507\n",
      "train loss:0.009652729727513158\n",
      "train loss:0.0013646346311071763\n",
      "train loss:0.003547114243361278\n",
      "train loss:0.007003289534095502\n",
      "train loss:0.004295712310983707\n",
      "train loss:0.006187008253883739\n",
      "train loss:0.008106432411552343\n",
      "train loss:0.00039790415873636984\n",
      "train loss:0.013739171512351605\n",
      "train loss:0.0062919859595073745\n",
      "train loss:0.0035038618997066495\n",
      "train loss:0.003549331104602282\n",
      "train loss:0.0006207465705843283\n",
      "train loss:0.0007597669725750003\n",
      "train loss:0.020303554090041313\n",
      "train loss:0.019720846460892682\n",
      "train loss:0.016141595025996835\n",
      "train loss:0.007971321073971622\n",
      "train loss:0.002012363021976101\n",
      "train loss:0.0035062828586312606\n",
      "train loss:0.005271518668825546\n",
      "train loss:0.0028023362945795893\n",
      "train loss:0.002532662078958231\n",
      "train loss:0.010739883404414164\n",
      "train loss:0.002590331931416037\n",
      "train loss:0.015653102149250545\n",
      "train loss:0.0021140229830048543\n",
      "train loss:0.002511816981861243\n",
      "train loss:0.022804574474582954\n",
      "train loss:0.00821069960497193\n",
      "train loss:0.0029252895066970972\n",
      "train loss:0.001603571702339416\n",
      "train loss:0.018965986194698116\n",
      "train loss:0.003844784461198072\n",
      "train loss:0.0035024767426785138\n",
      "train loss:0.00031914291946851756\n",
      "train loss:0.007585376927591551\n",
      "train loss:0.011782503917652273\n",
      "train loss:0.0028658632645960106\n",
      "train loss:0.006922422251875673\n",
      "train loss:0.002061107540574664\n",
      "train loss:0.0004684887843246226\n",
      "train loss:0.0035479207560509666\n",
      "train loss:0.0008770478988011558\n",
      "train loss:0.010203565816274835\n",
      "train loss:0.02153903039799885\n",
      "train loss:0.006520160955014188\n",
      "train loss:0.001068050629896097\n",
      "train loss:0.004476101782543233\n",
      "train loss:0.004241238847883991\n",
      "train loss:0.0023728365369989775\n",
      "train loss:0.011877774143522223\n",
      "train loss:0.001702571826247912\n",
      "train loss:0.0009437406911332754\n",
      "train loss:0.00741789003211935\n",
      "train loss:0.0015125186726708804\n",
      "train loss:0.0017531176771286771\n",
      "train loss:0.006701633654436529\n",
      "train loss:0.003184209682530857\n",
      "train loss:0.015103677758626238\n",
      "train loss:0.00229253307103483\n",
      "train loss:0.011137004791728033\n",
      "train loss:0.03444996297686095\n",
      "train loss:0.003870182363950122\n",
      "train loss:0.003735682154788634\n",
      "train loss:0.000580366394861049\n",
      "train loss:0.0010695826496907584\n",
      "train loss:0.002281439113080238\n",
      "train loss:0.0033385902316176086\n",
      "train loss:0.0057562250325097885\n",
      "train loss:0.009706069288991669\n",
      "train loss:0.003709870892570666\n",
      "train loss:0.0023276697243803583\n",
      "train loss:0.006857212819313107\n",
      "train loss:0.0021262450698581376\n",
      "train loss:0.0005652500323354809\n",
      "train loss:0.0028431020507648703\n",
      "train loss:0.0023776555646394227\n",
      "train loss:0.023341665629163302\n",
      "train loss:0.00029767378167541784\n",
      "train loss:0.006643183443180168\n",
      "train loss:0.0035397232300096036\n",
      "train loss:0.0006845823297505438\n",
      "train loss:0.04275341582521033\n",
      "train loss:0.002075015264037803\n",
      "train loss:0.002804576101114449\n",
      "train loss:0.0004848128284021401\n",
      "train loss:0.0066156357039987845\n",
      "train loss:0.012802982401604273\n",
      "train loss:0.009129225507640094\n",
      "train loss:0.00181527525415659\n",
      "train loss:0.00039183127330502736\n",
      "train loss:0.0016156704255920922\n",
      "train loss:0.002204870285325295\n",
      "train loss:0.004992449156359923\n",
      "train loss:0.0017845186144945107\n",
      "train loss:0.0007781859146023435\n",
      "train loss:0.013457175252184017\n",
      "train loss:0.002521664541774965\n",
      "train loss:0.0037463507061763933\n",
      "train loss:0.004367550402226966\n",
      "train loss:0.0033350899213292775\n",
      "train loss:0.014550798223054202\n",
      "train loss:0.0004173035425900198\n",
      "train loss:0.0035712582361274205\n",
      "train loss:0.0027947440721938434\n",
      "train loss:0.003933310984990892\n",
      "train loss:0.00532684130555807\n",
      "train loss:0.0074551371715609405\n",
      "train loss:0.00684308263167421\n",
      "train loss:0.0013719316121677916\n",
      "train loss:0.0009752930908058974\n",
      "train loss:0.0021109437384398233\n",
      "train loss:0.005443919688383284\n",
      "train loss:0.0031283590943873827\n",
      "train loss:0.02355282726364047\n",
      "train loss:0.0003488667819421271\n",
      "train loss:0.04305000582937528\n",
      "train loss:0.02568913369270219\n",
      "train loss:0.0019116000957926605\n",
      "train loss:0.004200555018978105\n",
      "train loss:0.002356607562602623\n",
      "train loss:0.007599352591303683\n",
      "train loss:0.001414434179944892\n",
      "train loss:0.008611567002200195\n",
      "train loss:0.0006263852259682698\n",
      "train loss:0.0006323165965768215\n",
      "train loss:0.0019670850897441565\n",
      "train loss:0.0024457616445071845\n",
      "train loss:0.0031294392878681043\n",
      "train loss:0.002601477752728362\n",
      "train loss:0.0023920628258372913\n",
      "train loss:0.03556998935342\n",
      "train loss:0.0008704013027645167\n",
      "train loss:0.00361413529989318\n",
      "train loss:0.0002654720204939643\n",
      "train loss:0.0022209156809637432\n",
      "train loss:0.0021707155825747325\n",
      "train loss:0.022268842910271022\n",
      "train loss:0.0006780161492575483\n",
      "train loss:0.00355627742925992\n",
      "train loss:0.003718622638776685\n",
      "train loss:0.01845056124842764\n",
      "train loss:0.005443579349952027\n",
      "train loss:0.0004409912532008642\n",
      "train loss:0.03223878212194203\n",
      "train loss:0.0007577887301625015\n",
      "train loss:0.0021609733704380896\n",
      "train loss:0.002082641769386294\n",
      "train loss:0.0018106772828732048\n",
      "train loss:0.0005667136258462518\n",
      "train loss:0.01128772837581957\n",
      "train loss:0.005309293142552416\n",
      "train loss:0.011020377357947362\n",
      "train loss:0.0029040145414666956\n",
      "train loss:0.015924883541189892\n",
      "train loss:0.0022766221530509875\n",
      "train loss:0.025486356307679196\n",
      "train loss:0.014481718711585156\n",
      "train loss:0.0008256804608619585\n",
      "train loss:0.00886037848704735\n",
      "train loss:0.002949444014701523\n",
      "train loss:0.002154016194795098\n",
      "train loss:0.0018160864298440796\n",
      "train loss:0.027470153479279787\n",
      "train loss:0.016935974747313395\n",
      "train loss:0.00787499197327954\n",
      "train loss:0.004656974120843335\n",
      "train loss:0.008759244269716889\n",
      "train loss:0.006510178603009811\n",
      "train loss:0.013534305220376259\n",
      "train loss:0.003180702785794657\n",
      "train loss:0.0023049164516850493\n",
      "train loss:0.01441542701065038\n",
      "train loss:0.004823255469568944\n",
      "train loss:0.009112559267859165\n",
      "train loss:0.00469224486442534\n",
      "train loss:0.001122381497329355\n",
      "train loss:0.0006807556553171941\n",
      "train loss:0.006476663620635814\n",
      "train loss:0.0014860406420826714\n",
      "train loss:0.005404205894394166\n",
      "train loss:0.003287871237267481\n",
      "train loss:0.004790440389238787\n",
      "train loss:0.004552787125718265\n",
      "train loss:0.004441133795426924\n",
      "train loss:0.01664151156460184\n",
      "train loss:0.004304247221814278\n",
      "train loss:0.006042077643925544\n",
      "train loss:0.0039238180629183675\n",
      "train loss:0.010360239615940833\n",
      "train loss:0.005970920898988503\n",
      "train loss:0.0005321704651301252\n",
      "train loss:0.005521807529218754\n",
      "train loss:0.006670726393202418\n",
      "train loss:0.008275317678108466\n",
      "train loss:0.008315635692855969\n",
      "train loss:0.018118561325479295\n",
      "train loss:0.0016398820179920038\n",
      "train loss:0.0012683802246601802\n",
      "train loss:0.006887481956336986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004785350276355871\n",
      "train loss:0.004200623643744646\n",
      "train loss:0.005133138835409934\n",
      "train loss:0.0008989428415184895\n",
      "train loss:0.0016985735024900275\n",
      "train loss:0.022410514360175268\n",
      "train loss:0.005472311836752985\n",
      "train loss:0.007407230784131874\n",
      "train loss:0.006530143236529571\n",
      "train loss:0.004992798213906516\n",
      "train loss:0.014162527309325025\n",
      "train loss:0.00022587450672340015\n",
      "train loss:0.004218909794101755\n",
      "train loss:0.024929664536190044\n",
      "train loss:0.002843291091404528\n",
      "train loss:0.002866492991703355\n",
      "train loss:0.003704409383194376\n",
      "train loss:0.0009812181282913535\n",
      "train loss:0.009013489826040338\n",
      "train loss:0.0277392684586214\n",
      "train loss:0.014744687564336702\n",
      "train loss:0.005530125415971009\n",
      "=== epoch:11, train acc:0.996, test acc:0.989 ===\n",
      "train loss:0.0030938368461825\n",
      "train loss:0.022280550327118988\n",
      "train loss:0.00048301371821357056\n",
      "train loss:0.0028518620576022608\n",
      "train loss:0.00700066024178066\n",
      "train loss:0.009725026338238314\n",
      "train loss:0.005140668498323183\n",
      "train loss:0.006690511743755254\n",
      "train loss:0.0038203967428422827\n",
      "train loss:0.01758548902975092\n",
      "train loss:0.009896006141992998\n",
      "train loss:0.0032096706576748295\n",
      "train loss:0.11725764030246044\n",
      "train loss:0.05635982034939019\n",
      "train loss:0.003722643912255684\n",
      "train loss:0.00035434585148591026\n",
      "train loss:0.006970743880211199\n",
      "train loss:0.003926006968022939\n",
      "train loss:0.021219856047757793\n",
      "train loss:0.008860859485670563\n",
      "train loss:0.011187568119836698\n",
      "train loss:0.003329334484161918\n",
      "train loss:0.0021826091984165595\n",
      "train loss:0.002420205317237481\n",
      "train loss:0.004407604433412671\n",
      "train loss:0.012201248645503125\n",
      "train loss:0.003992616468633503\n",
      "train loss:0.00874179759353756\n",
      "train loss:0.0006083813628394172\n",
      "train loss:0.005350019207258149\n",
      "train loss:0.022631759143160523\n",
      "train loss:0.002236733307180898\n",
      "train loss:0.0008380180861798113\n",
      "train loss:0.00848715410796479\n",
      "train loss:0.00585387646211947\n",
      "train loss:0.009313317980044707\n",
      "train loss:0.0018709123430796877\n",
      "train loss:0.016767716197951296\n",
      "train loss:0.012980295806996113\n",
      "train loss:0.003062648903156093\n",
      "train loss:0.0020480843414984553\n",
      "train loss:0.009895829978984595\n",
      "train loss:0.012600213069179989\n",
      "train loss:0.007527207269161365\n",
      "train loss:0.0013510606385253843\n",
      "train loss:0.002760845561066167\n",
      "train loss:0.0005980660740075336\n",
      "train loss:0.006206107567685495\n",
      "train loss:0.007080025029000945\n",
      "train loss:0.004127246808214361\n",
      "train loss:0.02389932233461699\n",
      "train loss:0.008908429229583452\n",
      "train loss:0.0014493622167186973\n",
      "train loss:0.014796227230967001\n",
      "train loss:0.002786208750818109\n",
      "train loss:0.02991829152249771\n",
      "train loss:0.003640215098136077\n",
      "train loss:0.0009088104555591155\n",
      "train loss:0.0019246254673169411\n",
      "train loss:0.02531278512490388\n",
      "train loss:0.018425581822883185\n",
      "train loss:0.0011798958320026359\n",
      "train loss:0.010407415513839441\n",
      "train loss:0.0031537098065214254\n",
      "train loss:0.006776812525215983\n",
      "train loss:0.014019449786640688\n",
      "train loss:0.0046424025308284675\n",
      "train loss:0.0023743268920424104\n",
      "train loss:0.002142278026305524\n",
      "train loss:0.00923236117041511\n",
      "train loss:0.001606287741701223\n",
      "train loss:0.0031355994747831696\n",
      "train loss:0.007332609166837077\n",
      "train loss:0.0017895718925717938\n",
      "train loss:0.026765813319911683\n",
      "train loss:0.007454472964564082\n",
      "train loss:0.0012697992644864179\n",
      "train loss:0.003540357273547926\n",
      "train loss:0.00726612138604445\n",
      "train loss:0.005940618077435133\n",
      "train loss:0.0009991800636296642\n",
      "train loss:0.018108844411568677\n",
      "train loss:0.0004624676919449493\n",
      "train loss:0.00358272530207169\n",
      "train loss:0.0007021662719710603\n",
      "train loss:0.0036085915662925493\n",
      "train loss:0.0037713545504712244\n",
      "train loss:0.0039273376932892\n",
      "train loss:0.011748033438366612\n",
      "train loss:0.011613167316962643\n",
      "train loss:0.005311995240337446\n",
      "train loss:0.0844410732577124\n",
      "train loss:0.011530365405067959\n",
      "train loss:0.01232912030671327\n",
      "train loss:0.00813644081206028\n",
      "train loss:0.005966846093015737\n",
      "train loss:0.05589265120566681\n",
      "train loss:0.012738219670413196\n",
      "train loss:0.009198599215059637\n",
      "train loss:0.0013439131632444522\n",
      "train loss:0.027529218557254855\n",
      "train loss:0.007522901841398207\n",
      "train loss:0.009875014258269919\n",
      "train loss:0.005695433941943562\n",
      "train loss:0.0023850895535283117\n",
      "train loss:0.0007626874535677351\n",
      "train loss:0.0032849750732503354\n",
      "train loss:0.001576392514544937\n",
      "train loss:0.0005109932026664462\n",
      "train loss:0.007616233552578319\n",
      "train loss:0.006494532985167165\n",
      "train loss:0.0005036091951737397\n",
      "train loss:0.0022043790624292747\n",
      "train loss:0.009361107362560411\n",
      "train loss:0.003628004450967082\n",
      "train loss:0.0019744958055289055\n",
      "train loss:0.0005368221901220025\n",
      "train loss:0.0007969423107949541\n",
      "train loss:0.0007434760888428475\n",
      "train loss:0.010156460848947231\n",
      "train loss:0.010032043180588916\n",
      "train loss:0.013487847378639672\n",
      "train loss:0.0028170169119991527\n",
      "train loss:0.008487607072083972\n",
      "train loss:0.011644688719029017\n",
      "train loss:0.00100494715231525\n",
      "train loss:0.0020709352039104904\n",
      "train loss:0.002532296164929439\n",
      "train loss:0.008383241381049763\n",
      "train loss:0.009629751714057054\n",
      "train loss:0.010439944277728843\n",
      "train loss:0.005327485369774233\n",
      "train loss:0.00790156631434249\n",
      "train loss:0.0014171921893565954\n",
      "train loss:0.004159827947786434\n",
      "train loss:0.0015461172824006808\n",
      "train loss:0.0034665501298899964\n",
      "train loss:0.03242786801378941\n",
      "train loss:0.0023874346751167706\n",
      "train loss:0.011512312865886623\n",
      "train loss:0.005971355127155222\n",
      "train loss:0.0023776050481920923\n",
      "train loss:0.004586817329077039\n",
      "train loss:0.004951271184284933\n",
      "train loss:0.00368149131050425\n",
      "train loss:0.0012285103608690499\n",
      "train loss:0.004518462172663852\n",
      "train loss:0.0029019519837399587\n",
      "train loss:0.001936477643377382\n",
      "train loss:0.0011996880653796507\n",
      "train loss:0.01100518533021181\n",
      "train loss:0.0038029587296112004\n",
      "train loss:0.006477915381703496\n",
      "train loss:0.011161766689421712\n",
      "train loss:0.0011589467540141858\n",
      "train loss:0.00270546605594953\n",
      "train loss:0.020368573332223673\n",
      "train loss:0.0015481208251537368\n",
      "train loss:0.0038239153918892942\n",
      "train loss:0.0002740890320951004\n",
      "train loss:0.006191175234200986\n",
      "train loss:0.00415374931822708\n",
      "train loss:0.03451422566952005\n",
      "train loss:0.0009166711450041836\n",
      "train loss:0.0045489428677719605\n",
      "train loss:0.0013687698839526697\n",
      "train loss:0.012317012424719385\n",
      "train loss:0.0016352513990290985\n",
      "train loss:0.0037321726019148467\n",
      "train loss:0.0042155377040316655\n",
      "train loss:0.0023423046964479383\n",
      "train loss:0.009633034111716891\n",
      "train loss:0.0027332160861866096\n",
      "train loss:0.0027715255662157275\n",
      "train loss:0.015458904440511073\n",
      "train loss:0.014816735626277514\n",
      "train loss:0.03720500506073774\n",
      "train loss:0.0016133728951193537\n",
      "train loss:0.01771657733176734\n",
      "train loss:0.00447920068289745\n",
      "train loss:0.0025551770269064793\n",
      "train loss:0.004629829908728082\n",
      "train loss:0.002568523095388322\n",
      "train loss:0.003344973154315706\n",
      "train loss:0.013212465723933912\n",
      "train loss:0.001088406217282533\n",
      "train loss:0.002980202800039336\n",
      "train loss:0.04337725667289947\n",
      "train loss:0.0022513822406024244\n",
      "train loss:0.0011139992597349617\n",
      "train loss:0.00036450139198093793\n",
      "train loss:0.003587712125062731\n",
      "train loss:0.0020026528684101725\n",
      "train loss:0.0015719073724412792\n",
      "train loss:0.0011240320769442076\n",
      "train loss:0.0006907422611878786\n",
      "train loss:0.0028535239678421378\n",
      "train loss:0.004386248401195777\n",
      "train loss:0.027808765080576434\n",
      "train loss:0.02888711043636936\n",
      "train loss:0.018416751129504763\n",
      "train loss:0.0009607556625723893\n",
      "train loss:0.0025044605008031125\n",
      "train loss:0.003094103750324263\n",
      "train loss:0.005300050095270602\n",
      "train loss:0.0011018420682183587\n",
      "train loss:0.004937617995252162\n",
      "train loss:0.0009147247294723464\n",
      "train loss:0.04328394944911531\n",
      "train loss:0.032426667623303665\n",
      "train loss:0.0012952932187948842\n",
      "train loss:0.00215461643828455\n",
      "train loss:0.02051745070707247\n",
      "train loss:0.0011702169284375503\n",
      "train loss:0.001340124057810812\n",
      "train loss:0.014439877970740589\n",
      "train loss:0.003138370010032478\n",
      "train loss:0.0019903900890765112\n",
      "train loss:0.0006366507591451529\n",
      "train loss:0.030602355971787593\n",
      "train loss:0.0033588236793302\n",
      "train loss:0.001090734248815356\n",
      "train loss:0.008323699435885224\n",
      "train loss:0.0009092870600829164\n",
      "train loss:0.003427320852602814\n",
      "train loss:0.003173410753529647\n",
      "train loss:0.006673858068956342\n",
      "train loss:0.0028683735604304356\n",
      "train loss:0.005972756746127623\n",
      "train loss:0.03866756933104063\n",
      "train loss:0.001513937424931797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006741370760780573\n",
      "train loss:0.002797667921255189\n",
      "train loss:0.0012267130916281774\n",
      "train loss:0.002346489611838745\n",
      "train loss:0.001717160698704611\n",
      "train loss:0.0022333955450806603\n",
      "train loss:0.015028450710214114\n",
      "train loss:0.011056083525238923\n",
      "train loss:0.005007272973896501\n",
      "train loss:0.006284817198849206\n",
      "train loss:0.059669558745942465\n",
      "train loss:0.00019939647285080898\n",
      "train loss:0.0020751854268642573\n",
      "train loss:0.007162167699422763\n",
      "train loss:0.004310559617736109\n",
      "train loss:0.0025767104438034465\n",
      "train loss:0.0008872195862297787\n",
      "train loss:0.0031449916670121284\n",
      "train loss:0.00861608968561016\n",
      "train loss:0.004706192060072365\n",
      "train loss:0.002481853962825383\n",
      "train loss:0.0037225245561112357\n",
      "train loss:0.006235587005755055\n",
      "train loss:0.008013685848113034\n",
      "train loss:0.001921438070813397\n",
      "train loss:0.03656576230088744\n",
      "train loss:0.0029158469120950797\n",
      "train loss:0.02019227464374948\n",
      "train loss:0.0017250071687256918\n",
      "train loss:0.011320122820782055\n",
      "train loss:0.014225328610403825\n",
      "train loss:0.004067243750453434\n",
      "train loss:0.005946790421737866\n",
      "train loss:0.003970216901229542\n",
      "train loss:0.028502966862436453\n",
      "train loss:0.0020342419985176826\n",
      "train loss:0.0009794420391271508\n",
      "train loss:0.005650467965111587\n",
      "train loss:0.020577787946963248\n",
      "train loss:0.006474868786869662\n",
      "train loss:0.008569988916275022\n",
      "train loss:0.013204720023889012\n",
      "train loss:0.06177442901796559\n",
      "train loss:0.0025730508618519543\n",
      "train loss:0.015372278833266265\n",
      "train loss:0.04808539264909708\n",
      "train loss:0.01762447890914879\n",
      "train loss:0.0050524031240965295\n",
      "train loss:0.009920007646236293\n",
      "train loss:0.009494573213658672\n",
      "train loss:0.0038297552188389693\n",
      "train loss:0.0036022481354196613\n",
      "train loss:0.00795207901473293\n",
      "train loss:0.02657879503479746\n",
      "train loss:0.022745938939476094\n",
      "train loss:0.008243919002906337\n",
      "train loss:0.008411425202534406\n",
      "train loss:0.002265815277814853\n",
      "train loss:0.0002566670046135122\n",
      "train loss:0.006656516980509307\n",
      "train loss:0.005456244287873984\n",
      "train loss:0.010979685510565908\n",
      "train loss:0.0003647667700169629\n",
      "train loss:0.0021723033393772928\n",
      "train loss:0.011683917607347128\n",
      "train loss:0.012255430013453743\n",
      "train loss:0.006792272048001912\n",
      "train loss:0.0014934152426523198\n",
      "train loss:0.0019901563564010878\n",
      "train loss:0.0013835708120844045\n",
      "train loss:0.0023457797241494\n",
      "train loss:0.004447192451066561\n",
      "train loss:0.004270083448565744\n",
      "train loss:0.012788834316972322\n",
      "train loss:0.0011773821393690042\n",
      "train loss:0.0039939927532018195\n",
      "train loss:0.03884889114675163\n",
      "train loss:0.0013368836908947204\n",
      "train loss:0.002681179042766581\n",
      "train loss:0.009532402178605594\n",
      "train loss:0.002213231542072689\n",
      "train loss:0.00024711809561644174\n",
      "train loss:0.0020732673431361416\n",
      "train loss:0.0018928505760596676\n",
      "train loss:0.010898715912055202\n",
      "train loss:0.009808191438555987\n",
      "train loss:0.0013462707115139928\n",
      "train loss:0.0055148893293299915\n",
      "train loss:0.004307425151192714\n",
      "train loss:0.0027375493133437495\n",
      "train loss:0.007603482241081773\n",
      "train loss:0.001916196551032795\n",
      "train loss:0.016310720574209223\n",
      "train loss:0.0016137076564122649\n",
      "train loss:0.009936682252737795\n",
      "train loss:0.0043274788373597484\n",
      "train loss:0.006508555240685636\n",
      "train loss:0.0034349052341701453\n",
      "train loss:0.0036315028660247844\n",
      "train loss:0.0049677009825829285\n",
      "train loss:0.005606768078953331\n",
      "train loss:0.000910186550854087\n",
      "train loss:0.005040677962908116\n",
      "train loss:0.0032565327255198377\n",
      "train loss:0.004899871735663735\n",
      "train loss:0.006912901405968464\n",
      "train loss:0.0014652323130202461\n",
      "train loss:0.003284565068223617\n",
      "train loss:0.0014001292657146965\n",
      "train loss:0.0033356939865016966\n",
      "train loss:0.0013752293248052408\n",
      "train loss:0.0013620666850937943\n",
      "train loss:0.0029452241713271952\n",
      "train loss:0.0008884373681953623\n",
      "train loss:0.004908902668802222\n",
      "train loss:0.0014786992906151003\n",
      "train loss:0.0005561323005998178\n",
      "train loss:0.0008621990477434727\n",
      "train loss:0.005083547170830364\n",
      "train loss:0.003143834844224172\n",
      "train loss:0.0016268610296112512\n",
      "train loss:0.0019369306178425997\n",
      "train loss:0.0007501345261210981\n",
      "train loss:0.007699354859224473\n",
      "train loss:0.0001322373627938758\n",
      "train loss:0.001257846534400269\n",
      "train loss:0.016334581413882065\n",
      "train loss:0.00375030863829427\n",
      "train loss:0.009413197272839745\n",
      "train loss:0.0015469359107890485\n",
      "train loss:0.004243196221434905\n",
      "train loss:0.005009374692592686\n",
      "train loss:0.009028090351342544\n",
      "train loss:0.0009285960847986824\n",
      "train loss:0.000785531303010211\n",
      "train loss:0.0023723240138415146\n",
      "train loss:0.0031575891185163015\n",
      "train loss:0.0028930728890620722\n",
      "train loss:0.004439374232939891\n",
      "train loss:0.0073858638486504966\n",
      "train loss:0.008352976571582243\n",
      "train loss:0.0033081181824278177\n",
      "train loss:0.000976786767804476\n",
      "train loss:0.0037149656761272763\n",
      "train loss:0.005434818186118308\n",
      "train loss:0.004010302175252623\n",
      "train loss:0.002974677849741826\n",
      "train loss:0.0022488118204381496\n",
      "train loss:0.004413058167395919\n",
      "train loss:0.004626603032398839\n",
      "train loss:0.0011778084278513889\n",
      "train loss:0.022922395748654945\n",
      "train loss:0.0016792576495688939\n",
      "train loss:0.007552383512517371\n",
      "train loss:0.03435313500579585\n",
      "train loss:0.006684416125321157\n",
      "train loss:0.015526278933687456\n",
      "train loss:0.0012060590575730466\n",
      "train loss:0.0015105258886353137\n",
      "train loss:0.003352803934405378\n",
      "train loss:0.00724828131358936\n",
      "train loss:0.008789809520775098\n",
      "train loss:0.0009816386974411942\n",
      "train loss:0.009102142545371198\n",
      "train loss:0.002787111562407046\n",
      "train loss:0.003388239380490296\n",
      "train loss:0.0013265492821829164\n",
      "train loss:0.0029877483190082553\n",
      "train loss:0.010625830028528687\n",
      "train loss:0.005631376790148392\n",
      "train loss:0.001807696537977188\n",
      "train loss:0.012784766270341022\n",
      "train loss:0.0016350378926033304\n",
      "train loss:0.0004398680760993027\n",
      "train loss:0.004648503055201699\n",
      "train loss:0.0014446003127070494\n",
      "train loss:0.004546484937351676\n",
      "train loss:0.002304663255366698\n",
      "train loss:0.012919838762485331\n",
      "train loss:0.0030436948306551827\n",
      "train loss:0.005022000936726326\n",
      "train loss:0.0016507234138655109\n",
      "train loss:0.002115106797720161\n",
      "train loss:0.004865562997783753\n",
      "train loss:0.0059620691895674064\n",
      "train loss:0.0009818327245455557\n",
      "train loss:0.002474227807536161\n",
      "train loss:0.0033323541317961747\n",
      "train loss:0.013034357439713262\n",
      "train loss:0.001470236037799329\n",
      "train loss:0.0037356722433126723\n",
      "train loss:0.0005137148403758171\n",
      "train loss:0.007860217454478983\n",
      "train loss:0.0032191232012867676\n",
      "train loss:0.023282130007914695\n",
      "train loss:0.005675772366056823\n",
      "train loss:0.001984792981494576\n",
      "train loss:0.014276157695488295\n",
      "train loss:0.0008685197262688403\n",
      "train loss:0.00202940972906412\n",
      "train loss:0.002879704804469258\n",
      "train loss:0.00045124250178589525\n",
      "train loss:0.0014023272095431386\n",
      "train loss:0.010258427136368053\n",
      "train loss:0.008999179983900452\n",
      "train loss:0.002963924736660467\n",
      "train loss:0.002073930812028694\n",
      "train loss:0.010088081802185046\n",
      "train loss:0.0015420324866988395\n",
      "train loss:0.0008311320988326934\n",
      "train loss:0.017028150305900377\n",
      "train loss:0.0012402460122091915\n",
      "train loss:0.00385928800543634\n",
      "train loss:0.007318505509812616\n",
      "train loss:0.013598936480019443\n",
      "train loss:0.0023759065647111105\n",
      "train loss:0.00155151825313191\n",
      "train loss:0.0032684433455223718\n",
      "train loss:0.007339618942652658\n",
      "train loss:0.005202554851577276\n",
      "train loss:0.006933303055629063\n",
      "train loss:0.018502092969318054\n",
      "train loss:0.002392062232563901\n",
      "train loss:0.0002381194479044141\n",
      "train loss:0.0006101818255795716\n",
      "train loss:0.0033680977251212014\n",
      "train loss:0.00581135046688128\n",
      "train loss:0.0020917928276994653\n",
      "train loss:0.011626482882926914\n",
      "train loss:0.00969755807060017\n",
      "train loss:0.051459801454300395\n",
      "train loss:0.008813683104111491\n",
      "train loss:0.0022506492318293205\n",
      "train loss:0.011852771927305572\n",
      "train loss:0.0059924915073230065\n",
      "train loss:0.006539542499882653\n",
      "train loss:0.0024965804677011686\n",
      "train loss:0.002734862844486971\n",
      "train loss:0.0032280031952918215\n",
      "train loss:0.011831085661138102\n",
      "train loss:0.0010807115498393154\n",
      "train loss:0.006800229752767724\n",
      "train loss:0.0012365492874090065\n",
      "train loss:0.0019783565407653077\n",
      "train loss:0.0020248621453299847\n",
      "train loss:0.016503238352915305\n",
      "train loss:0.003413468271771882\n",
      "train loss:0.007605295804688772\n",
      "train loss:0.014236341763616028\n",
      "train loss:0.0006521903116530617\n",
      "train loss:0.005672402181219155\n",
      "train loss:0.002555422341838065\n",
      "train loss:0.0011051685987295019\n",
      "train loss:0.0013620301672862525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005676485657690941\n",
      "train loss:0.0056187563029802\n",
      "train loss:0.002049740312652041\n",
      "train loss:0.0028589626765118015\n",
      "train loss:0.005714495828609222\n",
      "train loss:0.004982269879808322\n",
      "train loss:0.03351060055921892\n",
      "train loss:0.000852489018905963\n",
      "train loss:0.005300397556461234\n",
      "train loss:0.002572974053565681\n",
      "train loss:0.013641814581048817\n",
      "train loss:0.0022632633507941604\n",
      "train loss:0.0033354657579963936\n",
      "train loss:0.00384865856467528\n",
      "train loss:0.0018619894733457694\n",
      "train loss:0.006587846286595786\n",
      "train loss:0.006646977823276441\n",
      "train loss:0.0006183055905689118\n",
      "train loss:0.01107592893856218\n",
      "train loss:0.0013272018326266838\n",
      "train loss:0.002241522603519193\n",
      "train loss:0.006640644462967102\n",
      "train loss:0.004557912436763259\n",
      "train loss:0.01063496454866041\n",
      "train loss:0.03799099678186258\n",
      "train loss:0.007125674924677163\n",
      "train loss:0.0020158182485500464\n",
      "train loss:0.0014615795638592928\n",
      "train loss:0.005096865602858618\n",
      "train loss:0.006504523485819894\n",
      "train loss:0.0008039154519526414\n",
      "train loss:0.0016318643365643476\n",
      "train loss:0.0016465937930308172\n",
      "train loss:0.0019919348572526342\n",
      "train loss:0.0030651690479226064\n",
      "train loss:0.0016548135573229556\n",
      "train loss:0.01979854169918843\n",
      "train loss:0.002208206686188927\n",
      "train loss:0.01433145573208044\n",
      "train loss:0.008231388261490573\n",
      "train loss:0.0032578608343243605\n",
      "train loss:0.001684929826298922\n",
      "train loss:0.004154900644832208\n",
      "train loss:0.00020250147391724334\n",
      "train loss:0.007426907753967336\n",
      "train loss:0.0014351402406480225\n",
      "train loss:0.0005979856778146531\n",
      "train loss:0.006651704438898578\n",
      "train loss:0.009506285787100303\n",
      "train loss:0.007287904356876746\n",
      "train loss:0.012564782300639475\n",
      "train loss:0.001186672320286154\n",
      "train loss:0.0020924434771560922\n",
      "train loss:0.0007790897902842875\n",
      "train loss:0.007217235988080869\n",
      "train loss:0.003481457240663401\n",
      "train loss:0.0021039215878511488\n",
      "train loss:0.0005500601768587268\n",
      "train loss:0.0056419312970250445\n",
      "train loss:0.0023304632482255613\n",
      "train loss:0.0014431972738641716\n",
      "train loss:0.005346731795250397\n",
      "train loss:0.004314800078581313\n",
      "train loss:0.0018422261602450637\n",
      "train loss:0.0031424575579515196\n",
      "train loss:0.002872115777999702\n",
      "train loss:0.004403704265499312\n",
      "train loss:0.0007305650517184467\n",
      "train loss:0.0012646753971772649\n",
      "train loss:0.000705656109733711\n",
      "train loss:0.0038823951959335076\n",
      "train loss:0.010879703311756441\n",
      "train loss:0.0014666250351230003\n",
      "train loss:0.004819591106598519\n",
      "train loss:0.0009029829015661785\n",
      "train loss:0.003506696846042207\n",
      "train loss:0.0016854145978241772\n",
      "train loss:0.0009764357972595691\n",
      "train loss:0.0017722604857330906\n",
      "train loss:0.003297567430484417\n",
      "train loss:0.0006007365444548123\n",
      "train loss:0.0004069682737962928\n",
      "train loss:0.0022405614881979875\n",
      "train loss:0.002731773739065419\n",
      "train loss:0.0024391130245473513\n",
      "train loss:0.0037672563269949477\n",
      "train loss:0.0020323128708828585\n",
      "train loss:0.0033149104599655556\n",
      "train loss:0.0006795700700112804\n",
      "train loss:0.004636384570110048\n",
      "train loss:0.002529424863914827\n",
      "train loss:0.006943900102963372\n",
      "train loss:0.002235188866912575\n",
      "train loss:0.002593210828813052\n",
      "train loss:0.0008055912116237695\n",
      "train loss:0.011886209044740454\n",
      "train loss:0.004351234969837015\n",
      "train loss:0.0024028201476015737\n",
      "train loss:0.00620917362575934\n",
      "train loss:0.0007633111717210542\n",
      "train loss:0.003557625008407059\n",
      "train loss:0.0005527236353759131\n",
      "train loss:0.0082414572191911\n",
      "train loss:0.00022020353463282177\n",
      "train loss:0.00135580590652676\n",
      "train loss:0.005883008751186513\n",
      "train loss:0.009515654212701768\n",
      "train loss:0.0031591544731468467\n",
      "train loss:0.0007943462338648936\n",
      "train loss:0.0010692641034738333\n",
      "train loss:0.0021096661832429777\n",
      "train loss:0.010589084298554352\n",
      "train loss:0.0022825126122713066\n",
      "train loss:0.0018993609249664959\n",
      "train loss:0.006676065217296531\n",
      "=== epoch:12, train acc:0.995, test acc:0.991 ===\n",
      "train loss:0.004480043685145344\n",
      "train loss:0.020871778140819742\n",
      "train loss:0.009869258785225113\n",
      "train loss:0.011881842152188184\n",
      "train loss:0.0008972143605171587\n",
      "train loss:0.006519070803600974\n",
      "train loss:0.006083219161129496\n",
      "train loss:0.011896081827218132\n",
      "train loss:0.0035420701250182315\n",
      "train loss:0.0029432773876009906\n",
      "train loss:0.003985307486321055\n",
      "train loss:0.0006315106499437652\n",
      "train loss:0.10349679838236192\n",
      "train loss:0.00018517473938403544\n",
      "train loss:0.0035191817113775854\n",
      "train loss:0.0018099801115183422\n",
      "train loss:0.0020948201889208055\n",
      "train loss:0.001079112618053614\n",
      "train loss:0.0050132903918850965\n",
      "train loss:0.003065621018791572\n",
      "train loss:0.0005843362274337107\n",
      "train loss:0.003797455368735413\n",
      "train loss:0.019138907600311793\n",
      "train loss:0.01113439691824391\n",
      "train loss:0.0008333134256898421\n",
      "train loss:0.005205390995847595\n",
      "train loss:0.00015943909748103658\n",
      "train loss:0.009515221868800215\n",
      "train loss:0.01021789488762181\n",
      "train loss:0.00027459083849994104\n",
      "train loss:0.009073033383362803\n",
      "train loss:0.002151201476925706\n",
      "train loss:0.007986089543400155\n",
      "train loss:0.0033947061860770877\n",
      "train loss:0.0006512222849169194\n",
      "train loss:0.005950908347829005\n",
      "train loss:0.16076910191611746\n",
      "train loss:0.02247560623636529\n",
      "train loss:0.004512223239518436\n",
      "train loss:0.001436096571004504\n",
      "train loss:0.021470720366133192\n",
      "train loss:0.047268760964100924\n",
      "train loss:0.003063246134750411\n",
      "train loss:0.0032484726432207515\n",
      "train loss:0.004015758794098747\n",
      "train loss:0.005231685415968982\n",
      "train loss:0.005323276499901747\n",
      "train loss:0.004617832872602575\n",
      "train loss:0.004112983417660688\n",
      "train loss:0.008047748335876119\n",
      "train loss:0.0017032962356563275\n",
      "train loss:0.008296725073313178\n",
      "train loss:0.01041846537318309\n",
      "train loss:0.023452425246321244\n",
      "train loss:0.0022718337196220993\n",
      "train loss:0.0024518595918355756\n",
      "train loss:0.001306742916987789\n",
      "train loss:0.004930433683760658\n",
      "train loss:0.005515170029721208\n",
      "train loss:0.01985454429817432\n",
      "train loss:0.0023782911944940453\n",
      "train loss:0.0038643703054805027\n",
      "train loss:0.004071211898990984\n",
      "train loss:0.008710829520214448\n",
      "train loss:0.003911232983555057\n",
      "train loss:0.0018612076732967154\n",
      "train loss:0.0014435601002494006\n",
      "train loss:0.0009881970927280025\n",
      "train loss:0.0011726477910345232\n",
      "train loss:0.0038124856047823223\n",
      "train loss:0.011909255286282313\n",
      "train loss:0.007653853871457616\n",
      "train loss:0.000578047723936643\n",
      "train loss:0.0024448126275539808\n",
      "train loss:0.0019240828580791582\n",
      "train loss:0.0029356447825022876\n",
      "train loss:0.028259514375732927\n",
      "train loss:0.007193206334607249\n",
      "train loss:0.004063841954703928\n",
      "train loss:0.004898172175512358\n",
      "train loss:0.007822078398227577\n",
      "train loss:0.01838507191008119\n",
      "train loss:0.016557703370877683\n",
      "train loss:0.009781629042099383\n",
      "train loss:0.005456367837306489\n",
      "train loss:0.004055363519822029\n",
      "train loss:0.0008097334782945281\n",
      "train loss:0.004785618642686541\n",
      "train loss:0.003340968507786344\n",
      "train loss:0.0009044438705583379\n",
      "train loss:0.004451708882008258\n",
      "train loss:0.0065794860191575495\n",
      "train loss:0.0026586137762897944\n",
      "train loss:0.001150849573656802\n",
      "train loss:0.0053348632528598975\n",
      "train loss:0.007763674160926295\n",
      "train loss:0.022720966751967584\n",
      "train loss:0.012809748160068458\n",
      "train loss:0.0050571264106347045\n",
      "train loss:0.005825414260859895\n",
      "train loss:0.0013635249052456266\n",
      "train loss:0.0022224080541209806\n",
      "train loss:0.0028938873938433246\n",
      "train loss:0.00696943005750741\n",
      "train loss:0.009755246787826848\n",
      "train loss:0.0013962491253228662\n",
      "train loss:0.0045296996378943275\n",
      "train loss:0.004078732328422387\n",
      "train loss:0.007540083429414941\n",
      "train loss:0.010577993964253178\n",
      "train loss:0.006156362010421778\n",
      "train loss:0.0036143343166513105\n",
      "train loss:0.003803728012107423\n",
      "train loss:0.0020181252976318805\n",
      "train loss:0.004315215141909475\n",
      "train loss:0.003669321774513454\n",
      "train loss:0.00040829582212096585\n",
      "train loss:0.004463414934880761\n",
      "train loss:0.006066897078327219\n",
      "train loss:0.0026880445851072067\n",
      "train loss:0.0040235746687886185\n",
      "train loss:0.001755324725892764\n",
      "train loss:0.0011506642535445196\n",
      "train loss:0.0005762288283456681\n",
      "train loss:0.005522627679323901\n",
      "train loss:0.0006270948903172368\n",
      "train loss:0.0005518134357631913\n",
      "train loss:0.0024806877433575267\n",
      "train loss:0.0015116878001942425\n",
      "train loss:0.0016230663604070012\n",
      "train loss:0.002479599936910428\n",
      "train loss:0.0047213633371873155\n",
      "train loss:0.0027553208863786726\n",
      "train loss:0.002997867959467602\n",
      "train loss:0.0016828325961062574\n",
      "train loss:0.0005157353494064287\n",
      "train loss:0.002536170876865698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010079953610524575\n",
      "train loss:0.0026624150559168285\n",
      "train loss:0.0035527674350283494\n",
      "train loss:0.00686067293224312\n",
      "train loss:0.0022793691291317655\n",
      "train loss:0.015167083465950288\n",
      "train loss:0.002562539938587338\n",
      "train loss:0.0013775076973762293\n",
      "train loss:0.006737842993899444\n",
      "train loss:0.0022153197660347203\n",
      "train loss:0.011333774811040396\n",
      "train loss:0.0010965790184580399\n",
      "train loss:0.0010585178449800605\n",
      "train loss:0.0006925299400875208\n",
      "train loss:0.0016932132106016987\n",
      "train loss:0.0011098196452064247\n",
      "train loss:0.00022951360249925154\n",
      "train loss:0.00373516169260734\n",
      "train loss:0.0011652098789561845\n",
      "train loss:0.005158023015512532\n",
      "train loss:0.002835384084574841\n",
      "train loss:0.0023315580801623412\n",
      "train loss:0.0005987720843603696\n",
      "train loss:0.020720686210937863\n",
      "train loss:0.0025788661695413297\n",
      "train loss:0.007839895352438158\n",
      "train loss:0.002791227631490353\n",
      "train loss:0.0015499976210511664\n",
      "train loss:0.007328707546551862\n",
      "train loss:0.0025156082473081227\n",
      "train loss:0.0017526214291900576\n",
      "train loss:0.002955676422857731\n",
      "train loss:0.012938663640451806\n",
      "train loss:0.0009331164253312788\n",
      "train loss:0.0022772451786451844\n",
      "train loss:0.0030782894276031535\n",
      "train loss:0.0014514137618132814\n",
      "train loss:0.0005553167317479319\n",
      "train loss:0.005427351942744057\n",
      "train loss:0.01902697345015455\n",
      "train loss:0.0026623032480471986\n",
      "train loss:0.0034452729473281223\n",
      "train loss:0.01958766531044714\n",
      "train loss:0.004779802903436413\n",
      "train loss:0.0010706314612380279\n",
      "train loss:0.00917348940142315\n",
      "train loss:0.008343618691571839\n",
      "train loss:0.005659600201437386\n",
      "train loss:0.005567748970338463\n",
      "train loss:0.0011836190738035623\n",
      "train loss:0.0016420285580199367\n",
      "train loss:0.008552208206190381\n",
      "train loss:0.0032238054075461303\n",
      "train loss:0.0028552481794074536\n",
      "train loss:0.00385822743787289\n",
      "train loss:0.018171247371944806\n",
      "train loss:0.0027532921985171993\n",
      "train loss:0.003295759336367465\n",
      "train loss:0.0006227332608293302\n",
      "train loss:0.0014147412395048235\n",
      "train loss:0.0023374272531427377\n",
      "train loss:0.0009182502236039531\n",
      "train loss:0.03913965493915637\n",
      "train loss:0.003251828092017989\n",
      "train loss:0.0014519427229359753\n",
      "train loss:0.0003214535992249737\n",
      "train loss:0.001098947330336535\n",
      "train loss:0.0006486154131139534\n",
      "train loss:0.0031976760497513723\n",
      "train loss:0.0046576300817955316\n",
      "train loss:0.0020694858038378993\n",
      "train loss:0.004441503921007986\n",
      "train loss:0.002749030548092751\n",
      "train loss:0.0014121732405130377\n",
      "train loss:0.0018485133118008085\n",
      "train loss:0.0018210843787016887\n",
      "train loss:0.01036091054790347\n",
      "train loss:0.0004831443269601656\n",
      "train loss:0.002728543406954732\n",
      "train loss:0.0006365490958246382\n",
      "train loss:0.005107254396286506\n",
      "train loss:0.0034201939191933735\n",
      "train loss:0.0066414865224233765\n",
      "train loss:0.041236614875332374\n",
      "train loss:0.011187019121485328\n",
      "train loss:0.017377011515938123\n",
      "train loss:0.007669945853926722\n",
      "train loss:0.005765165746918413\n",
      "train loss:0.002523174219066431\n",
      "train loss:0.0007049087619500711\n",
      "train loss:0.007077552886274163\n",
      "train loss:0.0009417480944357451\n",
      "train loss:0.003926843487194586\n",
      "train loss:0.00633258701086974\n",
      "train loss:0.0001621427334958914\n",
      "train loss:0.0033720258351328945\n",
      "train loss:0.0011294555699751453\n",
      "train loss:0.002822751887734044\n",
      "train loss:0.02489864455780753\n",
      "train loss:0.0036675757902664614\n",
      "train loss:0.0016242521090353657\n",
      "train loss:0.0012059670467441106\n",
      "train loss:0.004495175102746716\n",
      "train loss:0.0030531657668533448\n",
      "train loss:0.008673043429496497\n",
      "train loss:0.00030617987356892294\n",
      "train loss:0.0009072393089901851\n",
      "train loss:0.024606138476540015\n",
      "train loss:0.0016196091203099269\n",
      "train loss:0.01982524348924905\n",
      "train loss:0.012399757236258085\n",
      "train loss:0.0019305803615662443\n",
      "train loss:0.01942793629524773\n",
      "train loss:0.0008143171324043087\n",
      "train loss:0.001380872045145124\n",
      "train loss:0.0021393506471300327\n",
      "train loss:0.0025902763544558365\n",
      "train loss:0.005486092165409603\n",
      "train loss:0.029909132626664156\n",
      "train loss:0.001606796525707584\n",
      "train loss:0.005931650646770707\n",
      "train loss:0.0045175234144884\n",
      "train loss:0.0011641665260039335\n",
      "train loss:0.006716977718209086\n",
      "train loss:0.0007712203330844731\n",
      "train loss:0.002521691260762614\n",
      "train loss:0.0021796875306104592\n",
      "train loss:0.005166806081799099\n",
      "train loss:0.001555295687562839\n",
      "train loss:0.0006021920452107434\n",
      "train loss:0.017037214052886374\n",
      "train loss:0.005404795590048242\n",
      "train loss:0.0036866483632872894\n",
      "train loss:0.0010841503530139936\n",
      "train loss:0.017216774846095125\n",
      "train loss:0.0025430264103632728\n",
      "train loss:0.013859614703612431\n",
      "train loss:0.004275956522668538\n",
      "train loss:0.0005692042651520139\n",
      "train loss:0.015527617956143722\n",
      "train loss:0.005160438053231155\n",
      "train loss:0.004366230344788904\n",
      "train loss:0.003607558629462772\n",
      "train loss:0.005728263358093431\n",
      "train loss:0.004676862745219933\n",
      "train loss:0.0004331397955398109\n",
      "train loss:0.0006776941111648819\n",
      "train loss:0.020676636981709233\n",
      "train loss:0.009524438549230557\n",
      "train loss:0.0015677291318821557\n",
      "train loss:0.0009095630739971419\n",
      "train loss:0.0009766526018833409\n",
      "train loss:0.012205933920443607\n",
      "train loss:0.005205737133242196\n",
      "train loss:0.005621995528866316\n",
      "train loss:0.003983659997638448\n",
      "train loss:0.0024623496623272277\n",
      "train loss:0.0025417008937965928\n",
      "train loss:0.03862838551965354\n",
      "train loss:0.0013218308978099071\n",
      "train loss:0.0013506295715509623\n",
      "train loss:0.011379526212173214\n",
      "train loss:0.0011720002251203532\n",
      "train loss:0.0021164510273758404\n",
      "train loss:0.011072514039859514\n",
      "train loss:0.004525095096099539\n",
      "train loss:0.008810777687841456\n",
      "train loss:0.005391234189918706\n",
      "train loss:0.005175520055085896\n",
      "train loss:0.0003434507073078665\n",
      "train loss:0.000747610967305245\n",
      "train loss:0.019796100798881763\n",
      "train loss:0.00019573195127660218\n",
      "train loss:0.0010837749290745638\n",
      "train loss:0.001437536206530117\n",
      "train loss:0.011647567072613853\n",
      "train loss:0.00897196748842687\n",
      "train loss:0.001344716153183649\n",
      "train loss:0.0006392341649171096\n",
      "train loss:0.019302395659995638\n",
      "train loss:0.007080219788359475\n",
      "train loss:0.0015407304992146346\n",
      "train loss:0.0008703515880465432\n",
      "train loss:0.002416545521331901\n",
      "train loss:0.013955938524112225\n",
      "train loss:0.003843025413259687\n",
      "train loss:0.001465815070838984\n",
      "train loss:0.0018597676230244845\n",
      "train loss:0.0035620830643034135\n",
      "train loss:0.001239363055091826\n",
      "train loss:0.0037021093237536835\n",
      "train loss:0.004923795705495938\n",
      "train loss:0.0070469343641709845\n",
      "train loss:0.006701912728831732\n",
      "train loss:0.021916094372131337\n",
      "train loss:0.00810090506729174\n",
      "train loss:0.005332622011514046\n",
      "train loss:0.0013415299458718936\n",
      "train loss:0.005838422174841926\n",
      "train loss:0.008456858411321273\n",
      "train loss:0.0034125281206314534\n",
      "train loss:0.001374741002967509\n",
      "train loss:0.008036699469068775\n",
      "train loss:0.0002861820671682024\n",
      "train loss:0.0038019437908658597\n",
      "train loss:0.0028608035184993926\n",
      "train loss:0.00442331490681151\n",
      "train loss:0.02594552949889085\n",
      "train loss:0.003952628597727227\n",
      "train loss:0.00639076244499994\n",
      "train loss:0.004211415692346127\n",
      "train loss:0.009761696240974773\n",
      "train loss:0.012121394098548972\n",
      "train loss:0.003432730970720477\n",
      "train loss:0.001149687534522716\n",
      "train loss:0.004688079886874059\n",
      "train loss:0.0011497606709621846\n",
      "train loss:0.007840138658511636\n",
      "train loss:0.004912856700000142\n",
      "train loss:0.015308238967527936\n",
      "train loss:0.057951829222044775\n",
      "train loss:0.0036648368910717983\n",
      "train loss:0.009735859847166732\n",
      "train loss:0.00026978316210568174\n",
      "train loss:0.002237160163450783\n",
      "train loss:0.005012676802532303\n",
      "train loss:0.0043311867721409466\n",
      "train loss:0.0020490334722764996\n",
      "train loss:0.005125694782372928\n",
      "train loss:0.0160535717231183\n",
      "train loss:0.0022416261763573042\n",
      "train loss:0.002570289588657085\n",
      "train loss:0.0004438862218842304\n",
      "train loss:0.0018091553446724854\n",
      "train loss:0.0035874476963773595\n",
      "train loss:0.01249356454122496\n",
      "train loss:0.00511120595182433\n",
      "train loss:0.014055385341438275\n",
      "train loss:0.028760645395157578\n",
      "train loss:0.007187381937465355\n",
      "train loss:0.00023848505275046595\n",
      "train loss:0.0005138292436875989\n",
      "train loss:0.002756526839256191\n",
      "train loss:0.013607104390410301\n",
      "train loss:0.0033786498218212812\n",
      "train loss:0.0007854551736263531\n",
      "train loss:0.004505726554922935\n",
      "train loss:0.0016806593692773881\n",
      "train loss:0.0012174770013478442\n",
      "train loss:0.017366524702355647\n",
      "train loss:0.0046083332610669095\n",
      "train loss:0.002893900238920323\n",
      "train loss:0.0011268567477029034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00017053986822228006\n",
      "train loss:0.004765921099937428\n",
      "train loss:0.006524418258006644\n",
      "train loss:0.00664860100345622\n",
      "train loss:0.004039011060987537\n",
      "train loss:0.0021871251377374025\n",
      "train loss:0.0006780866662567056\n",
      "train loss:0.0006375522017904166\n",
      "train loss:0.002543810517337867\n",
      "train loss:0.0008090201749602069\n",
      "train loss:0.0013939023832798467\n",
      "train loss:0.011654165854013182\n",
      "train loss:0.0039464100166615845\n",
      "train loss:0.0008741151169136149\n",
      "train loss:0.00016643373527162073\n",
      "train loss:0.0056125512232945065\n",
      "train loss:0.0031810478131541376\n",
      "train loss:0.0020540626155193882\n",
      "train loss:0.000925825113765867\n",
      "train loss:0.004673062320858844\n",
      "train loss:0.006108324773947126\n",
      "train loss:0.0003822811840981617\n",
      "train loss:0.002482686240254944\n",
      "train loss:0.008476787829011054\n",
      "train loss:0.0025206330642188342\n",
      "train loss:0.0014849174067306627\n",
      "train loss:0.0011589037983215024\n",
      "train loss:0.006475404049244071\n",
      "train loss:0.006739736293432797\n",
      "train loss:0.029876529938433455\n",
      "train loss:0.0035334019474995023\n",
      "train loss:0.0012392355760079948\n",
      "train loss:0.002121576796719885\n",
      "train loss:0.0034924598803567925\n",
      "train loss:0.027708546668145692\n",
      "train loss:0.00042935890651871455\n",
      "train loss:0.002195211538947806\n",
      "train loss:0.0011073148730416844\n",
      "train loss:0.00945170125402963\n",
      "train loss:0.006608075672198668\n",
      "train loss:0.0002769132975901561\n",
      "train loss:0.01610209134002222\n",
      "train loss:0.0013362246184935541\n",
      "train loss:0.028694371958457497\n",
      "train loss:0.0027598320714568763\n",
      "train loss:0.0027795467769119618\n",
      "train loss:0.003486446209491004\n",
      "train loss:0.004124339345917074\n",
      "train loss:0.0011560305230414842\n",
      "train loss:0.003278624860776347\n",
      "train loss:0.006557828321454302\n",
      "train loss:0.0011929735112680708\n",
      "train loss:0.009976713646755864\n",
      "train loss:0.004916739310363893\n",
      "train loss:0.01461215699122291\n",
      "train loss:0.0010107594287886636\n",
      "train loss:0.0007424368067454425\n",
      "train loss:0.0011159259976479003\n",
      "train loss:0.024090996452675748\n",
      "train loss:0.0030113426386290643\n",
      "train loss:0.0010995255171577637\n",
      "train loss:0.001529520789788804\n",
      "train loss:0.005385926331492833\n",
      "train loss:0.001979847838306762\n",
      "train loss:0.00550345979065855\n",
      "train loss:0.004419578396943824\n",
      "train loss:0.0019261073532853836\n",
      "train loss:0.0051304255647783735\n",
      "train loss:0.002530343645686274\n",
      "train loss:0.019015369265308408\n",
      "train loss:0.0027746599481571223\n",
      "train loss:0.000777524418922892\n",
      "train loss:0.0029533317629080523\n",
      "train loss:0.0018424110992772084\n",
      "train loss:0.0023371415763244973\n",
      "train loss:0.011617170969647973\n",
      "train loss:0.011485242808795029\n",
      "train loss:0.0016402075806826227\n",
      "train loss:0.004657843415367002\n",
      "train loss:0.0032015841545474178\n",
      "train loss:0.00024046003550657607\n",
      "train loss:0.00564466811132466\n",
      "train loss:0.003826734612527788\n",
      "train loss:0.027523195233534702\n",
      "train loss:0.0010744894675873543\n",
      "train loss:0.0018383286736665654\n",
      "train loss:0.001995198634431362\n",
      "train loss:0.0032628365532676147\n",
      "train loss:0.0008049082494532925\n",
      "train loss:0.003455058309966658\n",
      "train loss:0.002944441423912542\n",
      "train loss:0.14356080971364418\n",
      "train loss:0.009048939267761506\n",
      "train loss:0.0009939896686663916\n",
      "train loss:0.0020837797251245793\n",
      "train loss:0.016276427353044312\n",
      "train loss:0.00684926899548381\n",
      "train loss:0.032074227557366226\n",
      "train loss:0.0004178204955966295\n",
      "train loss:0.0032385680615801093\n",
      "train loss:0.020913548502468817\n",
      "train loss:0.002757159410745053\n",
      "train loss:0.0019544469598423266\n",
      "train loss:0.003047601199561459\n",
      "train loss:0.0008508615318182422\n",
      "train loss:0.004814288219079926\n",
      "train loss:0.00042062142924088436\n",
      "train loss:0.004271138051323014\n",
      "train loss:0.009736932986298394\n",
      "train loss:0.006178721455570492\n",
      "train loss:0.009154488037903462\n",
      "train loss:0.029672574046726633\n",
      "train loss:0.008865032951863491\n",
      "train loss:0.0004845214725086459\n",
      "train loss:0.007852766363687952\n",
      "train loss:0.0011723638180577082\n",
      "train loss:0.0008690478105523933\n",
      "train loss:0.0006472277410213438\n",
      "train loss:0.005648649738749037\n",
      "train loss:0.0070095010897337565\n",
      "train loss:0.006703324052384747\n",
      "train loss:0.005479812684845122\n",
      "train loss:0.0036262855462838458\n",
      "train loss:0.0025513387766361545\n",
      "train loss:0.0012157336339341292\n",
      "train loss:0.0008492471008473124\n",
      "train loss:0.0009974542932690057\n",
      "train loss:0.012535785796436478\n",
      "train loss:0.0005743700247614788\n",
      "train loss:0.0008621192761447045\n",
      "train loss:0.0064156137613602116\n",
      "train loss:0.005713699559748378\n",
      "train loss:0.0018712373004054186\n",
      "train loss:0.006512810425199337\n",
      "train loss:0.002522493380941836\n",
      "train loss:0.007572063061130023\n",
      "train loss:0.009656942504054036\n",
      "train loss:0.006576466627086797\n",
      "train loss:0.00425779401704643\n",
      "train loss:0.005623372846495428\n",
      "train loss:0.0008057365033887789\n",
      "train loss:0.005335674731942007\n",
      "train loss:0.0003097666231693757\n",
      "train loss:0.0017273714503977511\n",
      "train loss:0.0016588965639092012\n",
      "train loss:0.006197604457689698\n",
      "train loss:0.00509954479329274\n",
      "train loss:0.0014838115180238027\n",
      "train loss:0.012232615044947256\n",
      "train loss:0.009079236531508411\n",
      "train loss:0.0030918612790276395\n",
      "train loss:0.0010036778519809419\n",
      "train loss:0.0008851705551634142\n",
      "train loss:0.0024481031779797977\n",
      "train loss:0.01386275815269036\n",
      "train loss:0.0019400634026553393\n",
      "train loss:0.002884731711977277\n",
      "train loss:0.002504151880947115\n",
      "train loss:0.003422155415748097\n",
      "train loss:0.0032004074576460857\n",
      "train loss:0.002750963958247949\n",
      "train loss:0.004512336432141579\n",
      "train loss:0.0013474504858804774\n",
      "train loss:0.0042629298698288135\n",
      "train loss:0.01438921090007411\n",
      "train loss:0.007091683345740296\n",
      "train loss:0.0003347885139572729\n",
      "train loss:0.004971017218594689\n",
      "train loss:0.004525140451896289\n",
      "train loss:0.0070118021093816185\n",
      "train loss:0.0014760291792149918\n",
      "train loss:0.006945684460500212\n",
      "train loss:0.020116702481152108\n",
      "train loss:0.05361078406435107\n",
      "train loss:0.0031886388626078364\n",
      "train loss:0.006164739251440231\n",
      "train loss:0.001958507231908973\n",
      "train loss:0.004547408474863147\n",
      "train loss:0.0061885964321344925\n",
      "train loss:0.020321775640937366\n",
      "train loss:0.015506210985934474\n",
      "train loss:0.0017560912309374716\n",
      "train loss:0.007799117727255246\n",
      "train loss:0.003332613909725741\n",
      "train loss:0.0015536062861378891\n",
      "train loss:0.001679736512693524\n",
      "train loss:0.010111978920544638\n",
      "train loss:0.0013456059063193795\n",
      "train loss:0.003329489803167825\n",
      "train loss:0.009232159423735897\n",
      "train loss:0.006706821859966341\n",
      "train loss:0.002242446228572951\n",
      "train loss:0.0073556025969289274\n",
      "train loss:0.0038213711389751466\n",
      "train loss:0.0010834135294141435\n",
      "train loss:0.010610012572290231\n",
      "train loss:0.0036587671027710437\n",
      "train loss:0.00125530070659402\n",
      "train loss:0.000566837666796464\n",
      "train loss:0.001358748542571213\n",
      "train loss:0.0037940417990661897\n",
      "train loss:0.009349978351743895\n",
      "train loss:0.0011097920839286777\n",
      "train loss:0.008326706989295957\n",
      "train loss:0.009700266733216067\n",
      "train loss:0.001767872203129428\n",
      "train loss:0.0006829624268593194\n",
      "train loss:0.0011156094484987423\n",
      "train loss:0.0018430755948639782\n",
      "train loss:0.0028844592500388943\n",
      "=== epoch:13, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.0014521088552673497\n",
      "train loss:0.0110254449003345\n",
      "train loss:0.008953200543875751\n",
      "train loss:0.004805934470393801\n",
      "train loss:0.00833550897917301\n",
      "train loss:0.00319416937628708\n",
      "train loss:0.0024748820451752974\n",
      "train loss:0.0058307772869610084\n",
      "train loss:0.01157847278422778\n",
      "train loss:0.0029617265613634492\n",
      "train loss:0.0030597573357741986\n",
      "train loss:0.0003580913355632251\n",
      "train loss:0.0057762469238509615\n",
      "train loss:0.0018963009645357092\n",
      "train loss:0.0484256153693418\n",
      "train loss:0.001048865139101672\n",
      "train loss:0.0005689532076033539\n",
      "train loss:0.0026824892071538337\n",
      "train loss:0.0018180823247196567\n",
      "train loss:0.00038611019459773794\n",
      "train loss:0.003702556404338996\n",
      "train loss:0.011517433177517212\n",
      "train loss:0.004854479070746082\n",
      "train loss:0.001059624218554651\n",
      "train loss:0.022476977830415946\n",
      "train loss:0.00422172426053339\n",
      "train loss:0.0010153578322384638\n",
      "train loss:0.0012810655173497274\n",
      "train loss:0.03491744259556925\n",
      "train loss:0.0018439466326360733\n",
      "train loss:0.0051899201944145415\n",
      "train loss:0.02345441131498083\n",
      "train loss:0.001990262557508248\n",
      "train loss:0.010088558928963695\n",
      "train loss:0.00762744960211092\n",
      "train loss:0.0049126198852440985\n",
      "train loss:0.00035287695563377444\n",
      "train loss:0.010264119367776854\n",
      "train loss:0.001642759050771697\n",
      "train loss:0.0032613149604484477\n",
      "train loss:0.0045026604554288426\n",
      "train loss:0.040808615225383725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010150251208545638\n",
      "train loss:0.003340922604592722\n",
      "train loss:0.025566371175780197\n",
      "train loss:0.023900364419834973\n",
      "train loss:0.009717490546060338\n",
      "train loss:0.0030663862638202286\n",
      "train loss:0.0006941054358929837\n",
      "train loss:0.0014254251042857557\n",
      "train loss:0.0007214147969089466\n",
      "train loss:0.0032970211752465024\n",
      "train loss:0.005582761857192803\n",
      "train loss:0.015401408182828353\n",
      "train loss:0.007197915020291486\n",
      "train loss:0.011457234328128221\n",
      "train loss:0.003187401726340224\n",
      "train loss:0.006657371741040419\n",
      "train loss:0.006199541178616097\n",
      "train loss:0.0035688652607888966\n",
      "train loss:0.01727394241422271\n",
      "train loss:0.006287033675534661\n",
      "train loss:0.0010731022831711717\n",
      "train loss:0.0038722477148375747\n",
      "train loss:0.012222600137903659\n",
      "train loss:0.029149540757490176\n",
      "train loss:0.0017535554964105387\n",
      "train loss:0.0029562934010455323\n",
      "train loss:0.007271577826573355\n",
      "train loss:0.004095835030662118\n",
      "train loss:0.002457365920502911\n",
      "train loss:0.006951209664173985\n",
      "train loss:0.01250156094318338\n",
      "train loss:0.0003532300515046562\n",
      "train loss:0.0015396467570253584\n",
      "train loss:0.0008436769554167696\n",
      "train loss:0.006760111436048019\n",
      "train loss:0.005076859983820125\n",
      "train loss:0.00046513402310373016\n",
      "train loss:0.004891175527611366\n",
      "train loss:0.004519243151122832\n",
      "train loss:0.0016261603576621234\n",
      "train loss:0.006261478049109882\n",
      "train loss:0.0021418989215237954\n",
      "train loss:0.0009231707201094058\n",
      "train loss:0.006630245243002695\n",
      "train loss:0.009409457089142563\n",
      "train loss:0.00431236552502373\n",
      "train loss:0.0007733917039617447\n",
      "train loss:0.0009090870597961163\n",
      "train loss:0.0058910173772602605\n",
      "train loss:0.0032653690672580045\n",
      "train loss:0.0008907918904545428\n",
      "train loss:0.011816338709013828\n",
      "train loss:0.0034595828682489125\n",
      "train loss:0.003127460959404533\n",
      "train loss:0.0005648683227163811\n",
      "train loss:0.008177582603617358\n",
      "train loss:0.0008498310971044762\n",
      "train loss:0.0007360534804865998\n",
      "train loss:0.0029347613873142676\n",
      "train loss:0.016085706216566117\n",
      "train loss:0.003171373913438016\n",
      "train loss:0.006636182023280791\n",
      "train loss:0.0011534433498094632\n",
      "train loss:0.007013481322780445\n",
      "train loss:0.003081541738451188\n",
      "train loss:0.014713644528097399\n",
      "train loss:0.010645485098518773\n",
      "train loss:0.0022264694259275268\n",
      "train loss:0.033117798096240984\n",
      "train loss:0.004343917293797867\n",
      "train loss:0.007975705281422813\n",
      "train loss:0.003224307850739525\n",
      "train loss:0.01044129074873383\n",
      "train loss:0.008495826471115702\n",
      "train loss:0.010832092013853663\n",
      "train loss:0.009694216973151596\n",
      "train loss:0.001854863516187131\n",
      "train loss:0.0056881231714443845\n",
      "train loss:0.0005422856300648909\n",
      "train loss:0.006372461550389713\n",
      "train loss:0.0032385691545866453\n",
      "train loss:0.019888123058692114\n",
      "train loss:0.0030447479517315633\n",
      "train loss:0.009081556799776753\n",
      "train loss:0.00016569908338034164\n",
      "train loss:0.0015108740332568965\n",
      "train loss:0.0002241335889264104\n",
      "train loss:0.0008667944587935277\n",
      "train loss:0.0002558379301308176\n",
      "train loss:0.0005257159005160705\n",
      "train loss:0.0652761390566516\n",
      "train loss:0.001997671315720095\n",
      "train loss:0.002784075951688977\n",
      "train loss:0.0036035665965474762\n",
      "train loss:0.0003810592684518838\n",
      "train loss:0.01210002298252429\n",
      "train loss:0.0005135838863991435\n",
      "train loss:0.00033937628405278955\n",
      "train loss:0.0011324505181110613\n",
      "train loss:0.0013153510172793262\n",
      "train loss:0.011579839953946278\n",
      "train loss:0.006906655330727696\n",
      "train loss:0.002201103062345933\n",
      "train loss:0.005245530461138997\n",
      "train loss:0.0018060299898837431\n",
      "train loss:0.008231611911896359\n",
      "train loss:0.014749747707911064\n",
      "train loss:0.0012460474572437272\n",
      "train loss:0.006471594861498568\n",
      "train loss:0.004663552401891935\n",
      "train loss:0.001507798079961686\n",
      "train loss:0.002864969062466902\n",
      "train loss:0.0006154313517503414\n",
      "train loss:0.005911322487692376\n",
      "train loss:0.0008746567029758645\n",
      "train loss:0.0011904638189045662\n",
      "train loss:0.004917870826715576\n",
      "train loss:0.00263001436432853\n",
      "train loss:0.004270095009776993\n",
      "train loss:0.000950707480832946\n",
      "train loss:0.0034894836928044955\n",
      "train loss:0.001106198457731279\n",
      "train loss:0.003468591774521726\n",
      "train loss:0.0009848454677388158\n",
      "train loss:0.0018851362160484477\n",
      "train loss:0.0016979564985511214\n",
      "train loss:0.0004524002975828394\n",
      "train loss:0.0012242675777582234\n",
      "train loss:0.0008746251057588199\n",
      "train loss:0.018990984749106165\n",
      "train loss:0.008731124504176364\n",
      "train loss:0.00407917864179793\n",
      "train loss:0.0005568690659184533\n",
      "train loss:0.0035571093200818826\n",
      "train loss:0.004446772685484995\n",
      "train loss:0.008981184523084882\n",
      "train loss:0.004734196074521957\n",
      "train loss:0.0046286475551555965\n",
      "train loss:0.0017837961398193894\n",
      "train loss:0.0014730701708848956\n",
      "train loss:0.003184094803527445\n",
      "train loss:0.0013828058704270058\n",
      "train loss:0.0005489700950591899\n",
      "train loss:0.0024171610249016213\n",
      "train loss:0.0016790131383540735\n",
      "train loss:0.0002571480604975163\n",
      "train loss:0.000501735970610744\n",
      "train loss:0.0014834743130342836\n",
      "train loss:0.0015375070140512474\n",
      "train loss:0.0010010790237345282\n",
      "train loss:0.0041047684352809284\n",
      "train loss:0.0005602204781576067\n",
      "train loss:0.005953922750187005\n",
      "train loss:0.00402288921104579\n",
      "train loss:0.0011621044323339843\n",
      "train loss:0.001132754765274217\n",
      "train loss:0.006619632346209678\n",
      "train loss:0.00020110328701759223\n",
      "train loss:0.0014099533271563383\n",
      "train loss:0.0021517185557655034\n",
      "train loss:0.001653289114366889\n",
      "train loss:0.004572988338272618\n",
      "train loss:0.0002821225878817836\n",
      "train loss:0.0014026189861019028\n",
      "train loss:0.011195318243201031\n",
      "train loss:0.01097881132309086\n",
      "train loss:0.006323464819384105\n",
      "train loss:0.00035653422587770563\n",
      "train loss:0.0011020160191814823\n",
      "train loss:0.0019380134441517453\n",
      "train loss:0.004961053843083669\n",
      "train loss:0.0013783073643368953\n",
      "train loss:0.00398378078693643\n",
      "train loss:0.000620898737471202\n",
      "train loss:0.0006674027668232507\n",
      "train loss:0.001257100780891835\n",
      "train loss:0.0004736097082931422\n",
      "train loss:0.006406434964091344\n",
      "train loss:0.0005119449723202444\n",
      "train loss:0.0014067137896170284\n",
      "train loss:0.004256692647770268\n",
      "train loss:0.0038283593841218714\n",
      "train loss:0.0016010697369377874\n",
      "train loss:0.0002299470085111229\n",
      "train loss:0.0005931833642909051\n",
      "train loss:0.0005645267656541793\n",
      "train loss:0.007098207204999094\n",
      "train loss:0.0016965196942347186\n",
      "train loss:0.0037719809224517776\n",
      "train loss:0.003953852128232243\n",
      "train loss:0.002773463605275697\n",
      "train loss:0.0014689902765688734\n",
      "train loss:0.0003322840497494403\n",
      "train loss:0.014458759889288837\n",
      "train loss:0.004691175965435433\n",
      "train loss:0.004050981436141589\n",
      "train loss:0.008045664032384556\n",
      "train loss:0.0009581399744435046\n",
      "train loss:0.0017120523303313492\n",
      "train loss:0.0026098196268940464\n",
      "train loss:0.04021760691973797\n",
      "train loss:0.004813535259261433\n",
      "train loss:0.001797673235061952\n",
      "train loss:0.0009515244839301303\n",
      "train loss:0.001068197078673944\n",
      "train loss:0.016650945283953826\n",
      "train loss:0.0009901790785711508\n",
      "train loss:0.0020354720966195765\n",
      "train loss:0.0036679653964138063\n",
      "train loss:0.0032490607860946263\n",
      "train loss:0.001874626724846122\n",
      "train loss:0.007382215466334576\n",
      "train loss:0.049488521649415536\n",
      "train loss:0.0017715006737705663\n",
      "train loss:0.0004349000748154442\n",
      "train loss:0.0005767666227067657\n",
      "train loss:0.00552678666361649\n",
      "train loss:0.0005336554758939724\n",
      "train loss:7.064535345280282e-05\n",
      "train loss:0.002067391864201103\n",
      "train loss:0.00018833534776178007\n",
      "train loss:0.0013497559276738364\n",
      "train loss:0.0024825318638425765\n",
      "train loss:0.010856314793167659\n",
      "train loss:0.0019924513201413445\n",
      "train loss:0.00505783581549604\n",
      "train loss:0.0008640903380452232\n",
      "train loss:0.016351139674019535\n",
      "train loss:0.018410763537297398\n",
      "train loss:0.0036907229348528956\n",
      "train loss:0.005905618958882122\n",
      "train loss:0.005314642311943495\n",
      "train loss:0.0014223867637623772\n",
      "train loss:0.004819601995173371\n",
      "train loss:0.0026764687372322566\n",
      "train loss:0.0021240860298713904\n",
      "train loss:0.01479166360432733\n",
      "train loss:0.014766123288321277\n",
      "train loss:0.006337509392903601\n",
      "train loss:0.00034302374884568275\n",
      "train loss:0.0009886391541670044\n",
      "train loss:0.005669885780091432\n",
      "train loss:0.0014840159537186912\n",
      "train loss:0.011490431509645072\n",
      "train loss:0.000376189076119669\n",
      "train loss:0.004002253854345145\n",
      "train loss:0.005849754310733994\n",
      "train loss:0.0006601366830252364\n",
      "train loss:0.0014095212156978634\n",
      "train loss:0.004760488114576237\n",
      "train loss:0.0013023708788093616\n",
      "train loss:0.0007709307643488586\n",
      "train loss:0.0005837563433912545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004840672437455387\n",
      "train loss:0.010603309319569805\n",
      "train loss:0.01405958528777121\n",
      "train loss:0.0013446842248657927\n",
      "train loss:0.0015650714790883522\n",
      "train loss:0.0004792694514658613\n",
      "train loss:0.004553762408539328\n",
      "train loss:0.004642036048031956\n",
      "train loss:0.002933116764149653\n",
      "train loss:0.004289207015709273\n",
      "train loss:0.00042621553892895373\n",
      "train loss:0.016677329184305447\n",
      "train loss:0.002558376713558116\n",
      "train loss:0.0009382242848052973\n",
      "train loss:0.03164992733024961\n",
      "train loss:0.0017013796357957028\n",
      "train loss:0.02074634227286355\n",
      "train loss:0.006432108487732916\n",
      "train loss:6.928824636317821e-05\n",
      "train loss:0.0015891095214497872\n",
      "train loss:0.0038009165974655485\n",
      "train loss:0.0013102734588243585\n",
      "train loss:0.005176243551293922\n",
      "train loss:0.0016071193943729928\n",
      "train loss:0.010719509189761394\n",
      "train loss:0.001086014334380743\n",
      "train loss:0.004755588621183985\n",
      "train loss:0.007601184404639662\n",
      "train loss:0.0015497541733729486\n",
      "train loss:0.004848488820693102\n",
      "train loss:0.002718866837478676\n",
      "train loss:0.0016180060774730843\n",
      "train loss:0.0010460056823328504\n",
      "train loss:0.00728023341217922\n",
      "train loss:0.0025084064553102326\n",
      "train loss:0.002792365222934689\n",
      "train loss:0.0060682588075135005\n",
      "train loss:0.002427438714695918\n",
      "train loss:0.0008284845351100818\n",
      "train loss:0.001166805114127025\n",
      "train loss:0.0021373820076185054\n",
      "train loss:0.004217106868341499\n",
      "train loss:0.0011084635243365853\n",
      "train loss:0.0015509225961583368\n",
      "train loss:0.0020607267093359907\n",
      "train loss:0.0010765178778297689\n",
      "train loss:0.00795082749468767\n",
      "train loss:0.019996840040483622\n",
      "train loss:0.001381644473692796\n",
      "train loss:0.003505030732940136\n",
      "train loss:0.0006670623563141128\n",
      "train loss:0.0024500714854615428\n",
      "train loss:0.0009230119510902418\n",
      "train loss:0.00027599718137471434\n",
      "train loss:0.0018000254356903506\n",
      "train loss:0.0030486656567328967\n",
      "train loss:0.0014733103173982293\n",
      "train loss:0.002866818824898292\n",
      "train loss:0.004090711808582973\n",
      "train loss:0.0007331646374454039\n",
      "train loss:0.0007343891032955533\n",
      "train loss:0.004327600280413558\n",
      "train loss:0.00042997607644407426\n",
      "train loss:0.0005878880211067785\n",
      "train loss:0.002334894827367603\n",
      "train loss:0.009574372673278259\n",
      "train loss:0.004073881629634695\n",
      "train loss:0.003156642875383999\n",
      "train loss:0.0228437364953801\n",
      "train loss:0.0027248533843449363\n",
      "train loss:0.012831559659498287\n",
      "train loss:0.001947306164901258\n",
      "train loss:0.003615286905485592\n",
      "train loss:0.003770830874104411\n",
      "train loss:0.0021001761871125573\n",
      "train loss:0.020184250390061574\n",
      "train loss:0.007072774667934887\n",
      "train loss:0.0014250993665246659\n",
      "train loss:0.006336346363908399\n",
      "train loss:0.0006975519707137698\n",
      "train loss:0.019915727834834744\n",
      "train loss:0.007357235990574062\n",
      "train loss:0.0012334155015118042\n",
      "train loss:0.0013721716458853835\n",
      "train loss:0.0031873233246826342\n",
      "train loss:0.0005990477509856442\n",
      "train loss:0.001702834388704524\n",
      "train loss:0.01582845771600977\n",
      "train loss:0.0004933129599158812\n",
      "train loss:0.006208405831706509\n",
      "train loss:0.0020851992341128405\n",
      "train loss:0.0028678631180958053\n",
      "train loss:0.0006119415989565965\n",
      "train loss:0.0014522118856551249\n",
      "train loss:0.002671861914315728\n",
      "train loss:0.0031484183736699197\n",
      "train loss:0.000468171850982538\n",
      "train loss:0.0007137102890301976\n",
      "train loss:0.020420435812323588\n",
      "train loss:0.0019948331883263572\n",
      "train loss:0.003412141485131892\n",
      "train loss:0.005680809651003307\n",
      "train loss:0.0023910383919063397\n",
      "train loss:0.0022741274162527887\n",
      "train loss:0.004691207817228183\n",
      "train loss:0.005125979035653336\n",
      "train loss:0.00531394906368736\n",
      "train loss:0.0009311385321870524\n",
      "train loss:0.0022428496803396578\n",
      "train loss:0.0010688012406888862\n",
      "train loss:0.008108203925112283\n",
      "train loss:0.001848563315354461\n",
      "train loss:0.002438210853364504\n",
      "train loss:0.006054503870938482\n",
      "train loss:0.0004956230978271265\n",
      "train loss:0.003120562717238936\n",
      "train loss:0.00048821309062965535\n",
      "train loss:0.003401314370465213\n",
      "train loss:0.0001890122677898703\n",
      "train loss:0.005092806119243601\n",
      "train loss:0.0014823412335953148\n",
      "train loss:0.004314787728608661\n",
      "train loss:0.0010455264468312723\n",
      "train loss:0.0006549082616884443\n",
      "train loss:0.004390909109380185\n",
      "train loss:0.003811201226183042\n",
      "train loss:0.005849997895604161\n",
      "train loss:0.0015688025039238614\n",
      "train loss:0.005598164158960046\n",
      "train loss:0.004462994189851053\n",
      "train loss:0.0014095910572887893\n",
      "train loss:0.0019327869627762126\n",
      "train loss:0.014184973733048218\n",
      "train loss:0.001935509014184574\n",
      "train loss:0.00207717873996371\n",
      "train loss:0.002091652193123404\n",
      "train loss:0.009316078309534133\n",
      "train loss:0.004290014091321836\n",
      "train loss:0.0004782676031086899\n",
      "train loss:0.0002473186779428036\n",
      "train loss:0.00044324714472635104\n",
      "train loss:0.00370596348109432\n",
      "train loss:0.0036937978508129166\n",
      "train loss:0.0007001745472046836\n",
      "train loss:0.0003121101198479315\n",
      "train loss:0.0039763432232469585\n",
      "train loss:0.000207957176825767\n",
      "train loss:0.01940074990113917\n",
      "train loss:0.010582397027678905\n",
      "train loss:0.00524059610198745\n",
      "train loss:0.002457966894448929\n",
      "train loss:0.006989072269630328\n",
      "train loss:0.004234169308106313\n",
      "train loss:0.0030570590153227743\n",
      "train loss:0.0013277699352738529\n",
      "train loss:0.0014891392058886802\n",
      "train loss:0.0008820614141358377\n",
      "train loss:0.0021776388314766132\n",
      "train loss:0.003872710901192244\n",
      "train loss:0.004086045901124284\n",
      "train loss:0.004362722463140816\n",
      "train loss:0.014473540912479245\n",
      "train loss:0.0013663517410639266\n",
      "train loss:0.005103467604836795\n",
      "train loss:0.0114274282356989\n",
      "train loss:0.003911260226813985\n",
      "train loss:0.001126757006402873\n",
      "train loss:0.0002156528516539236\n",
      "train loss:0.0023769119966290404\n",
      "train loss:0.0024042383663838694\n",
      "train loss:0.006499586350036398\n",
      "train loss:0.039404909241768545\n",
      "train loss:0.00048191245364881055\n",
      "train loss:0.007112622359428373\n",
      "train loss:0.004262996883204619\n",
      "train loss:0.00035034513105339725\n",
      "train loss:0.013221046815739167\n",
      "train loss:0.005144638132130957\n",
      "train loss:0.0002265874214555589\n",
      "train loss:0.0003714562773531279\n",
      "train loss:0.0011898044269439058\n",
      "train loss:0.004434237860950771\n",
      "train loss:0.0022575282156134845\n",
      "train loss:0.0012545047146107692\n",
      "train loss:0.0006630348607739484\n",
      "train loss:0.0009963414315970138\n",
      "train loss:0.0014753421622055113\n",
      "train loss:0.0002134205966406822\n",
      "train loss:0.0020379453678994806\n",
      "train loss:0.0010093176130442317\n",
      "train loss:0.013694975049197944\n",
      "train loss:0.0016999949102023079\n",
      "train loss:0.0008128832134028775\n",
      "train loss:0.0045391732440246\n",
      "train loss:0.0006761181795703608\n",
      "train loss:0.004369504786047683\n",
      "train loss:0.004238267710961939\n",
      "train loss:0.002154805718347875\n",
      "train loss:0.0034397448909316915\n",
      "train loss:0.002866728194105689\n",
      "train loss:0.0017538949211352802\n",
      "train loss:0.0060843657358426026\n",
      "train loss:0.0019012444925179822\n",
      "train loss:0.0019166454988523262\n",
      "train loss:0.0003989635560563735\n",
      "train loss:0.004663195461970021\n",
      "train loss:0.009712164632039343\n",
      "train loss:0.004964533094621424\n",
      "train loss:0.0026844466468951026\n",
      "train loss:0.010876376081383138\n",
      "train loss:0.0005610188856648246\n",
      "train loss:0.0012949251676527345\n",
      "train loss:0.01340459095979738\n",
      "train loss:0.0004891219579635616\n",
      "train loss:0.018955180990096073\n",
      "train loss:0.001395559960882162\n",
      "train loss:0.008569807885547747\n",
      "train loss:0.0037339407177766136\n",
      "train loss:0.0023639811355130546\n",
      "train loss:0.01956117439084534\n",
      "train loss:0.005618592727187383\n",
      "train loss:0.0031404352834085865\n",
      "train loss:0.0009084223253787735\n",
      "train loss:0.0003079776837669883\n",
      "train loss:0.0015070034328008653\n",
      "train loss:0.09840358621027638\n",
      "train loss:0.006080148903996436\n",
      "train loss:0.00016085897094995384\n",
      "train loss:0.003866726383579266\n",
      "train loss:0.0007761002169329531\n",
      "train loss:0.005448671305495914\n",
      "train loss:0.003636099082937893\n",
      "train loss:0.002450161936549145\n",
      "train loss:0.004881551828895029\n",
      "train loss:0.001954252737478143\n",
      "train loss:0.0015934426472216253\n",
      "train loss:0.0034830043842849667\n",
      "train loss:0.010706795611788939\n",
      "train loss:0.00048325881029551105\n",
      "train loss:0.006082311105061793\n",
      "train loss:0.0029025539779215077\n",
      "train loss:0.0017051428896165952\n",
      "train loss:0.0010235104508212994\n",
      "train loss:0.006077841306888001\n",
      "train loss:0.0014125852797129577\n",
      "train loss:0.00033472758769463763\n",
      "train loss:0.002364471431577414\n",
      "train loss:0.0044394968356429605\n",
      "train loss:0.0025490266098877213\n",
      "train loss:0.0022618208247316696\n",
      "train loss:0.09797553094380859\n",
      "train loss:0.0007341649781986186\n",
      "train loss:0.002942314557289521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0035716043472254215\n",
      "train loss:0.002056710842666275\n",
      "train loss:0.025638123999880923\n",
      "train loss:0.0013966912875809133\n",
      "train loss:0.00010793399780570901\n",
      "train loss:0.002032271819361702\n",
      "train loss:0.0006648560610141665\n",
      "train loss:0.0066106855899484\n",
      "train loss:0.0009746259660795186\n",
      "train loss:0.00015483593146146504\n",
      "train loss:0.0035523165376794073\n",
      "train loss:0.0160214890382996\n",
      "train loss:0.0014196643608795406\n",
      "train loss:0.0024004694519496\n",
      "train loss:0.0023771166375001294\n",
      "train loss:0.004144725414202513\n",
      "train loss:0.00030948880641808635\n",
      "train loss:0.007429416790661964\n",
      "train loss:0.045433312094561404\n",
      "train loss:0.01979719026096137\n",
      "train loss:0.0012867319684734307\n",
      "train loss:0.003589662802745637\n",
      "train loss:0.0024104232399408255\n",
      "train loss:0.0014387095321836446\n",
      "train loss:0.0018704772138050318\n",
      "train loss:0.0032780343874329416\n",
      "train loss:0.004910138877304463\n",
      "train loss:0.003915173103349159\n",
      "train loss:0.000912264852452242\n",
      "train loss:0.0028004787337683724\n",
      "train loss:0.008445657477221293\n",
      "train loss:0.005876622446439974\n",
      "train loss:0.0014089408244288392\n",
      "train loss:0.0017642456504939064\n",
      "train loss:0.010326643125260892\n",
      "train loss:0.005585015172737672\n",
      "train loss:0.02255628536191745\n",
      "train loss:0.0017950191843428762\n",
      "train loss:0.012267526958661528\n",
      "train loss:0.009580938769893927\n",
      "train loss:0.0014739697635181865\n",
      "train loss:0.0014085861854369601\n",
      "train loss:0.0018715101161338656\n",
      "train loss:0.000610491769234692\n",
      "train loss:0.0013704571625853092\n",
      "train loss:0.009182234455932279\n",
      "train loss:0.009236002933572726\n",
      "train loss:0.008564787417816131\n",
      "train loss:0.014798091147353556\n",
      "train loss:0.0013052679280102044\n",
      "train loss:0.0018377845851709237\n",
      "train loss:0.002414000539575348\n",
      "=== epoch:14, train acc:1.0, test acc:0.988 ===\n",
      "train loss:0.00516221703588301\n",
      "train loss:0.005105618654994653\n",
      "train loss:0.005275276819008889\n",
      "train loss:0.0028722191002646335\n",
      "train loss:0.0034699304086219284\n",
      "train loss:0.012956661529711859\n",
      "train loss:0.00032019662373935045\n",
      "train loss:0.046276448447368675\n",
      "train loss:0.0022068415641143826\n",
      "train loss:0.008548930922531232\n",
      "train loss:0.0038551100346072504\n",
      "train loss:0.004057709406417425\n",
      "train loss:0.00437016009393363\n",
      "train loss:0.0004311601526764596\n",
      "train loss:0.002634044833022048\n",
      "train loss:0.002510778558692254\n",
      "train loss:0.002363847841699469\n",
      "train loss:0.0006079404581618757\n",
      "train loss:0.004645923899374134\n",
      "train loss:0.0013107402975681684\n",
      "train loss:0.008390292178449778\n",
      "train loss:0.004726618471996727\n",
      "train loss:0.004164387411696704\n",
      "train loss:0.004079390004773645\n",
      "train loss:0.0017367074985410514\n",
      "train loss:0.0029305310433248837\n",
      "train loss:0.004763472251501894\n",
      "train loss:0.002308679290281062\n",
      "train loss:0.02120525581859031\n",
      "train loss:0.0019010884642274043\n",
      "train loss:0.0010786879535107459\n",
      "train loss:0.0019009536045700498\n",
      "train loss:0.003554361114917116\n",
      "train loss:0.002023493654307888\n",
      "train loss:0.01698403935588438\n",
      "train loss:0.008471667138806722\n",
      "train loss:0.0010405198866867886\n",
      "train loss:0.0002053055685911252\n",
      "train loss:0.005418435994281149\n",
      "train loss:0.002489555238770745\n",
      "train loss:0.002372964660130536\n",
      "train loss:0.0031912687688724567\n",
      "train loss:0.00015834020683789735\n",
      "train loss:0.005480700038330006\n",
      "train loss:0.008485000829880993\n",
      "train loss:0.015029632551794623\n",
      "train loss:0.004878570154025864\n",
      "train loss:0.0004824469487567093\n",
      "train loss:0.024344607466789153\n",
      "train loss:0.00811962581391354\n",
      "train loss:0.0007127222014295564\n",
      "train loss:0.004316217306008561\n",
      "train loss:0.0015825954481930118\n",
      "train loss:0.00417312781504329\n",
      "train loss:0.006494833159630534\n",
      "train loss:0.0016699622003169229\n",
      "train loss:0.0008595948287814285\n",
      "train loss:0.01133193718637324\n",
      "train loss:0.002653141339961563\n",
      "train loss:0.0371820877527384\n",
      "train loss:0.001016537181023641\n",
      "train loss:0.0009838504897655656\n",
      "train loss:0.0022134190793478277\n",
      "train loss:0.014686587473575333\n",
      "train loss:0.006814391009501917\n",
      "train loss:0.005989703154164889\n",
      "train loss:0.001730316501684548\n",
      "train loss:0.0008278529215981567\n",
      "train loss:0.0012166038268282852\n",
      "train loss:0.005285887764117219\n",
      "train loss:0.0005485780499598551\n",
      "train loss:0.003465676646805184\n",
      "train loss:0.0013615408630375614\n",
      "train loss:0.01921189808387594\n",
      "train loss:0.002284590072932411\n",
      "train loss:0.0006343488575688054\n",
      "train loss:0.002479276710541386\n",
      "train loss:0.004466237269779785\n",
      "train loss:0.0046369505349695295\n",
      "train loss:0.003431851126803664\n",
      "train loss:0.0010315004719969336\n",
      "train loss:0.020265354446641553\n",
      "train loss:0.0021733548748997466\n",
      "train loss:0.006567928855486052\n",
      "train loss:0.0012104464606935035\n",
      "train loss:0.0061467955418555474\n",
      "train loss:0.0018891218269342191\n",
      "train loss:0.0017573873172948204\n",
      "train loss:0.0038987048439777044\n",
      "train loss:0.003305872780200292\n",
      "train loss:0.007404873666206528\n",
      "train loss:0.00709834625180103\n",
      "train loss:0.001218128892516037\n",
      "train loss:0.004214003028034298\n",
      "train loss:0.0015472396086176116\n",
      "train loss:0.002423893881680815\n",
      "train loss:0.00213328847884863\n",
      "train loss:0.0002746413355303156\n",
      "train loss:0.008393826782489044\n",
      "train loss:0.0009122935457222225\n",
      "train loss:0.003192578801884271\n",
      "train loss:0.00017465491601956405\n",
      "train loss:0.0009662266038834096\n",
      "train loss:0.009096450746588016\n",
      "train loss:0.0005447223058421839\n",
      "train loss:0.007699269923680047\n",
      "train loss:0.0018120792215648473\n",
      "train loss:0.0018373235075808964\n",
      "train loss:0.011254701338333057\n",
      "train loss:0.004662754391553\n",
      "train loss:0.0016562981739382274\n",
      "train loss:0.0015626734254650337\n",
      "train loss:0.0019618394213417874\n",
      "train loss:0.0008653048098801751\n",
      "train loss:0.0016605330331204904\n",
      "train loss:0.004318361535594975\n",
      "train loss:5.6770544644736063e-05\n",
      "train loss:0.003022490046493072\n",
      "train loss:0.011583464609287872\n",
      "train loss:0.004718872124123953\n",
      "train loss:0.0024648435456684414\n",
      "train loss:0.005276539425323229\n",
      "train loss:0.0025480796755560447\n",
      "train loss:0.009245496656967311\n",
      "train loss:0.0016338250302511729\n",
      "train loss:0.00038181737696889046\n",
      "train loss:0.0013026771422351257\n",
      "train loss:0.006883538118682749\n",
      "train loss:0.0005937239562049736\n",
      "train loss:0.0002059131463785473\n",
      "train loss:0.001527573385712804\n",
      "train loss:0.002439655755114278\n",
      "train loss:0.0020810355677717916\n",
      "train loss:0.0016090207549095466\n",
      "train loss:0.006987348480584497\n",
      "train loss:0.0012675756814037459\n",
      "train loss:0.006241197567542454\n",
      "train loss:0.004585875920687486\n",
      "train loss:0.0005871587153205852\n",
      "train loss:0.0006933915449066018\n",
      "train loss:0.00025992367622563176\n",
      "train loss:0.0009078429073378075\n",
      "train loss:0.006894268155515947\n",
      "train loss:0.006003480983861473\n",
      "train loss:0.008835944973204907\n",
      "train loss:0.0018185475082455318\n",
      "train loss:0.00037618993052599336\n",
      "train loss:0.0033748443505844127\n",
      "train loss:0.0021415999370479753\n",
      "train loss:0.006048707721851609\n",
      "train loss:0.0011258964133090057\n",
      "train loss:0.0009424003034704215\n",
      "train loss:0.006096775074127433\n",
      "train loss:0.009560376309827886\n",
      "train loss:0.0005449869234982818\n",
      "train loss:0.0007438875715267294\n",
      "train loss:0.0006760915985921305\n",
      "train loss:0.0003839375590890222\n",
      "train loss:0.0021160950321565163\n",
      "train loss:0.003477467380422608\n",
      "train loss:0.0021952299353769703\n",
      "train loss:0.0023689122360950167\n",
      "train loss:0.004756162689988478\n",
      "train loss:0.008112907713903855\n",
      "train loss:0.00661906200862431\n",
      "train loss:0.0014276953317065824\n",
      "train loss:0.006609045943850849\n",
      "train loss:0.0007460794074050448\n",
      "train loss:0.004293384530214917\n",
      "train loss:0.02101147226186297\n",
      "train loss:0.002146754777466677\n",
      "train loss:0.0011891989685565646\n",
      "train loss:8.45423643004705e-05\n",
      "train loss:0.00048072569100037236\n",
      "train loss:0.00215522398494598\n",
      "train loss:0.004277999155931008\n",
      "train loss:0.0030952225173040806\n",
      "train loss:0.00018254010833142675\n",
      "train loss:0.0010183968346936351\n",
      "train loss:0.0018397924973493334\n",
      "train loss:0.0022926117644344835\n",
      "train loss:0.0006049059075301744\n",
      "train loss:0.008581306286631783\n",
      "train loss:0.0023498166331534366\n",
      "train loss:0.0020594031378287896\n",
      "train loss:0.0008766491892505039\n",
      "train loss:0.0018310994324322216\n",
      "train loss:0.005117443122565386\n",
      "train loss:0.005784558121209597\n",
      "train loss:0.0029086082329809414\n",
      "train loss:0.001939508849317901\n",
      "train loss:0.0016909205474161357\n",
      "train loss:0.004506891044809532\n",
      "train loss:0.0012109789035215789\n",
      "train loss:0.0015185485803479307\n",
      "train loss:0.0009742143060166054\n",
      "train loss:0.0012582437636946564\n",
      "train loss:0.0004755338918412531\n",
      "train loss:0.00025403137071467754\n",
      "train loss:0.0013177596914709514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008924193291044566\n",
      "train loss:0.005179783246980649\n",
      "train loss:0.0003393934145762004\n",
      "train loss:0.004190467997304138\n",
      "train loss:0.0005177028510019899\n",
      "train loss:0.0012681348411615959\n",
      "train loss:0.009269760155509035\n",
      "train loss:0.0022204120137151585\n",
      "train loss:0.0009494259265028522\n",
      "train loss:0.0002805899661065476\n",
      "train loss:0.0012898830945051653\n",
      "train loss:0.004512557989673927\n",
      "train loss:0.001971561600669058\n",
      "train loss:0.0021924797518546786\n",
      "train loss:0.0044829197488097374\n",
      "train loss:0.00041381067648996514\n",
      "train loss:0.0003210359581322629\n",
      "train loss:0.0013041748012845313\n",
      "train loss:0.004184289744805006\n",
      "train loss:0.006216856341160141\n",
      "train loss:0.00010854208239791678\n",
      "train loss:0.002115587343261551\n",
      "train loss:0.00033602877035071143\n",
      "train loss:0.0020603294681304837\n",
      "train loss:0.003290815401839856\n",
      "train loss:0.001470434069655234\n",
      "train loss:0.001978358955465291\n",
      "train loss:0.0018042584053194679\n",
      "train loss:0.0006733768999866748\n",
      "train loss:0.0016611872281699907\n",
      "train loss:0.001279936851186156\n",
      "train loss:0.0015689854773206435\n",
      "train loss:0.00612824463497581\n",
      "train loss:0.0066060204647505035\n",
      "train loss:0.005650467430473585\n",
      "train loss:0.001558512689803661\n",
      "train loss:0.0012911449271380657\n",
      "train loss:0.0017407983374742072\n",
      "train loss:0.0011012724673239722\n",
      "train loss:0.003190571789996246\n",
      "train loss:0.0002154618982948259\n",
      "train loss:0.0033149436195199318\n",
      "train loss:0.0015390576128987566\n",
      "train loss:0.03364713481568326\n",
      "train loss:0.0025425521398975666\n",
      "train loss:0.0008887024841700455\n",
      "train loss:0.00018363636368258412\n",
      "train loss:0.00015775268821120194\n",
      "train loss:0.0028066321395999803\n",
      "train loss:0.0031435085033429456\n",
      "train loss:0.0031478288416022493\n",
      "train loss:0.0020118582622937085\n",
      "train loss:0.002573211571403536\n",
      "train loss:0.0025374407953646667\n",
      "train loss:0.02494055472004324\n",
      "train loss:0.003041394429602478\n",
      "train loss:0.009431156533266325\n",
      "train loss:0.000939028217224925\n",
      "train loss:0.00090310775902072\n",
      "train loss:0.000604325920944029\n",
      "train loss:0.0005842907932941041\n",
      "train loss:0.007276473948876253\n",
      "train loss:0.0014885002113580587\n",
      "train loss:0.0040189808722685865\n",
      "train loss:0.00019789025473978297\n",
      "train loss:0.0007835849952300654\n",
      "train loss:0.000382597020382338\n",
      "train loss:0.03625756492716204\n",
      "train loss:0.005087864550909343\n",
      "train loss:0.02093055539038117\n",
      "train loss:0.004937566321631273\n",
      "train loss:0.0006169350515851039\n",
      "train loss:0.0026229120641994247\n",
      "train loss:0.015487465856060438\n",
      "train loss:0.0003701478364957437\n",
      "train loss:0.0005378543524104062\n",
      "train loss:0.0006065371440503564\n",
      "train loss:0.0011812525844276467\n",
      "train loss:0.0006672796754168624\n",
      "train loss:0.002536084474499196\n",
      "train loss:0.0022225774756367096\n",
      "train loss:0.0055839887323340396\n",
      "train loss:0.006415064330235928\n",
      "train loss:0.0010532913573571437\n",
      "train loss:0.0007452952336844259\n",
      "train loss:0.0004883972489855236\n",
      "train loss:0.03188172113481501\n",
      "train loss:0.0011901542325909154\n",
      "train loss:0.003979989126592486\n",
      "train loss:0.0012857461317161228\n",
      "train loss:0.001302933487745673\n",
      "train loss:0.014216778930043408\n",
      "train loss:0.002876710368588993\n",
      "train loss:0.0014385266970195995\n",
      "train loss:0.0024342411825011736\n",
      "train loss:0.0018352223891143651\n",
      "train loss:0.042247987661509584\n",
      "train loss:0.00917637526696068\n",
      "train loss:0.0033678356622207943\n",
      "train loss:0.004064211119681729\n",
      "train loss:0.0015346849418559252\n",
      "train loss:0.009849855511334864\n",
      "train loss:0.004040989806908148\n",
      "train loss:0.0037351521698387852\n",
      "train loss:0.0002070705110066139\n",
      "train loss:0.0004185960422732079\n",
      "train loss:0.0023986351485891164\n",
      "train loss:0.0017339425088084507\n",
      "train loss:0.005786435114337172\n",
      "train loss:0.001468938471373711\n",
      "train loss:0.0025842069987529574\n",
      "train loss:0.0003475043798612599\n",
      "train loss:0.00021791555844963208\n",
      "train loss:0.0014602934646693044\n",
      "train loss:0.002422804999993219\n",
      "train loss:0.00170763810698451\n",
      "train loss:0.0017522876165582844\n",
      "train loss:0.0005585104734788487\n",
      "train loss:0.0049771493027634325\n",
      "train loss:0.0038969338804147615\n",
      "train loss:0.00033977410962558226\n",
      "train loss:0.004580381609558339\n",
      "train loss:0.005415758598654223\n",
      "train loss:0.001964272063344978\n",
      "train loss:0.0011664272040319272\n",
      "train loss:0.0006437003572839404\n",
      "train loss:0.002310378660958461\n",
      "train loss:0.0008367243669753652\n",
      "train loss:0.0003541564066432125\n",
      "train loss:0.005959498800104506\n",
      "train loss:0.0009064964013962124\n",
      "train loss:0.004108491180661769\n",
      "train loss:0.004857382291927959\n",
      "train loss:0.002657455799097204\n",
      "train loss:0.002076410655310897\n",
      "train loss:9.249811692916769e-05\n",
      "train loss:0.004000599111155029\n",
      "train loss:0.0021981432259155134\n",
      "train loss:0.0010569888997539847\n",
      "train loss:0.0030891795616305464\n",
      "train loss:0.0004970684652186153\n",
      "train loss:0.0008902124719220167\n",
      "train loss:0.0041905944016055775\n",
      "train loss:0.0013869597548505843\n",
      "train loss:0.0011903367295429774\n",
      "train loss:0.002246087922079391\n",
      "train loss:0.0017290350064843435\n",
      "train loss:0.0021236557249678443\n",
      "train loss:0.00025455047264074884\n",
      "train loss:0.0026609272917853845\n",
      "train loss:0.0034488559983557672\n",
      "train loss:0.0032111242416791256\n",
      "train loss:0.0005922652486045254\n",
      "train loss:0.002667553582702123\n",
      "train loss:0.006127866325918032\n",
      "train loss:0.0007527472410852092\n",
      "train loss:0.0008365641752242423\n",
      "train loss:0.00585984627158608\n",
      "train loss:0.0012429027552026785\n",
      "train loss:0.0005669718413668352\n",
      "train loss:0.0012624690803259065\n",
      "train loss:0.0007534377009563312\n",
      "train loss:0.0001829137486926956\n",
      "train loss:0.0016522588492420406\n",
      "train loss:0.004702113436825707\n",
      "train loss:0.00024995432800696045\n",
      "train loss:0.0031189887414967764\n",
      "train loss:0.003817266270442224\n",
      "train loss:0.0035291851788180305\n",
      "train loss:0.0036622476121388873\n",
      "train loss:0.00034369531193553836\n",
      "train loss:0.00016682429934752573\n",
      "train loss:0.001431529904217226\n",
      "train loss:0.0025260771701134045\n",
      "train loss:0.0022547873339225422\n",
      "train loss:0.00014944979390347674\n",
      "train loss:0.0016740745210740483\n",
      "train loss:0.003480998889072009\n",
      "train loss:0.0004086118920970229\n",
      "train loss:0.0038327170253159614\n",
      "train loss:0.018327676874457622\n",
      "train loss:0.0015766668243468122\n",
      "train loss:0.00037739492667372617\n",
      "train loss:0.0018166526537135505\n",
      "train loss:0.006600680936268062\n",
      "train loss:0.0025102347369218674\n",
      "train loss:0.0014993830667506644\n",
      "train loss:0.0010626772107246623\n",
      "train loss:0.0014109672396058245\n",
      "train loss:0.0006050691957711118\n",
      "train loss:0.0009922549059783313\n",
      "train loss:0.0030363225422506035\n",
      "train loss:0.0009877657478914777\n",
      "train loss:0.0020497639200558696\n",
      "train loss:0.0009227836436899258\n",
      "train loss:0.001264235552335727\n",
      "train loss:0.000743829985285569\n",
      "train loss:0.004634194306307813\n",
      "train loss:0.0026791681684623907\n",
      "train loss:0.0003180914821090337\n",
      "train loss:0.0006297669550886304\n",
      "train loss:0.0015171945211774548\n",
      "train loss:0.00135485692873774\n",
      "train loss:0.0010286386331028788\n",
      "train loss:0.0005637910578049309\n",
      "train loss:0.0012343681224812962\n",
      "train loss:0.0011199485661526109\n",
      "train loss:0.0001792028342444114\n",
      "train loss:0.0025524639983936152\n",
      "train loss:0.0013164203316405163\n",
      "train loss:0.0024936128996892347\n",
      "train loss:0.0037403620973899664\n",
      "train loss:0.0028090864607135902\n",
      "train loss:1.9838872416821726e-05\n",
      "train loss:0.004186299267366073\n",
      "train loss:0.00027202020516846163\n",
      "train loss:0.00022200174011087582\n",
      "train loss:0.0005731498962197937\n",
      "train loss:0.0007380697119688087\n",
      "train loss:0.0008328919359084114\n",
      "train loss:0.0006670638106113125\n",
      "train loss:0.000666495382499557\n",
      "train loss:0.0025114178958414203\n",
      "train loss:0.0014137870650710977\n",
      "train loss:0.0020349843182541454\n",
      "train loss:0.008077749791909136\n",
      "train loss:0.0017748124537369909\n",
      "train loss:0.01315564530651629\n",
      "train loss:0.0025047795523266553\n",
      "train loss:0.0005800820478917024\n",
      "train loss:0.006586664517251408\n",
      "train loss:0.00028223889132708124\n",
      "train loss:0.016260212307180534\n",
      "train loss:0.0005063424456783898\n",
      "train loss:0.0031194993565462213\n",
      "train loss:0.004674586775755047\n",
      "train loss:0.0008301481520451197\n",
      "train loss:0.0005856827798173872\n",
      "train loss:0.0003001516710483492\n",
      "train loss:0.0007794819741672123\n",
      "train loss:0.001290002432210083\n",
      "train loss:0.0020439083126087493\n",
      "train loss:0.012061719466671929\n",
      "train loss:0.00020139809283470773\n",
      "train loss:0.0007641366496413785\n",
      "train loss:0.0021078230232582772\n",
      "train loss:0.007175079222996967\n",
      "train loss:0.021716444488043506\n",
      "train loss:0.0014398834122604982\n",
      "train loss:0.0018256880952252118\n",
      "train loss:0.0018889831332572244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006389490930787281\n",
      "train loss:0.001886548815049186\n",
      "train loss:0.002355914825406001\n",
      "train loss:0.0043317870077910145\n",
      "train loss:0.0013018463322090079\n",
      "train loss:0.001914335695573226\n",
      "train loss:0.004802307160177866\n",
      "train loss:0.0013810669794827818\n",
      "train loss:0.003013022353365172\n",
      "train loss:0.002248940839564116\n",
      "train loss:0.0011355564614559206\n",
      "train loss:0.003246058665530484\n",
      "train loss:0.005214382435994131\n",
      "train loss:0.0014306689733339752\n",
      "train loss:0.0007676983299072816\n",
      "train loss:0.010508278456457276\n",
      "train loss:0.003093107939417949\n",
      "train loss:0.00026964668259936523\n",
      "train loss:0.0029741774076007966\n",
      "train loss:0.0004857168756695475\n",
      "train loss:0.0024466468157864282\n",
      "train loss:0.0013861647082652154\n",
      "train loss:0.0010150095815049864\n",
      "train loss:0.007202358291013012\n",
      "train loss:0.0004014484936201026\n",
      "train loss:0.00032371717132784227\n",
      "train loss:0.00026450868160153584\n",
      "train loss:0.00044435161968369054\n",
      "train loss:0.001890974442839214\n",
      "train loss:0.020825693884132624\n",
      "train loss:0.0031779332913036166\n",
      "train loss:0.0011899604875527721\n",
      "train loss:0.004881497351442084\n",
      "train loss:0.00018824261348616037\n",
      "train loss:0.000541410817137501\n",
      "train loss:0.00044894990617915014\n",
      "train loss:0.003325742063094251\n",
      "train loss:0.00575092573884797\n",
      "train loss:0.00296275062015141\n",
      "train loss:0.00019608529908749707\n",
      "train loss:0.0016927152392352907\n",
      "train loss:0.014456460634550592\n",
      "train loss:0.010662483931714239\n",
      "train loss:0.0006851409953728882\n",
      "train loss:0.00039010842132652983\n",
      "train loss:0.0014620806482642046\n",
      "train loss:0.011923977567590525\n",
      "train loss:0.00019482378703424073\n",
      "train loss:0.004742863950872208\n",
      "train loss:0.0006660773393900131\n",
      "train loss:0.0015931571990242133\n",
      "train loss:0.0014389758099079206\n",
      "train loss:0.004093491131175981\n",
      "train loss:0.010423071650701197\n",
      "train loss:0.00030317680945517314\n",
      "train loss:0.0027965424152298747\n",
      "train loss:0.001294357330130908\n",
      "train loss:0.000640546520639212\n",
      "train loss:0.0002098178425241499\n",
      "train loss:0.0007999871959713329\n",
      "train loss:0.00020263182661479776\n",
      "train loss:0.0004158109533125689\n",
      "train loss:0.00026211279450921867\n",
      "train loss:0.0005071698919124621\n",
      "train loss:0.0011432240513650433\n",
      "train loss:0.0011506465171908556\n",
      "train loss:0.0030075287265296834\n",
      "train loss:0.0018681013420552008\n",
      "train loss:0.0012972507422449242\n",
      "train loss:0.0005342164175501011\n",
      "train loss:0.0006763786824615517\n",
      "train loss:0.0025728093676422497\n",
      "train loss:8.415795520590359e-05\n",
      "train loss:0.001930576821380545\n",
      "train loss:0.0012137915860371575\n",
      "train loss:0.0017318481318945194\n",
      "train loss:0.0008386578276441077\n",
      "train loss:0.0017878830974845535\n",
      "train loss:0.0011855365612506114\n",
      "train loss:0.001690517224388808\n",
      "train loss:0.0037070188045696785\n",
      "train loss:0.0007037827365535921\n",
      "train loss:0.001917830574856718\n",
      "train loss:0.0008644389769360883\n",
      "train loss:0.0024026933550989264\n",
      "train loss:0.020178835946930727\n",
      "train loss:0.0012553678106308824\n",
      "train loss:0.00018198520249032614\n",
      "train loss:0.0019171099043954287\n",
      "train loss:0.0006177946856605218\n",
      "train loss:0.0027615261047248024\n",
      "train loss:0.0018353988821174058\n",
      "train loss:0.0020474923045942094\n",
      "train loss:0.0016520417911405768\n",
      "train loss:0.004543707491272454\n",
      "train loss:0.0011816329699266225\n",
      "train loss:0.00458504320168409\n",
      "train loss:0.007084594388906502\n",
      "train loss:0.0006041339509643403\n",
      "train loss:0.03981459854804544\n",
      "train loss:0.0010069643727618064\n",
      "train loss:0.00012644195258573428\n",
      "train loss:0.0014265159514610017\n",
      "train loss:0.004744881009763529\n",
      "train loss:0.00018046017113928546\n",
      "train loss:0.002929035639888376\n",
      "train loss:0.00026393600543930974\n",
      "train loss:0.00018506192759812064\n",
      "train loss:0.0036175938140818095\n",
      "train loss:0.0019088277234376053\n",
      "train loss:0.00022102822000369865\n",
      "train loss:0.0008468004427252921\n",
      "train loss:0.002549331908990312\n",
      "train loss:0.001879216601451112\n",
      "train loss:0.003939779187357083\n",
      "train loss:0.00033096613837017543\n",
      "train loss:0.004135066614593913\n",
      "train loss:0.00020551470459382815\n",
      "train loss:0.0002769326266118962\n",
      "train loss:0.02078318104522497\n",
      "train loss:0.002064331933222885\n",
      "train loss:0.0011930940509272663\n",
      "train loss:0.001375725307809741\n",
      "train loss:0.0016656086566033661\n",
      "train loss:0.004229769299858824\n",
      "train loss:0.0035259186517764057\n",
      "train loss:0.001300111001672816\n",
      "train loss:0.000649642338513759\n",
      "train loss:0.0005547496507118733\n",
      "train loss:0.00047634444424838896\n",
      "train loss:0.0015836522632481566\n",
      "train loss:0.0009460072804729869\n",
      "train loss:0.004551150980423746\n",
      "train loss:0.0018028550368702398\n",
      "train loss:0.0025629570221587274\n",
      "train loss:0.00045907243597389846\n",
      "train loss:0.0012211451439866573\n",
      "train loss:0.00021485016787161263\n",
      "train loss:0.002230893519742434\n",
      "train loss:0.0033264026879451726\n",
      "train loss:0.0008285970875571544\n",
      "train loss:0.004564233338423342\n",
      "train loss:0.0009427859370388265\n",
      "train loss:0.0008462931410313801\n",
      "train loss:0.001991165706361069\n",
      "train loss:0.00526015703491632\n",
      "train loss:6.857780298920038e-05\n",
      "train loss:0.0002391039118046441\n",
      "train loss:0.00028352030473475734\n",
      "=== epoch:15, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0003223124018723731\n",
      "train loss:1.815404449315683e-05\n",
      "train loss:0.0013709155911687699\n",
      "train loss:0.00013684096635209066\n",
      "train loss:8.712057574424222e-05\n",
      "train loss:0.001935663127045407\n",
      "train loss:0.001254842799056037\n",
      "train loss:0.0020546764817168956\n",
      "train loss:0.00015416142707118976\n",
      "train loss:0.0006078666421377839\n",
      "train loss:0.002119511002210178\n",
      "train loss:0.00030800332545029307\n",
      "train loss:0.006065009143455251\n",
      "train loss:0.0010498338987640628\n",
      "train loss:0.0002288642006912367\n",
      "train loss:0.001154586287961535\n",
      "train loss:0.0009128930857102102\n",
      "train loss:0.004003259790075303\n",
      "train loss:0.0008030274232666531\n",
      "train loss:0.00311922686463426\n",
      "train loss:0.0008786512170554741\n",
      "train loss:0.00038612234670995586\n",
      "train loss:0.0002841929809626935\n",
      "train loss:0.002991169995679376\n",
      "train loss:0.0007471499148602542\n",
      "train loss:0.00046129047769615585\n",
      "train loss:0.0006243516266996092\n",
      "train loss:0.0023868441436586036\n",
      "train loss:0.00027719222685460053\n",
      "train loss:0.0043870204880324766\n",
      "train loss:0.00021527568348790529\n",
      "train loss:0.0001882213049329054\n",
      "train loss:0.0007651071971569594\n",
      "train loss:0.00014222141681540182\n",
      "train loss:0.0007243779125436674\n",
      "train loss:0.00015477867474193008\n",
      "train loss:0.003616381121654404\n",
      "train loss:0.0007278379300438555\n",
      "train loss:0.0053762781374029865\n",
      "train loss:0.0010290105917917997\n",
      "train loss:0.030826072131226193\n",
      "train loss:0.0019482409418613\n",
      "train loss:0.0009462443406037072\n",
      "train loss:0.006877076559634368\n",
      "train loss:0.0016025319793634358\n",
      "train loss:0.0024102382524977006\n",
      "train loss:0.0021757054904512556\n",
      "train loss:0.0020679394381789896\n",
      "train loss:0.0004319100403011339\n",
      "train loss:0.00021342691018676378\n",
      "train loss:0.00123847092755782\n",
      "train loss:0.0012215591484214543\n",
      "train loss:0.00616049394332059\n",
      "train loss:0.0023923385304145135\n",
      "train loss:0.007572984934278165\n",
      "train loss:0.002446279082318017\n",
      "train loss:0.0014292104888902334\n",
      "train loss:0.0007138264030700165\n",
      "train loss:9.78883692777248e-05\n",
      "train loss:0.0009818695716511945\n",
      "train loss:0.0002947950964028641\n",
      "train loss:0.02089966476977599\n",
      "train loss:0.0004993672545787041\n",
      "train loss:0.0005291242822477976\n",
      "train loss:0.0006400194089363377\n",
      "train loss:0.007787066366036606\n",
      "train loss:0.0007160480822746576\n",
      "train loss:0.02430418095510447\n",
      "train loss:0.0038203630927753063\n",
      "train loss:0.00018875524401357517\n",
      "train loss:0.007656392079382957\n",
      "train loss:0.0005656196348129455\n",
      "train loss:0.000736631129585404\n",
      "train loss:0.002017826927488289\n",
      "train loss:0.006068608456174951\n",
      "train loss:0.0005893359815566792\n",
      "train loss:9.608626410926057e-05\n",
      "train loss:0.002750157021555827\n",
      "train loss:0.006039397717832967\n",
      "train loss:0.0025527833221592787\n",
      "train loss:0.0017728403407081136\n",
      "train loss:8.687740396485328e-05\n",
      "train loss:0.0011926514274585459\n",
      "train loss:0.005666692075178348\n",
      "train loss:0.009733367110237937\n",
      "train loss:0.001522955283586477\n",
      "train loss:0.002472557118235857\n",
      "train loss:0.0020542729573140572\n",
      "train loss:0.003084355817205933\n",
      "train loss:0.0005513431021915606\n",
      "train loss:0.0007933095104485414\n",
      "train loss:0.0010944382515747204\n",
      "train loss:0.0005958373942103732\n",
      "train loss:0.004989112796643149\n",
      "train loss:0.006890009765244625\n",
      "train loss:0.0009743452333494069\n",
      "train loss:0.0020178388851620215\n",
      "train loss:0.0011105012353613268\n",
      "train loss:0.005513474907379445\n",
      "train loss:0.0006687960261544291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06565640209370147\n",
      "train loss:0.0021438147060268598\n",
      "train loss:0.004724068892838304\n",
      "train loss:0.0008972609920344507\n",
      "train loss:0.0006618266681170924\n",
      "train loss:0.00054104546315299\n",
      "train loss:0.0058059217792859365\n",
      "train loss:0.0009857442549780892\n",
      "train loss:0.0006319370696998238\n",
      "train loss:0.0002707537849174723\n",
      "train loss:0.004111385025203987\n",
      "train loss:0.0006940258267781031\n",
      "train loss:0.004374673878993844\n",
      "train loss:0.0002692189582886698\n",
      "train loss:0.0006640164395553369\n",
      "train loss:0.0031763536508082222\n",
      "train loss:0.005506114633883837\n",
      "train loss:0.0011754157557560276\n",
      "train loss:0.0026536446828323867\n",
      "train loss:0.009908608899755218\n",
      "train loss:0.0008298125103741493\n",
      "train loss:0.05649313639951495\n",
      "train loss:0.0010326330876928543\n",
      "train loss:0.0009531268770055906\n",
      "train loss:0.0008249126385802412\n",
      "train loss:0.0022727054566264323\n",
      "train loss:0.0022304908473881517\n",
      "train loss:0.026212286971025\n",
      "train loss:0.0030052964672909765\n",
      "train loss:0.00028561279911976567\n",
      "train loss:0.0016701078743070323\n",
      "train loss:0.001164062713228803\n",
      "train loss:0.0011059673283350642\n",
      "train loss:0.0013643839918447572\n",
      "train loss:0.00272767385621558\n",
      "train loss:0.002291245197515443\n",
      "train loss:0.0015155256970286655\n",
      "train loss:0.00043463928244405264\n",
      "train loss:0.002868606174359423\n",
      "train loss:0.001596792245291709\n",
      "train loss:0.002526687714487259\n",
      "train loss:0.0009952202975716759\n",
      "train loss:0.0013306521839257356\n",
      "train loss:0.005211320213835277\n",
      "train loss:0.0018842966997933894\n",
      "train loss:0.006282379571628371\n",
      "train loss:0.00042411674949341095\n",
      "train loss:0.0003215521482446116\n",
      "train loss:0.0018061767558518816\n",
      "train loss:0.0047697494284305465\n",
      "train loss:0.000997094229763812\n",
      "train loss:0.001315281441736878\n",
      "train loss:0.0024006152547281783\n",
      "train loss:0.0022110719331229415\n",
      "train loss:0.0005141318741819773\n",
      "train loss:0.00302618732252739\n",
      "train loss:0.00018979032344568886\n",
      "train loss:0.003744953749895137\n",
      "train loss:0.010393833081872134\n",
      "train loss:0.00021001104201887443\n",
      "train loss:0.0011208715707745178\n",
      "train loss:0.0016790530365748861\n",
      "train loss:0.002060313912024314\n",
      "train loss:0.000510772713675008\n",
      "train loss:0.0023847490963793245\n",
      "train loss:0.022879782474659095\n",
      "train loss:0.0016336404102997126\n",
      "train loss:0.0018194253721889068\n",
      "train loss:0.00025483483879571117\n",
      "train loss:0.000727154698632027\n",
      "train loss:0.0006527796707079757\n",
      "train loss:0.007407906942410642\n",
      "train loss:0.07578336017762773\n",
      "train loss:0.001086205326607981\n",
      "train loss:0.04403632816598127\n",
      "train loss:0.0010293834824537656\n",
      "train loss:0.0022283080998994147\n",
      "train loss:0.0034303968926196306\n",
      "train loss:0.0009636839355869396\n",
      "train loss:0.0021417498514995736\n",
      "train loss:0.00035320038240201903\n",
      "train loss:0.0018170225558843639\n",
      "train loss:0.002803720732338029\n",
      "train loss:0.0014012440626721087\n",
      "train loss:0.0003946919081224539\n",
      "train loss:0.0014217480365701233\n",
      "train loss:0.011035036284022923\n",
      "train loss:0.0023199139605744813\n",
      "train loss:0.002929907932106697\n",
      "train loss:0.008559867240048584\n",
      "train loss:0.0016234126184646502\n",
      "train loss:0.026283196644705114\n",
      "train loss:0.0024491837244044337\n",
      "train loss:0.00033368834118569066\n",
      "train loss:0.00042724947181527575\n",
      "train loss:0.00026082725972377123\n",
      "train loss:0.00036734068892022996\n",
      "train loss:0.004752327165212978\n",
      "train loss:0.060831354139751825\n",
      "train loss:0.0032227710070766536\n",
      "train loss:0.0003763471808728808\n",
      "train loss:0.000570977225542762\n",
      "train loss:0.001560497304835156\n",
      "train loss:7.623695352770456e-05\n",
      "train loss:0.004484595486174086\n",
      "train loss:0.003114444019246543\n",
      "train loss:0.0012642592178143384\n",
      "train loss:0.0003901038688673228\n",
      "train loss:0.0013943412758454466\n",
      "train loss:0.002063064682178602\n",
      "train loss:0.0013060221046624005\n",
      "train loss:0.058952015629285814\n",
      "train loss:0.002917334333132856\n",
      "train loss:0.0011848398173571412\n",
      "train loss:0.0017338989669725717\n",
      "train loss:0.020689217205690443\n",
      "train loss:0.00047475046947584255\n",
      "train loss:0.00548038252766082\n",
      "train loss:0.0019617263012132154\n",
      "train loss:0.0008906229723740084\n",
      "train loss:0.0007283156077780033\n",
      "train loss:0.0015598527017553685\n",
      "train loss:0.005194690680882843\n",
      "train loss:0.0015957466935671621\n",
      "train loss:0.0003129988582056688\n",
      "train loss:0.0016661609829485967\n",
      "train loss:0.0013700019246951974\n",
      "train loss:0.0001342430919729111\n",
      "train loss:0.0006215787076904342\n",
      "train loss:0.014383242824405633\n",
      "train loss:0.0016369054569699915\n",
      "train loss:0.00029687829392229664\n",
      "train loss:0.0018658806315928252\n",
      "train loss:0.0012492946413450127\n",
      "train loss:0.0006247363670991622\n",
      "train loss:0.00048612343861474775\n",
      "train loss:0.005928580692515375\n",
      "train loss:0.003827055870818278\n",
      "train loss:0.0005690576855213646\n",
      "train loss:0.0016677185554162502\n",
      "train loss:0.0022009172908874926\n",
      "train loss:0.0014628901953779487\n",
      "train loss:0.004451551151012023\n",
      "train loss:0.0027897227003827363\n",
      "train loss:0.007998416926960345\n",
      "train loss:0.0031686283704949075\n",
      "train loss:0.006322679301932511\n",
      "train loss:0.004657051864237414\n",
      "train loss:0.004709497377140142\n",
      "train loss:0.001381895641576195\n",
      "train loss:0.004576669359595134\n",
      "train loss:0.013895238229253766\n",
      "train loss:0.0014072326549151367\n",
      "train loss:0.002307278578702504\n",
      "train loss:0.0040227086743831065\n",
      "train loss:0.004379536661561762\n",
      "train loss:0.005635512694553209\n",
      "train loss:0.00014630173443874048\n",
      "train loss:0.006531078382825203\n",
      "train loss:0.0008815178217190516\n",
      "train loss:0.0002065171107628082\n",
      "train loss:0.003877081905815856\n",
      "train loss:0.002282376014252405\n",
      "train loss:0.005341961194779861\n",
      "train loss:0.003079823625569965\n",
      "train loss:0.004761274338855425\n",
      "train loss:0.0033374168114865934\n",
      "train loss:0.0013973688319779962\n",
      "train loss:0.0007793939722985327\n",
      "train loss:0.05558847848843787\n",
      "train loss:0.0017766219838283499\n",
      "train loss:0.0006586798409710705\n",
      "train loss:0.0008338214362037209\n",
      "train loss:0.0032429328866160024\n",
      "train loss:0.003853018568320384\n",
      "train loss:0.004371854369305785\n",
      "train loss:0.00015809490791757994\n",
      "train loss:0.0029706457527527504\n",
      "train loss:0.0033982975733883986\n",
      "train loss:0.002970954994769198\n",
      "train loss:0.0005774096858300942\n",
      "train loss:0.0010953209490781226\n",
      "train loss:0.001331365783113585\n",
      "train loss:0.00010438489522032243\n",
      "train loss:0.000623100303340905\n",
      "train loss:0.0013882037363127481\n",
      "train loss:0.01218295102498763\n",
      "train loss:0.006036548430846294\n",
      "train loss:0.002107469748552168\n",
      "train loss:0.0005198889050770546\n",
      "train loss:0.009359938978069818\n",
      "train loss:0.0024014829664997977\n",
      "train loss:0.0008762050257878927\n",
      "train loss:0.005199770031670152\n",
      "train loss:0.005062773911673133\n",
      "train loss:0.005463780948346487\n",
      "train loss:0.0030830018789995066\n",
      "train loss:0.006986455895227312\n",
      "train loss:0.004022962671380927\n",
      "train loss:0.00036109636987147447\n",
      "train loss:0.003104123199107637\n",
      "train loss:0.012556295261297723\n",
      "train loss:0.0036077283343638423\n",
      "train loss:0.009390137230816319\n",
      "train loss:0.0018458319331088866\n",
      "train loss:0.009195517306759033\n",
      "train loss:0.00046060821570506117\n",
      "train loss:0.002730683365489329\n",
      "train loss:0.00228069348950214\n",
      "train loss:0.002207987900508617\n",
      "train loss:0.0010041536331467156\n",
      "train loss:0.00024639353328200343\n",
      "train loss:0.002857479030761753\n",
      "train loss:0.007297306086185091\n",
      "train loss:0.0024946075880461667\n",
      "train loss:0.0007470116434089975\n",
      "train loss:0.0002796074227119307\n",
      "train loss:0.0005634540962456368\n",
      "train loss:0.0016090108284750784\n",
      "train loss:0.004299363847075942\n",
      "train loss:0.0068551472395884305\n",
      "train loss:0.0010858153100941712\n",
      "train loss:0.0030091260244616397\n",
      "train loss:0.00227583014629903\n",
      "train loss:0.0005884199401370048\n",
      "train loss:0.003854828902152817\n",
      "train loss:0.0003179529559235653\n",
      "train loss:0.00024464515085063443\n",
      "train loss:0.0007358260584901368\n",
      "train loss:0.019978423271113287\n",
      "train loss:0.0008394656653785301\n",
      "train loss:0.0041974521457795256\n",
      "train loss:0.0024497762769378657\n",
      "train loss:0.00015272536365468523\n",
      "train loss:0.015228903400120276\n",
      "train loss:0.003810147332180464\n",
      "train loss:0.004663501972292577\n",
      "train loss:0.0006158519788494922\n",
      "train loss:0.00797610571070964\n",
      "train loss:0.0013598289283771035\n",
      "train loss:0.004683769077997891\n",
      "train loss:0.0011355784858195451\n",
      "train loss:0.0018117631620527652\n",
      "train loss:0.0009099443914172021\n",
      "train loss:0.0032448074588882327\n",
      "train loss:0.0033850517384557497\n",
      "train loss:0.001010489139262654\n",
      "train loss:0.00023823155174931878\n",
      "train loss:0.00039537757574536293\n",
      "train loss:0.001594635869102624\n",
      "train loss:0.0005893755115828641\n",
      "train loss:0.0011726964813333135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005506474165127962\n",
      "train loss:0.003334198825901241\n",
      "train loss:0.0015669215211731135\n",
      "train loss:0.00024575981994197653\n",
      "train loss:0.00021017022436019793\n",
      "train loss:0.00024763400404551034\n",
      "train loss:0.002479907601364695\n",
      "train loss:0.0011090006129474998\n",
      "train loss:0.0017188106781669565\n",
      "train loss:0.0006746270094213387\n",
      "train loss:0.00018930839972633437\n",
      "train loss:0.0023021304607969252\n",
      "train loss:0.010635754332828174\n",
      "train loss:0.0007344866046823462\n",
      "train loss:0.001077560507970567\n",
      "train loss:0.0009026277179547083\n",
      "train loss:0.004649423276341529\n",
      "train loss:0.0007744228463935671\n",
      "train loss:0.0021065877185321557\n",
      "train loss:0.0019493058969214502\n",
      "train loss:0.0021341080133548806\n",
      "train loss:0.002842029326572749\n",
      "train loss:0.004844894799323551\n",
      "train loss:0.0007321909589015145\n",
      "train loss:0.0033559687995064224\n",
      "train loss:0.0015708877821802312\n",
      "train loss:0.0016379058834312032\n",
      "train loss:0.012414882529734241\n",
      "train loss:0.0013422083021544795\n",
      "train loss:0.00042786793985499636\n",
      "train loss:0.00030534116653148385\n",
      "train loss:0.0025442373015924853\n",
      "train loss:0.000381846235840219\n",
      "train loss:0.00048425967949625816\n",
      "train loss:0.0025465895209210894\n",
      "train loss:0.0006722404199138498\n",
      "train loss:0.00030276983253014035\n",
      "train loss:0.0009715807982874572\n",
      "train loss:0.003200514615910207\n",
      "train loss:0.004710302663007564\n",
      "train loss:0.014354278304783544\n",
      "train loss:0.02371928703973913\n",
      "train loss:0.00016305120327407357\n",
      "train loss:0.0012951037444820395\n",
      "train loss:0.03132651810078856\n",
      "train loss:0.0010782135699965887\n",
      "train loss:0.004411295095932638\n",
      "train loss:0.002788364575604615\n",
      "train loss:0.0007841826469416579\n",
      "train loss:0.0007989822383094474\n",
      "train loss:0.00041940314735949537\n",
      "train loss:0.0033215901386098295\n",
      "train loss:0.007654408036464068\n",
      "train loss:0.0034691109829472987\n",
      "train loss:0.0002769931631921835\n",
      "train loss:0.02173936290146388\n",
      "train loss:0.001139877650202577\n",
      "train loss:0.005267900926336704\n",
      "train loss:0.0003556247579769353\n",
      "train loss:0.00028854999533604533\n",
      "train loss:0.0004298317994073613\n",
      "train loss:0.0030289152339580943\n",
      "train loss:0.0008896831308109367\n",
      "train loss:0.00044398843995218295\n",
      "train loss:0.0011254212675280207\n",
      "train loss:0.0030054443133648813\n",
      "train loss:0.0015157322863594645\n",
      "train loss:0.00045145510753141007\n",
      "train loss:0.00222419408489512\n",
      "train loss:0.0014103657415198258\n",
      "train loss:0.009665634030362446\n",
      "train loss:0.0004060970409388916\n",
      "train loss:0.0016993385597847688\n",
      "train loss:0.00014705996499092671\n",
      "train loss:0.00043544392853010414\n",
      "train loss:0.0022363023495310273\n",
      "train loss:0.00036478604316696195\n",
      "train loss:0.0012430771870944267\n",
      "train loss:0.01040000347381777\n",
      "train loss:0.001905027914520416\n",
      "train loss:0.0010327857241522718\n",
      "train loss:0.004840278358279917\n",
      "train loss:0.001465992767188423\n",
      "train loss:0.0014458706125086579\n",
      "train loss:0.005745362019249384\n",
      "train loss:0.0012797512764159689\n",
      "train loss:0.0008359588383186091\n",
      "train loss:0.005606698886003857\n",
      "train loss:0.001623606352820668\n",
      "train loss:0.0009999422057272696\n",
      "train loss:0.0016285354218849636\n",
      "train loss:0.003617805117173732\n",
      "train loss:0.005856866012492122\n",
      "train loss:0.0007218191605632479\n",
      "train loss:0.0004414394843794617\n",
      "train loss:0.0006445576044195283\n",
      "train loss:0.004017444074364574\n",
      "train loss:0.016501632789008246\n",
      "train loss:0.006101293034007861\n",
      "train loss:0.00033129396752344073\n",
      "train loss:0.0023962098921322715\n",
      "train loss:0.0018253635618572643\n",
      "train loss:0.0008500473534764938\n",
      "train loss:0.0007526094892270406\n",
      "train loss:0.004369145997235816\n",
      "train loss:0.0003200289646553288\n",
      "train loss:0.00022308483391619228\n",
      "train loss:0.00025079763465380887\n",
      "train loss:0.0033435900640172217\n",
      "train loss:0.0021273417138742905\n",
      "train loss:0.0011364087162172287\n",
      "train loss:0.0039421419753089375\n",
      "train loss:0.0005695150707145421\n",
      "train loss:0.001593597832608429\n",
      "train loss:0.0005759727533834757\n",
      "train loss:0.002912407705417775\n",
      "train loss:0.001433735603865246\n",
      "train loss:0.0004091600879448423\n",
      "train loss:0.0007435070282811565\n",
      "train loss:0.0011291428107828752\n",
      "train loss:0.00013802617643729825\n",
      "train loss:0.01028945254640024\n",
      "train loss:0.0040942676113659236\n",
      "train loss:0.0002730271244100531\n",
      "train loss:0.0019828875719004914\n",
      "train loss:0.003933182167158932\n",
      "train loss:0.0009408207000575807\n",
      "train loss:0.0028038066602141844\n",
      "train loss:0.000805187064171071\n",
      "train loss:0.002492874274917591\n",
      "train loss:0.002830538154844492\n",
      "train loss:0.002257720493160946\n",
      "train loss:0.0013504691333606844\n",
      "train loss:0.0006125881200801511\n",
      "train loss:0.002258941952522276\n",
      "train loss:0.011432197701494128\n",
      "train loss:0.0007689606047632847\n",
      "train loss:0.001470407942718773\n",
      "train loss:0.0008876378890224655\n",
      "train loss:0.0017627290176462202\n",
      "train loss:0.0029626811018932026\n",
      "train loss:0.001995907493510313\n",
      "train loss:0.0039448828207775104\n",
      "train loss:0.0018704009286708851\n",
      "train loss:0.017578792690873205\n",
      "train loss:0.002681238705408769\n",
      "train loss:0.0012460649432221003\n",
      "train loss:0.0007150924431963441\n",
      "train loss:0.003343962602565517\n",
      "train loss:0.005689608675001745\n",
      "train loss:0.000737044679592984\n",
      "train loss:0.002954428025271181\n",
      "train loss:0.0024046748849404077\n",
      "train loss:0.0059214237152115864\n",
      "train loss:0.009204185586085004\n",
      "train loss:0.007201242559945992\n",
      "train loss:0.0015412366620336385\n",
      "train loss:0.00025628915458127203\n",
      "train loss:0.000643129566267844\n",
      "train loss:0.0008871338976046653\n",
      "train loss:0.0009652338102793197\n",
      "train loss:0.0001214546265851256\n",
      "train loss:0.0001904450923955427\n",
      "train loss:0.0009215866377378245\n",
      "train loss:0.0011007287746423067\n",
      "train loss:0.003634549567961135\n",
      "train loss:0.004628797705581203\n",
      "train loss:0.00032736287689704607\n",
      "train loss:0.0032045181352075847\n",
      "train loss:0.0025947543187880874\n",
      "train loss:0.0003145446577704137\n",
      "train loss:0.008334881835421847\n",
      "train loss:0.001840588018199356\n",
      "train loss:0.001643366556796295\n",
      "train loss:0.001909079613154188\n",
      "train loss:0.0006157988674488139\n",
      "train loss:0.006971285750724924\n",
      "train loss:0.0007570818785406541\n",
      "train loss:0.001585793141888265\n",
      "train loss:0.0002488536604433813\n",
      "train loss:0.0006727456819639345\n",
      "train loss:0.008199112112765026\n",
      "train loss:0.00910967913894072\n",
      "train loss:0.005734225228957734\n",
      "train loss:0.0005465219331395561\n",
      "train loss:0.001448661829723646\n",
      "train loss:0.0024701503767507772\n",
      "train loss:0.009155750828180839\n",
      "train loss:0.00035902607004113877\n",
      "train loss:0.0031826358313843837\n",
      "train loss:0.002060357420090328\n",
      "train loss:0.0003249452260483847\n",
      "train loss:0.0001920132938690171\n",
      "train loss:0.0027179439378052705\n",
      "train loss:0.0023471232204439808\n",
      "train loss:0.0008343495088568858\n",
      "train loss:0.0021758492294237305\n",
      "train loss:0.0001208123482760197\n",
      "train loss:0.0009621816456211605\n",
      "train loss:0.0006337253821270153\n",
      "train loss:0.0011192026094388975\n",
      "train loss:0.000338487052555536\n",
      "train loss:0.010183354585945513\n",
      "train loss:0.0005941120882205975\n",
      "train loss:0.0014354570592222623\n",
      "train loss:0.00869528641672099\n",
      "train loss:0.00020631554259679114\n",
      "train loss:0.002828294538213585\n",
      "train loss:0.004697421837693329\n",
      "train loss:0.004276362079032811\n",
      "train loss:0.0006143537027245647\n",
      "train loss:0.0031622139797656155\n",
      "train loss:0.0002518734144236574\n",
      "train loss:0.0006265152371541195\n",
      "train loss:0.001386119215439935\n",
      "train loss:0.00017591710197975907\n",
      "train loss:0.0003243771055804597\n",
      "train loss:0.010981396831980177\n",
      "train loss:0.00089740124616145\n",
      "train loss:0.003967676052826474\n",
      "train loss:0.00011046211660633928\n",
      "train loss:0.0010538786471500374\n",
      "train loss:0.0007283286885466718\n",
      "train loss:0.00030296433253898633\n",
      "train loss:0.007422764896835169\n",
      "train loss:0.0054067543437539105\n",
      "train loss:0.00040158305273702987\n",
      "train loss:0.0010068610835279746\n",
      "train loss:0.002899076900846576\n",
      "train loss:0.0008209442907931217\n",
      "train loss:0.0006658075681551078\n",
      "train loss:0.0006300524908629603\n",
      "train loss:0.001746332716021632\n",
      "train loss:0.0040028992347055665\n",
      "train loss:0.00042434616429355904\n",
      "train loss:0.06227682376806912\n",
      "train loss:0.002203661164394024\n",
      "train loss:0.0027639294288439686\n",
      "train loss:0.004597288820220195\n",
      "train loss:0.0015556465128658923\n",
      "train loss:0.00443240281016123\n",
      "train loss:0.001968427737833147\n",
      "train loss:0.0016729858905182996\n",
      "train loss:0.0006252480679661976\n",
      "train loss:0.009911275075530262\n",
      "train loss:0.0004289749472019199\n",
      "train loss:0.00398015049270665\n",
      "train loss:0.0008738105692964043\n",
      "=== epoch:16, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.00039223806761209083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00044295548224182577\n",
      "train loss:0.0013682603971832494\n",
      "train loss:0.0018138097526582395\n",
      "train loss:0.004196863301386527\n",
      "train loss:0.0011143576164189795\n",
      "train loss:0.0004640453782672353\n",
      "train loss:0.013242937028606166\n",
      "train loss:0.0039221092134904085\n",
      "train loss:0.007853519100152077\n",
      "train loss:0.0002713610320707253\n",
      "train loss:0.0028133688200828767\n",
      "train loss:0.002983420215408067\n",
      "train loss:0.0007961805186437093\n",
      "train loss:0.0013018482921544863\n",
      "train loss:0.0027380911484257992\n",
      "train loss:0.0016553491179519782\n",
      "train loss:0.001950567022125514\n",
      "train loss:0.0009530308524342913\n",
      "train loss:0.0006358373348200963\n",
      "train loss:0.001253560521636529\n",
      "train loss:0.0005472052358419877\n",
      "train loss:0.0005128666232704787\n",
      "train loss:0.003490760934747515\n",
      "train loss:0.009129570454585442\n",
      "train loss:0.001563750409264912\n",
      "train loss:0.00037682571873277117\n",
      "train loss:0.0013860270313732325\n",
      "train loss:0.002106637094141512\n",
      "train loss:0.0008255415426040646\n",
      "train loss:4.7581871322246224e-05\n",
      "train loss:0.006253706456425308\n",
      "train loss:0.003582176065412684\n",
      "train loss:0.003807536036441043\n",
      "train loss:0.0002634507430793073\n",
      "train loss:0.0028609342898925274\n",
      "train loss:0.0006258132484534592\n",
      "train loss:0.0027990696151347135\n",
      "train loss:0.00016507772069786062\n",
      "train loss:0.0012626428962313554\n",
      "train loss:0.005191466674275045\n",
      "train loss:0.0007145958787259976\n",
      "train loss:0.0018980458258596512\n",
      "train loss:0.00024056295061893203\n",
      "train loss:0.000460331698483254\n",
      "train loss:0.002746135010775282\n",
      "train loss:0.001509974748050392\n",
      "train loss:0.0035714954465007193\n",
      "train loss:0.0029469858797711856\n",
      "train loss:0.0007122922988072274\n",
      "train loss:0.007246564517256335\n",
      "train loss:0.0007597696787163661\n",
      "train loss:0.005807975016872729\n",
      "train loss:0.001616204280406362\n",
      "train loss:0.00012426483037087066\n",
      "train loss:0.0006422706105683206\n",
      "train loss:0.003931555852045904\n",
      "train loss:0.0020011839537169684\n",
      "train loss:0.021065517009238425\n",
      "train loss:5.43401622656988e-05\n",
      "train loss:0.0028797244686498136\n",
      "train loss:7.017971802282206e-05\n",
      "train loss:0.000854962287075883\n",
      "train loss:0.00361954533679618\n",
      "train loss:0.0005078998333453338\n",
      "train loss:0.006200176131463181\n",
      "train loss:0.0021834105742450987\n",
      "train loss:0.005866279965264812\n",
      "train loss:0.003918775558235605\n",
      "train loss:3.4421708041659145e-05\n",
      "train loss:0.00015857670262961894\n",
      "train loss:0.004923615528760948\n",
      "train loss:0.000840131258432453\n",
      "train loss:0.0022244414248917856\n",
      "train loss:0.003013250042527038\n",
      "train loss:0.013027485152473407\n",
      "train loss:0.0010950863049494738\n",
      "train loss:0.0005052376696554363\n",
      "train loss:0.0010045263073703069\n",
      "train loss:0.002957793743350604\n",
      "train loss:0.0014985045167507608\n",
      "train loss:0.00023543696669330722\n",
      "train loss:0.0012760648408675077\n",
      "train loss:0.0004004141316359948\n",
      "train loss:0.00040968759105852883\n",
      "train loss:0.0014594672127456923\n",
      "train loss:0.0006407050645213816\n",
      "train loss:0.005459717516772775\n",
      "train loss:0.009527362237940809\n",
      "train loss:0.0005649591243255607\n",
      "train loss:0.0010966681641416292\n",
      "train loss:7.826115753855912e-05\n",
      "train loss:0.004449472086445506\n",
      "train loss:0.004079518661327801\n",
      "train loss:0.007141798745080467\n",
      "train loss:0.005072883626801766\n",
      "train loss:0.00023248638032387584\n",
      "train loss:0.00025416921137423197\n",
      "train loss:0.0013617393953500104\n",
      "train loss:0.003024600624334693\n",
      "train loss:0.001538939765939567\n",
      "train loss:0.00037677755228521687\n",
      "train loss:0.004799441896201282\n",
      "train loss:4.1084658807012546e-05\n",
      "train loss:0.0020117461952258104\n",
      "train loss:0.0062131086207122994\n",
      "train loss:0.00027722871584800405\n",
      "train loss:0.0036555852733123908\n",
      "train loss:0.003513649536903418\n",
      "train loss:7.279249188596716e-05\n",
      "train loss:0.0014085217821700848\n",
      "train loss:0.004802082021673185\n",
      "train loss:0.002985162113491173\n",
      "train loss:0.003959908526315877\n",
      "train loss:0.03607689340966478\n",
      "train loss:0.003072352072868611\n",
      "train loss:0.0009908816498881963\n",
      "train loss:0.001165409317025203\n",
      "train loss:0.000683161711215126\n",
      "train loss:0.0007054962379131802\n",
      "train loss:0.0005719963789571325\n",
      "train loss:0.001251599929962404\n",
      "train loss:0.0007626003272583347\n",
      "train loss:0.007404375894554997\n",
      "train loss:0.0012903399438184682\n",
      "train loss:0.0020732903896107575\n",
      "train loss:0.05397560502966051\n",
      "train loss:0.0010556093258049122\n",
      "train loss:0.004398490876391189\n",
      "train loss:0.000152736324191515\n",
      "train loss:0.0015117368455955277\n",
      "train loss:0.0002360217223270869\n",
      "train loss:0.0011288950086920976\n",
      "train loss:0.0015753532223066336\n",
      "train loss:0.003953344853204724\n",
      "train loss:0.0007196856924160447\n",
      "train loss:0.0005517160045115966\n",
      "train loss:0.011097100195763867\n",
      "train loss:0.0005120223140102601\n",
      "train loss:0.00029960128046033327\n",
      "train loss:0.0037392271381665155\n",
      "train loss:0.00017239791476076924\n",
      "train loss:0.0009546512109281445\n",
      "train loss:0.0010037833632637336\n",
      "train loss:0.0029204513687026133\n",
      "train loss:0.00855776168697334\n",
      "train loss:0.007005096518087138\n",
      "train loss:0.0007568972795403152\n",
      "train loss:4.5821069021563564e-05\n",
      "train loss:0.003302760130097792\n",
      "train loss:0.006227153780515202\n",
      "train loss:0.00024594897475966037\n",
      "train loss:0.002841286322618784\n",
      "train loss:0.001792325066186622\n",
      "train loss:0.0005392729631207447\n",
      "train loss:0.0005517512435119437\n",
      "train loss:0.0002764642674859305\n",
      "train loss:0.0005651784175794094\n",
      "train loss:0.005587539250970111\n",
      "train loss:0.0005814654074692214\n",
      "train loss:0.0004874254455206289\n",
      "train loss:0.002095305844641132\n",
      "train loss:0.004821525878782434\n",
      "train loss:0.0009050123852579788\n",
      "train loss:0.003960790143737161\n",
      "train loss:0.00037619110482522684\n",
      "train loss:0.0003668606608363\n",
      "train loss:0.0017459549815654358\n",
      "train loss:0.00035132991995532036\n",
      "train loss:2.6865165718757833e-05\n",
      "train loss:0.00045586652996881664\n",
      "train loss:0.0005612513724812382\n",
      "train loss:0.00015609598947030956\n",
      "train loss:0.00010565978812885118\n",
      "train loss:0.0005979450278784516\n",
      "train loss:0.0003027742036277497\n",
      "train loss:0.0003080226517111893\n",
      "train loss:0.002010964115606827\n",
      "train loss:0.00020328890505824738\n",
      "train loss:0.0008446595263455278\n",
      "train loss:0.0004670606504696103\n",
      "train loss:0.0004297435054461483\n",
      "train loss:0.0017012252041341213\n",
      "train loss:0.0007124799013122297\n",
      "train loss:0.015332130522316684\n",
      "train loss:0.00205250366996123\n",
      "train loss:0.0003029026537080246\n",
      "train loss:0.0003149292096651312\n",
      "train loss:0.00039886309069981155\n",
      "train loss:0.0005241189427678216\n",
      "train loss:0.0020104981459851856\n",
      "train loss:0.0006558134015070827\n",
      "train loss:0.002170667617825494\n",
      "train loss:0.00031486188672314895\n",
      "train loss:0.003000517513266192\n",
      "train loss:0.0005050937713584619\n",
      "train loss:0.0006408210302141104\n",
      "train loss:0.03345905634885338\n",
      "train loss:0.0010549983585949484\n",
      "train loss:0.0003001097949604616\n",
      "train loss:0.0007471396192093438\n",
      "train loss:0.001983061813727664\n",
      "train loss:0.0018125308301823293\n",
      "train loss:0.00018986872287864862\n",
      "train loss:0.0008027001742452477\n",
      "train loss:0.0007371303392673945\n",
      "train loss:0.0032786798250031023\n",
      "train loss:0.0022891322596930628\n",
      "train loss:0.0034935099565348406\n",
      "train loss:0.001295517484903337\n",
      "train loss:0.00043127921274100034\n",
      "train loss:0.0017189832287214976\n",
      "train loss:0.0010131601172901703\n",
      "train loss:0.003515258713024977\n",
      "train loss:0.0001835252696365583\n",
      "train loss:0.0005050515791208461\n",
      "train loss:0.001077024042475587\n",
      "train loss:0.002314810762990492\n",
      "train loss:0.0018636671165385434\n",
      "train loss:0.0023803520009283347\n",
      "train loss:0.0012128290163516376\n",
      "train loss:0.0005250683791943913\n",
      "train loss:0.003237611429406065\n",
      "train loss:0.0020509775651128908\n",
      "train loss:0.008119763801073203\n",
      "train loss:0.0005238226526962798\n",
      "train loss:0.0025072917384937475\n",
      "train loss:0.0006799259732393043\n",
      "train loss:0.00014297003153730965\n",
      "train loss:0.00020614854500825106\n",
      "train loss:0.00025397887266873445\n",
      "train loss:0.0004400966529056313\n",
      "train loss:0.0023575899726430496\n",
      "train loss:0.0037739344573948217\n",
      "train loss:0.001300944585490537\n",
      "train loss:0.001058372366314263\n",
      "train loss:0.0068076533126615905\n",
      "train loss:0.0031735697695981784\n",
      "train loss:0.0025545101418740306\n",
      "train loss:0.0008075857849570438\n",
      "train loss:0.002501709576692483\n",
      "train loss:0.00020977352467881056\n",
      "train loss:0.0009062337736586795\n",
      "train loss:0.0012031255812008947\n",
      "train loss:0.002711109696909821\n",
      "train loss:0.001551343689584414\n",
      "train loss:0.00026854102498046487\n",
      "train loss:0.0012532924030875022\n",
      "train loss:0.00021172360789136477\n",
      "train loss:0.0003303682873969215\n",
      "train loss:0.0009529601073784288\n",
      "train loss:0.0017542193073459317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00029901476171461045\n",
      "train loss:0.000399230452494055\n",
      "train loss:0.0008598500487062943\n",
      "train loss:0.0007425928303385278\n",
      "train loss:0.00015427927586884465\n",
      "train loss:0.0011605882636494113\n",
      "train loss:0.0005995762674915684\n",
      "train loss:0.00038434687041028593\n",
      "train loss:0.0035311081409128446\n",
      "train loss:0.0036098126635470745\n",
      "train loss:2.3702015814303014e-05\n",
      "train loss:0.0008822963220100513\n",
      "train loss:0.00018712305139792956\n",
      "train loss:0.0007176813741287416\n",
      "train loss:0.004373806947122645\n",
      "train loss:0.0024647218440186185\n",
      "train loss:0.0030803576630162423\n",
      "train loss:0.00022921769053347866\n",
      "train loss:0.004600588995138993\n",
      "train loss:0.00354899645328426\n",
      "train loss:0.0002511383742397302\n",
      "train loss:0.006945122617724002\n",
      "train loss:0.0017733797504204793\n",
      "train loss:0.008776182774188868\n",
      "train loss:0.0015105497340404592\n",
      "train loss:0.0011132099529354426\n",
      "train loss:0.0004538068147859266\n",
      "train loss:0.006765033996317271\n",
      "train loss:0.00879445675483879\n",
      "train loss:0.0006169941922164523\n",
      "train loss:0.0014021283026020494\n",
      "train loss:0.0026387522052686474\n",
      "train loss:0.0003608605032090577\n",
      "train loss:0.002793020498935551\n",
      "train loss:0.0030347245266079837\n",
      "train loss:0.0025965549156293827\n",
      "train loss:0.0006041035881996141\n",
      "train loss:0.0057746894227266145\n",
      "train loss:0.002892761418237648\n",
      "train loss:0.0002394835644675819\n",
      "train loss:0.0003910724906675278\n",
      "train loss:0.0016916919811217602\n",
      "train loss:0.00024238742262814816\n",
      "train loss:0.0010583381835246614\n",
      "train loss:0.0022290495259032557\n",
      "train loss:0.00025320130704819307\n",
      "train loss:0.0022207297297256144\n",
      "train loss:0.00015971632475702044\n",
      "train loss:0.0018829252052472523\n",
      "train loss:0.0002043545061411546\n",
      "train loss:0.0014467848504247204\n",
      "train loss:0.00030417218409521484\n",
      "train loss:0.0010855246107564862\n",
      "train loss:0.0033674106762395413\n",
      "train loss:0.00043857345881026256\n",
      "train loss:0.0037395057724556786\n",
      "train loss:0.0005612577503099257\n",
      "train loss:0.0033946307636740815\n",
      "train loss:0.0026818230655218838\n",
      "train loss:0.0011496633415156083\n",
      "train loss:0.0033791238473958535\n",
      "train loss:0.0017549310175950608\n",
      "train loss:0.000394607774117659\n",
      "train loss:0.0003090319892145017\n",
      "train loss:6.360499638136664e-05\n",
      "train loss:0.003038296899913348\n",
      "train loss:7.35384818781232e-05\n",
      "train loss:0.002478431101050335\n",
      "train loss:0.0012588044462500906\n",
      "train loss:0.000518702291247866\n",
      "train loss:0.003873723740036072\n",
      "train loss:0.0034240452716444818\n",
      "train loss:0.0010726846174621053\n",
      "train loss:0.00010961453648204039\n",
      "train loss:0.00027135739240825054\n",
      "train loss:0.0002050802256938744\n",
      "train loss:0.0009993615683607478\n",
      "train loss:0.0008356974537348995\n",
      "train loss:0.0012058874177227972\n",
      "train loss:0.00032925021843945897\n",
      "train loss:0.00012627453397047572\n",
      "train loss:0.001586386429258222\n",
      "train loss:0.0030410574655212936\n",
      "train loss:0.0014192072114217241\n",
      "train loss:0.001085545128537036\n",
      "train loss:0.0017790779718628031\n",
      "train loss:0.0015954967009085969\n",
      "train loss:0.015608929872263345\n",
      "train loss:0.0011309217654379344\n",
      "train loss:0.0008991541146611151\n",
      "train loss:0.00047495308951785083\n",
      "train loss:0.0005882048749371574\n",
      "train loss:0.0008439379977424949\n",
      "train loss:0.001025943773224223\n",
      "train loss:0.0006491233707371086\n",
      "train loss:0.009427481632933494\n",
      "train loss:0.0030302373294237143\n",
      "train loss:0.0039472091296396585\n",
      "train loss:0.001700353926236237\n",
      "train loss:0.0004244010392939826\n",
      "train loss:0.0038765402447451915\n",
      "train loss:0.0003153415722980448\n",
      "train loss:0.001488089917179294\n",
      "train loss:0.0031489601988549504\n",
      "train loss:0.0003426738217623099\n",
      "train loss:0.00022734290608317939\n",
      "train loss:0.0012123386365554098\n",
      "train loss:0.003668349472931273\n",
      "train loss:0.0022671938352580635\n",
      "train loss:0.0017875583622476122\n",
      "train loss:0.0012438474397744937\n",
      "train loss:0.0009462425029727541\n",
      "train loss:0.01687817506150427\n",
      "train loss:0.0003096568104072341\n",
      "train loss:0.0022676735624214124\n",
      "train loss:0.003923304380085534\n",
      "train loss:0.00219477945769357\n",
      "train loss:0.010888596860486897\n",
      "train loss:0.002280932862485242\n",
      "train loss:0.0019161709633097274\n",
      "train loss:0.007064631635592423\n",
      "train loss:0.0007295560764853539\n",
      "train loss:0.009795348483374681\n",
      "train loss:0.003079573610119366\n",
      "train loss:0.0044363620916856175\n",
      "train loss:0.019555898350138354\n",
      "train loss:0.0013451188801698393\n",
      "train loss:0.0001911621494913658\n",
      "train loss:0.0030623560430736918\n",
      "train loss:0.0026181782986022034\n",
      "train loss:0.0018476537333022805\n",
      "train loss:0.0007218777390463174\n",
      "train loss:0.0009064924632019574\n",
      "train loss:0.0001673904696989411\n",
      "train loss:0.0070015212626158875\n",
      "train loss:0.00016184653865182846\n",
      "train loss:0.0004052575850338112\n",
      "train loss:0.00021277801476572033\n",
      "train loss:0.0033266552932689247\n",
      "train loss:0.001545214440832429\n",
      "train loss:0.0005886446348562272\n",
      "train loss:0.005794220248206479\n",
      "train loss:0.001802754269738076\n",
      "train loss:0.0010023688498993766\n",
      "train loss:0.001639928622692932\n",
      "train loss:0.003089416243127853\n",
      "train loss:0.004384293194159195\n",
      "train loss:0.007202787595323521\n",
      "train loss:0.0004481565730225588\n",
      "train loss:0.008048404078627199\n",
      "train loss:0.002853764221881873\n",
      "train loss:0.0035824785777500163\n",
      "train loss:7.590046126949954e-05\n",
      "train loss:0.0012795994160582178\n",
      "train loss:0.006474392073051737\n",
      "train loss:0.0023542386757510725\n",
      "train loss:0.00025399732760508884\n",
      "train loss:0.002133693188214536\n",
      "train loss:0.00036332161432511535\n",
      "train loss:0.0007966091903998594\n",
      "train loss:0.0012541557170245902\n",
      "train loss:0.0009600792713509061\n",
      "train loss:0.0016041554989505813\n",
      "train loss:0.00952051569526211\n",
      "train loss:0.004174465445678471\n",
      "train loss:6.69717157661652e-05\n",
      "train loss:0.0004300622784124721\n",
      "train loss:0.0004527489683276979\n",
      "train loss:0.006188913093949344\n",
      "train loss:0.0007779208703553275\n",
      "train loss:0.0007121760500430831\n",
      "train loss:0.0036211080094497128\n",
      "train loss:0.0016029824855123605\n",
      "train loss:0.003624900717468148\n",
      "train loss:0.002269200353860337\n",
      "train loss:0.0017613562582325082\n",
      "train loss:0.005680894894430963\n",
      "train loss:0.002072566405089595\n",
      "train loss:0.0008908527882768837\n",
      "train loss:0.0010999731979486479\n",
      "train loss:0.00041308561181957297\n",
      "train loss:0.0004969170340576923\n",
      "train loss:0.008517218606642667\n",
      "train loss:0.00047254553358229423\n",
      "train loss:0.0012300043633777977\n",
      "train loss:0.0003798525451592482\n",
      "train loss:0.00014877143988347664\n",
      "train loss:0.0011925551707074721\n",
      "train loss:0.0013006552769887273\n",
      "train loss:0.003864736616240604\n",
      "train loss:0.0002463098488458478\n",
      "train loss:0.0013033535720471763\n",
      "train loss:0.002120360087451537\n",
      "train loss:0.002658066987103491\n",
      "train loss:0.005131043730378363\n",
      "train loss:0.0008270615987001228\n",
      "train loss:0.0039680312592828785\n",
      "train loss:8.46691291454393e-05\n",
      "train loss:0.0017001228621972813\n",
      "train loss:0.0004397403577480496\n",
      "train loss:0.0020622223668799525\n",
      "train loss:0.0005152348489261563\n",
      "train loss:0.00021342806537187628\n",
      "train loss:0.002722027180663547\n",
      "train loss:0.0010496708484595834\n",
      "train loss:0.00012951305007820308\n",
      "train loss:0.001324266275287707\n",
      "train loss:0.0004091757716048752\n",
      "train loss:0.0030413444305520078\n",
      "train loss:0.0006101275318661691\n",
      "train loss:0.0007403981327223419\n",
      "train loss:0.011770021804682144\n",
      "train loss:0.0013718398117642113\n",
      "train loss:0.0004940327453115072\n",
      "train loss:0.00018124446372215071\n",
      "train loss:0.0002209042553246323\n",
      "train loss:0.0010740211226599997\n",
      "train loss:0.0003700694918913039\n",
      "train loss:0.002231376042797731\n",
      "train loss:0.00026498643115048623\n",
      "train loss:0.0003448928674156216\n",
      "train loss:0.0008878063896956864\n",
      "train loss:0.0007746320434163437\n",
      "train loss:0.0024485444748428096\n",
      "train loss:0.00019217087358007218\n",
      "train loss:0.019456241972848135\n",
      "train loss:0.010346086301834437\n",
      "train loss:0.0009403747795665647\n",
      "train loss:0.003794294828095962\n",
      "train loss:0.0014917013127542398\n",
      "train loss:0.002306599542765605\n",
      "train loss:0.0038620269184054794\n",
      "train loss:0.0012915096043931377\n",
      "train loss:0.00011418342771895974\n",
      "train loss:0.0021399470100015258\n",
      "train loss:0.0021815128987679434\n",
      "train loss:0.0077588891345296805\n",
      "train loss:0.001965676017658942\n",
      "train loss:0.0006520023294319532\n",
      "train loss:0.0014363238684340135\n",
      "train loss:0.004723921721833699\n",
      "train loss:0.004925248847564186\n",
      "train loss:0.002324843815225457\n",
      "train loss:0.010402990936740185\n",
      "train loss:0.0001614979649444731\n",
      "train loss:0.0026377856522491736\n",
      "train loss:0.0007941441454423502\n",
      "train loss:0.0015343883214676687\n",
      "train loss:0.002704644784402797\n",
      "train loss:0.0010178416564002033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012406468301681876\n",
      "train loss:0.001967070574793647\n",
      "train loss:0.005590570906362601\n",
      "train loss:0.0030704846395292894\n",
      "train loss:0.014659011952041284\n",
      "train loss:0.011950462125405388\n",
      "train loss:0.0030395225189481785\n",
      "train loss:0.00043724557621932557\n",
      "train loss:0.004363433966321111\n",
      "train loss:0.0002761338287142572\n",
      "train loss:0.0002908357379717804\n",
      "train loss:0.01270076280267891\n",
      "train loss:0.00041077840075635826\n",
      "train loss:0.0005782737114524607\n",
      "train loss:0.001145660803243071\n",
      "train loss:0.007329783973246733\n",
      "train loss:0.0001542201783519204\n",
      "train loss:0.0011271029336834908\n",
      "train loss:0.0014690432708284117\n",
      "train loss:0.00043805439430459896\n",
      "train loss:0.004870676377551716\n",
      "train loss:0.005944057734301015\n",
      "train loss:0.002489874080707105\n",
      "train loss:0.0011598260946756988\n",
      "train loss:7.999266288517115e-05\n",
      "train loss:0.005430579603507445\n",
      "train loss:0.003676226442822502\n",
      "train loss:0.0012482972028817765\n",
      "train loss:0.003522850317639326\n",
      "train loss:0.0005820397790170541\n",
      "train loss:0.0007716683850609274\n",
      "train loss:0.0038944169936274923\n",
      "train loss:0.0020830245926974043\n",
      "train loss:0.00028330765380716753\n",
      "train loss:0.0016116026434451608\n",
      "train loss:0.0003177930083872271\n",
      "train loss:9.86642647053109e-05\n",
      "train loss:0.001257619446145234\n",
      "train loss:0.0008415334253032904\n",
      "train loss:0.000546617225205858\n",
      "train loss:0.00046073103615710214\n",
      "train loss:0.0028181244320818954\n",
      "train loss:0.0004261215065453695\n",
      "train loss:0.001876607691329017\n",
      "train loss:0.0002061357807320615\n",
      "train loss:3.0134004298003956e-05\n",
      "train loss:0.003551545017389085\n",
      "train loss:0.0007648561055966344\n",
      "train loss:0.0003935172435661293\n",
      "train loss:0.00020796511008465166\n",
      "train loss:0.00350801295849637\n",
      "train loss:7.378472162344542e-05\n",
      "train loss:0.005311253788381424\n",
      "train loss:0.0032431707139709454\n",
      "train loss:0.0011099642857237248\n",
      "train loss:0.0011459505838633962\n",
      "train loss:0.00038710185439975504\n",
      "train loss:0.0005943380287879471\n",
      "train loss:0.00284798854874569\n",
      "train loss:0.0033822061500288735\n",
      "train loss:0.0002021143886454741\n",
      "train loss:0.0088561719682507\n",
      "train loss:0.00031089517217356056\n",
      "train loss:0.000169539727369984\n",
      "train loss:0.002696673909864692\n",
      "train loss:0.001950666676874526\n",
      "train loss:0.0028627700757384027\n",
      "train loss:0.00022171158575891675\n",
      "train loss:0.0018804847975179778\n",
      "train loss:0.004387060477287836\n",
      "train loss:0.0023175894173623314\n",
      "train loss:0.006221641078617706\n",
      "train loss:0.00022117945243132933\n",
      "train loss:0.00012161621338733902\n",
      "train loss:5.844030929973603e-05\n",
      "train loss:9.049994373753998e-05\n",
      "train loss:0.00023735435395899816\n",
      "train loss:0.0015757585955102668\n",
      "train loss:0.0015804916536666254\n",
      "train loss:0.0009942767378445072\n",
      "train loss:0.0009295131725130117\n",
      "train loss:0.01135127453378179\n",
      "train loss:0.0011970770685105741\n",
      "train loss:0.00042466540301033996\n",
      "train loss:0.00021970127543601266\n",
      "train loss:0.0006994624343081127\n",
      "train loss:0.0001289649815995787\n",
      "train loss:0.006107096697916443\n",
      "train loss:0.001609316814334091\n",
      "train loss:0.0004080324945776392\n",
      "train loss:0.0020964327596594778\n",
      "train loss:0.0016702507358186541\n",
      "train loss:0.0015398659839088167\n",
      "train loss:0.0031922443340721297\n",
      "train loss:0.001024806769396751\n",
      "train loss:0.000402024930800927\n",
      "train loss:0.0003977606832354507\n",
      "train loss:0.0003284310349334171\n",
      "=== epoch:17, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.0003622653641651385\n",
      "train loss:0.00044633273023384287\n",
      "train loss:0.0029820610798439173\n",
      "train loss:0.004713823621505926\n",
      "train loss:0.0010750872539170152\n",
      "train loss:0.0007681492207602764\n",
      "train loss:7.814614114433523e-05\n",
      "train loss:0.0021166186453323984\n",
      "train loss:0.0006302265890192071\n",
      "train loss:0.001143362679475574\n",
      "train loss:0.00033945029411473315\n",
      "train loss:0.011745941361056516\n",
      "train loss:0.0056408313417483065\n",
      "train loss:0.002871167423072528\n",
      "train loss:0.001131650205488896\n",
      "train loss:0.004607448962267488\n",
      "train loss:0.0013889489107339\n",
      "train loss:0.0025326847551203025\n",
      "train loss:0.00026038206904053883\n",
      "train loss:0.0027767785747464407\n",
      "train loss:0.004700932179826085\n",
      "train loss:0.0013382137581490444\n",
      "train loss:0.0018701593340891157\n",
      "train loss:0.003287455059232839\n",
      "train loss:0.003482983850835621\n",
      "train loss:0.00325232274909691\n",
      "train loss:0.0004628152826376532\n",
      "train loss:0.001747454078409979\n",
      "train loss:0.00017999293214148856\n",
      "train loss:0.0008194147971858265\n",
      "train loss:0.0011631160140262104\n",
      "train loss:0.0011309170748244836\n",
      "train loss:0.001348550708142268\n",
      "train loss:0.002398510561938823\n",
      "train loss:0.00344819803235825\n",
      "train loss:0.003434120492031724\n",
      "train loss:0.00015143810686722885\n",
      "train loss:0.0009459103626685797\n",
      "train loss:0.0007994644020262435\n",
      "train loss:5.902983529158482e-05\n",
      "train loss:0.0007436492419705293\n",
      "train loss:0.0010962525260612105\n",
      "train loss:0.010720194895327077\n",
      "train loss:0.0012690164358241402\n",
      "train loss:0.0022372741702555033\n",
      "train loss:0.011830356222625474\n",
      "train loss:0.001386881684809588\n",
      "train loss:0.005397026118015212\n",
      "train loss:0.0035789430062470305\n",
      "train loss:0.0008773263857403358\n",
      "train loss:0.0013245266008560512\n",
      "train loss:0.00021884422144887393\n",
      "train loss:0.0002581751946578121\n",
      "train loss:0.00019505259267831848\n",
      "train loss:0.0073568335898011915\n",
      "train loss:0.0009266096545408176\n",
      "train loss:0.002376684859221807\n",
      "train loss:0.000638480022561066\n",
      "train loss:0.0027930884036465632\n",
      "train loss:0.0003093335319685763\n",
      "train loss:0.00012649056309789502\n",
      "train loss:0.0011939729106305566\n",
      "train loss:0.00048064705171419473\n",
      "train loss:0.0005969606371265738\n",
      "train loss:0.0020054533966679614\n",
      "train loss:8.87997403241411e-05\n",
      "train loss:0.00027396952983494436\n",
      "train loss:0.0002507411980349898\n",
      "train loss:0.0014440511572088263\n",
      "train loss:0.00012605686065496636\n",
      "train loss:0.000943173040619203\n",
      "train loss:0.0007818224711681967\n",
      "train loss:0.0009586274305562694\n",
      "train loss:0.0007982518076018527\n",
      "train loss:0.0008610190004787754\n",
      "train loss:0.0011321826564735266\n",
      "train loss:0.000441977932512832\n",
      "train loss:0.0002635517004031166\n",
      "train loss:0.003632642257761833\n",
      "train loss:0.0005255946169437625\n",
      "train loss:0.003632104886852135\n",
      "train loss:0.004761863816660896\n",
      "train loss:0.000670445383924542\n",
      "train loss:0.00021821561437320217\n",
      "train loss:0.0004193721489937074\n",
      "train loss:0.0049077799375915505\n",
      "train loss:0.00028164544484731644\n",
      "train loss:0.0012338585506235778\n",
      "train loss:0.0004124624917671599\n",
      "train loss:0.0007327892847442376\n",
      "train loss:0.00015081627936524105\n",
      "train loss:0.0005307857764930359\n",
      "train loss:0.0008016014295476093\n",
      "train loss:0.0005170570504870734\n",
      "train loss:0.000522778491334371\n",
      "train loss:0.002434460044949113\n",
      "train loss:0.00024577988320783413\n",
      "train loss:0.014235257326191133\n",
      "train loss:0.0017094815554980066\n",
      "train loss:0.0016060229985237382\n",
      "train loss:0.009822604643818244\n",
      "train loss:0.0014780476195490914\n",
      "train loss:0.0006435064583039696\n",
      "train loss:0.0013095207392264346\n",
      "train loss:7.241432180955001e-05\n",
      "train loss:0.0015601917386113807\n",
      "train loss:0.0015271153813718862\n",
      "train loss:0.0027652578469818424\n",
      "train loss:0.00046280161199123876\n",
      "train loss:0.000656898404453079\n",
      "train loss:0.0010695060438608219\n",
      "train loss:0.0034619250535132596\n",
      "train loss:0.0003692086084661753\n",
      "train loss:0.002369020584195137\n",
      "train loss:0.0015549637069574094\n",
      "train loss:0.0031239527119993125\n",
      "train loss:0.0005495096974257025\n",
      "train loss:0.00033066100645172283\n",
      "train loss:0.0014650034020025685\n",
      "train loss:4.209996948005673e-05\n",
      "train loss:0.001783330246512535\n",
      "train loss:0.0003600980581344098\n",
      "train loss:0.00030293290256514535\n",
      "train loss:0.0009173865727928121\n",
      "train loss:4.907032537979538e-05\n",
      "train loss:0.0011621747819759705\n",
      "train loss:0.0036195024675684155\n",
      "train loss:0.0019630867739888146\n",
      "train loss:0.0008556430189206386\n",
      "train loss:4.521159736397698e-05\n",
      "train loss:0.002208592435429924\n",
      "train loss:0.0015183887087731982\n",
      "train loss:0.0006417984962204899\n",
      "train loss:0.0020627304408618982\n",
      "train loss:0.0013414162142756244\n",
      "train loss:0.0032761567889808326\n",
      "train loss:0.014762618353729764\n",
      "train loss:0.0001629260091215981\n",
      "train loss:0.0001236457389011837\n",
      "train loss:0.0005885443102359791\n",
      "train loss:0.00018727550338834477\n",
      "train loss:0.000212443643072396\n",
      "train loss:0.00032032321982524683\n",
      "train loss:0.0007574134978210314\n",
      "train loss:0.00010426012966030861\n",
      "train loss:0.002587158628928297\n",
      "train loss:0.017679247373614922\n",
      "train loss:0.004768886283680609\n",
      "train loss:0.00041056353241333116\n",
      "train loss:0.0018092842333049587\n",
      "train loss:0.0027312717226831026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0020698467954040965\n",
      "train loss:0.00011889729628836615\n",
      "train loss:0.009074366225092084\n",
      "train loss:4.886905941187014e-05\n",
      "train loss:0.0027614363416435172\n",
      "train loss:0.0011644090075663325\n",
      "train loss:0.0015960525050913916\n",
      "train loss:0.0012182213953673877\n",
      "train loss:0.0009610906580628223\n",
      "train loss:0.0003862169563840872\n",
      "train loss:0.0013208229383046251\n",
      "train loss:0.00047540660616492695\n",
      "train loss:0.0025761126288649633\n",
      "train loss:0.00026697410550058457\n",
      "train loss:0.00017856530337966356\n",
      "train loss:0.0009623779828916669\n",
      "train loss:0.0015246234656575033\n",
      "train loss:0.0026524534824825087\n",
      "train loss:0.00911329369686798\n",
      "train loss:0.0029392017447628397\n",
      "train loss:0.0013832372975196277\n",
      "train loss:0.0037407408025846444\n",
      "train loss:0.0027976025379918574\n",
      "train loss:0.0021734183272960218\n",
      "train loss:0.0012264462317475595\n",
      "train loss:0.0056332818103624225\n",
      "train loss:0.0015644952470847734\n",
      "train loss:0.00013722620100795733\n",
      "train loss:0.0001695823277819896\n",
      "train loss:8.086301216094889e-05\n",
      "train loss:0.00040614644754475014\n",
      "train loss:0.0013951411776081152\n",
      "train loss:0.002687006368431731\n",
      "train loss:0.00040297785175621233\n",
      "train loss:0.009029814515653432\n",
      "train loss:0.005044819743810224\n",
      "train loss:0.00012617367590287822\n",
      "train loss:0.0024939097198615613\n",
      "train loss:0.0009191046583953344\n",
      "train loss:0.0007001792102505814\n",
      "train loss:5.1344064568292995e-05\n",
      "train loss:0.0008981899966776296\n",
      "train loss:0.0008890651522575344\n",
      "train loss:0.0032612825575438985\n",
      "train loss:0.010361671676469526\n",
      "train loss:0.0003796243692821265\n",
      "train loss:4.735344843240727e-05\n",
      "train loss:0.002155744035466116\n",
      "train loss:0.0004093085389354106\n",
      "train loss:0.0015784542449191463\n",
      "train loss:0.0011186244178154811\n",
      "train loss:0.0007420465281412599\n",
      "train loss:0.0001409212497132961\n",
      "train loss:0.001283461785145279\n",
      "train loss:0.00011519089926137968\n",
      "train loss:0.002761434272666544\n",
      "train loss:0.008148728739732151\n",
      "train loss:0.018850472626345042\n",
      "train loss:0.0006309893403764798\n",
      "train loss:0.0003225108850963088\n",
      "train loss:0.011073175140186152\n",
      "train loss:0.006129413686263405\n",
      "train loss:0.00015423222916621638\n",
      "train loss:0.001255753068485882\n",
      "train loss:0.000890327698827019\n",
      "train loss:0.004102257359326043\n",
      "train loss:0.000585668735445899\n",
      "train loss:0.0004724760334689964\n",
      "train loss:0.0004358679590770144\n",
      "train loss:0.0020593650908527577\n",
      "train loss:0.00024409137288215044\n",
      "train loss:0.00021284939357317227\n",
      "train loss:0.000994349683213148\n",
      "train loss:0.0009996623981359176\n",
      "train loss:0.004195065805798115\n",
      "train loss:0.03776334841657734\n",
      "train loss:0.0036435660415951136\n",
      "train loss:0.0009669694150741788\n",
      "train loss:0.0009310093512979175\n",
      "train loss:0.0021368577244369417\n",
      "train loss:0.006935762579223671\n",
      "train loss:0.0017563174604665315\n",
      "train loss:0.00398490716773106\n",
      "train loss:0.00037630996622217493\n",
      "train loss:0.0026861553261550803\n",
      "train loss:0.004845943161430747\n",
      "train loss:0.002880891445996001\n",
      "train loss:0.010929336860363115\n",
      "train loss:0.0018082698918097401\n",
      "train loss:0.0032708221626365093\n",
      "train loss:0.004058084909374967\n",
      "train loss:0.0009752567151849756\n",
      "train loss:0.002575603475874609\n",
      "train loss:0.0002700807283984825\n",
      "train loss:0.0032798842441618308\n",
      "train loss:0.0016262302217161107\n",
      "train loss:0.0030176467308547965\n",
      "train loss:0.002069343785311977\n",
      "train loss:0.002844746837910358\n",
      "train loss:0.0017666530260939154\n",
      "train loss:0.0009640607996489585\n",
      "train loss:0.0006881708404490762\n",
      "train loss:0.005819949743821666\n",
      "train loss:0.00029628472923054933\n",
      "train loss:0.0006772963406131879\n",
      "train loss:0.0019424478723473807\n",
      "train loss:0.0011501426535654368\n",
      "train loss:0.0015866137917359793\n",
      "train loss:0.0004793058710227371\n",
      "train loss:0.0005508497212173646\n",
      "train loss:0.0004795930142468303\n",
      "train loss:0.0007482058802017952\n",
      "train loss:0.00032909862144444457\n",
      "train loss:0.001225088369442467\n",
      "train loss:0.00198699879432299\n",
      "train loss:0.002437507766588553\n",
      "train loss:0.003470404885557624\n",
      "train loss:0.006649179271392089\n",
      "train loss:0.0007109613574958513\n",
      "train loss:0.00025853718364805085\n",
      "train loss:0.00019588571345793309\n",
      "train loss:0.001495922665055554\n",
      "train loss:0.00039713622902827207\n",
      "train loss:0.02714551093000797\n",
      "train loss:0.00024745634484175873\n",
      "train loss:0.000384415751985263\n",
      "train loss:0.0023206942087900316\n",
      "train loss:0.00021327721909390144\n",
      "train loss:0.0023070387684487373\n",
      "train loss:0.00046851486032905524\n",
      "train loss:0.001846179675894892\n",
      "train loss:0.006630415767970438\n",
      "train loss:0.0050156391781748435\n",
      "train loss:0.001498870354948545\n",
      "train loss:0.008986988209731699\n",
      "train loss:0.00046694782333226256\n",
      "train loss:0.002045981946396833\n",
      "train loss:0.00203307613813764\n",
      "train loss:0.0017032898158214865\n",
      "train loss:0.0018317045951417852\n",
      "train loss:0.00012663874147493773\n",
      "train loss:3.965652244303073e-05\n",
      "train loss:7.638929087298725e-05\n",
      "train loss:0.0015630421044796614\n",
      "train loss:0.0011626333347759946\n",
      "train loss:0.010732829377225892\n",
      "train loss:0.004352625607093297\n",
      "train loss:0.0013607047209660895\n",
      "train loss:0.008232531721211632\n",
      "train loss:0.00027931673398601904\n",
      "train loss:0.0032503916469965467\n",
      "train loss:0.00032509627498463297\n",
      "train loss:0.002664331103938384\n",
      "train loss:0.0005168534243799241\n",
      "train loss:0.0006087565916110755\n",
      "train loss:0.00023913828983793348\n",
      "train loss:0.002484508089437635\n",
      "train loss:0.0002342906824146216\n",
      "train loss:0.000853362650946191\n",
      "train loss:0.001095820948369102\n",
      "train loss:0.0020880662594817377\n",
      "train loss:0.0021256565541725937\n",
      "train loss:0.0007726884375484919\n",
      "train loss:0.00019118241328885792\n",
      "train loss:0.00032748543380141425\n",
      "train loss:0.0022763037189285906\n",
      "train loss:0.0016343629291852074\n",
      "train loss:0.0027573428746018288\n",
      "train loss:0.0003554803805901747\n",
      "train loss:0.00022533798252839042\n",
      "train loss:0.0005068120186809736\n",
      "train loss:0.0012019888059118494\n",
      "train loss:0.0037886104249654634\n",
      "train loss:0.0018228047110690104\n",
      "train loss:0.0034775074443078135\n",
      "train loss:0.0020408008366748663\n",
      "train loss:0.0034489331056307827\n",
      "train loss:0.0030127199201136195\n",
      "train loss:0.0008230454681646616\n",
      "train loss:0.00052024921654213\n",
      "train loss:0.0042393219595990685\n",
      "train loss:2.8440215853339087e-05\n",
      "train loss:0.002389945653808679\n",
      "train loss:0.0032517901769476224\n",
      "train loss:0.005398553651974608\n",
      "train loss:0.0014526751924879837\n",
      "train loss:0.00013984696643881434\n",
      "train loss:0.0036810995355400465\n",
      "train loss:0.0034972926586964086\n",
      "train loss:7.619535716691483e-05\n",
      "train loss:0.0009298801160551906\n",
      "train loss:6.141798919651189e-05\n",
      "train loss:0.0008854933211440004\n",
      "train loss:0.0006184597487694178\n",
      "train loss:0.0010023727267970762\n",
      "train loss:0.0005119949799597508\n",
      "train loss:0.00044811001617266243\n",
      "train loss:0.0014910904719400697\n",
      "train loss:0.00016932319422788882\n",
      "train loss:0.00025806256268595066\n",
      "train loss:0.0012867368141974771\n",
      "train loss:0.001326386228496669\n",
      "train loss:0.0019038819106368596\n",
      "train loss:0.003915072374827864\n",
      "train loss:0.005219658718762023\n",
      "train loss:0.000405926824630722\n",
      "train loss:0.001397134582777937\n",
      "train loss:0.0004950245821854735\n",
      "train loss:0.00010025102584663969\n",
      "train loss:0.0002566980093349535\n",
      "train loss:0.0004915125539160216\n",
      "train loss:0.00040625420040675216\n",
      "train loss:0.0008178825280349181\n",
      "train loss:0.0026630226398638795\n",
      "train loss:0.002009254210530105\n",
      "train loss:0.000737413024173249\n",
      "train loss:0.0006575095131312988\n",
      "train loss:4.405203138370267e-05\n",
      "train loss:0.00021849485603570005\n",
      "train loss:0.006081210640345337\n",
      "train loss:0.00021801609772706794\n",
      "train loss:0.0007697467471955962\n",
      "train loss:7.339912513416011e-05\n",
      "train loss:0.0004938238628372607\n",
      "train loss:0.0018911981156152994\n",
      "train loss:0.004738757155356138\n",
      "train loss:0.0009759608534303214\n",
      "train loss:0.0010586045663256729\n",
      "train loss:7.022607701189088e-05\n",
      "train loss:0.011483523297331624\n",
      "train loss:0.002862592158270344\n",
      "train loss:0.00033032679960507923\n",
      "train loss:0.0030765720881046404\n",
      "train loss:0.003510789691449653\n",
      "train loss:0.001202891737175859\n",
      "train loss:0.005288573155570303\n",
      "train loss:0.0006048337764776919\n",
      "train loss:0.0012981740234442884\n",
      "train loss:0.0008762811130756555\n",
      "train loss:0.00228090631499998\n",
      "train loss:9.280055294185328e-05\n",
      "train loss:0.0027952880174279943\n",
      "train loss:0.0014509549954196726\n",
      "train loss:0.0015225443243633457\n",
      "train loss:0.005688470888839872\n",
      "train loss:0.001248525786006936\n",
      "train loss:0.0011765118979699437\n",
      "train loss:0.000436044376595697\n",
      "train loss:0.0036986920861207086\n",
      "train loss:0.002271274303376513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00043201503830058547\n",
      "train loss:0.0002932494545585975\n",
      "train loss:0.001169947443376905\n",
      "train loss:0.01297639479948381\n",
      "train loss:0.005443489046613328\n",
      "train loss:0.0001947439143331651\n",
      "train loss:0.002007304066238935\n",
      "train loss:0.001966072764843216\n",
      "train loss:4.034766934312593e-05\n",
      "train loss:0.0013909259262892832\n",
      "train loss:0.001785554883913733\n",
      "train loss:0.001335607532209326\n",
      "train loss:0.000976700681079694\n",
      "train loss:0.00014473122759978463\n",
      "train loss:0.004090817789061804\n",
      "train loss:0.0005877009677912026\n",
      "train loss:0.0017410322504645235\n",
      "train loss:0.0013341812859766614\n",
      "train loss:0.0001655391170256585\n",
      "train loss:0.0014663595916954786\n",
      "train loss:0.0022032024466077803\n",
      "train loss:0.006016131460197384\n",
      "train loss:0.0007143621053085625\n",
      "train loss:0.0007559088426359445\n",
      "train loss:0.0019554716083345727\n",
      "train loss:0.0021776823947093193\n",
      "train loss:0.001234560134646935\n",
      "train loss:0.00015630747106921224\n",
      "train loss:0.0020023613381706957\n",
      "train loss:0.0002452937217532233\n",
      "train loss:0.0002101322330985716\n",
      "train loss:0.00020079171910071823\n",
      "train loss:0.0014103108290628088\n",
      "train loss:8.243672089224509e-05\n",
      "train loss:0.0002100732320171079\n",
      "train loss:0.0014012947386660784\n",
      "train loss:6.645885302799085e-05\n",
      "train loss:0.004373933969072407\n",
      "train loss:0.0014506673431790085\n",
      "train loss:0.00011831624450443067\n",
      "train loss:0.0009248222464479085\n",
      "train loss:0.000615795200690502\n",
      "train loss:0.014777312303090685\n",
      "train loss:0.001574483476897545\n",
      "train loss:0.0010829285213785778\n",
      "train loss:3.836347531232124e-05\n",
      "train loss:0.0029453671882694547\n",
      "train loss:0.0032371578603612237\n",
      "train loss:9.450480276055317e-05\n",
      "train loss:0.00013936664987818334\n",
      "train loss:0.002092163595127098\n",
      "train loss:0.002567540955959458\n",
      "train loss:0.0017109597673554042\n",
      "train loss:8.238374756426344e-05\n",
      "train loss:0.00901669354516963\n",
      "train loss:0.0009588345204659851\n",
      "train loss:9.238875485961974e-05\n",
      "train loss:0.0017613324507756718\n",
      "train loss:0.0002362246006966488\n",
      "train loss:0.00033474502604838183\n",
      "train loss:0.0030761624492730306\n",
      "train loss:0.0013523765965735373\n",
      "train loss:0.0006529165368674848\n",
      "train loss:0.0024380179249101045\n",
      "train loss:0.0010575354952180253\n",
      "train loss:0.00023470922146950869\n",
      "train loss:0.002054993272448051\n",
      "train loss:0.0003007256461544771\n",
      "train loss:0.008627062535166914\n",
      "train loss:3.030113951803679e-05\n",
      "train loss:0.008272371503419583\n",
      "train loss:0.0008227888293085165\n",
      "train loss:0.0009773410946321906\n",
      "train loss:0.0008297126907074098\n",
      "train loss:0.0011086366104033794\n",
      "train loss:0.0013447680697632192\n",
      "train loss:0.0003194859048687811\n",
      "train loss:0.003359795879654435\n",
      "train loss:0.0028481759778896843\n",
      "train loss:0.0002327220169488358\n",
      "train loss:0.002424412738021194\n",
      "train loss:0.0018779545911966527\n",
      "train loss:0.0005653130249343455\n",
      "train loss:0.0003501262399124949\n",
      "train loss:0.004187768483912499\n",
      "train loss:0.0007250375359361238\n",
      "train loss:0.001196161567919168\n",
      "train loss:0.005914526083606954\n",
      "train loss:0.0009121751498545217\n",
      "train loss:0.00028761969895792656\n",
      "train loss:0.0044024148503525\n",
      "train loss:0.0023387481165002364\n",
      "train loss:0.00034043512125125837\n",
      "train loss:6.985374373231479e-05\n",
      "train loss:0.0008916321082075583\n",
      "train loss:0.00019486415274894004\n",
      "train loss:0.0006300812453759876\n",
      "train loss:0.0003571946043382353\n",
      "train loss:0.0005694132041923287\n",
      "train loss:9.471629431555873e-05\n",
      "train loss:0.0031437449333954546\n",
      "train loss:0.0006944641475425981\n",
      "train loss:2.7622352503706838e-05\n",
      "train loss:0.0012030841252554608\n",
      "train loss:0.0009469839301366879\n",
      "train loss:0.0003423509139886957\n",
      "train loss:0.0022440097327699454\n",
      "train loss:0.000583871309820259\n",
      "train loss:0.0003395719014494948\n",
      "train loss:3.54776713750029e-05\n",
      "train loss:0.0005788276783163619\n",
      "train loss:0.00042476920965315787\n",
      "train loss:0.0008588107906513095\n",
      "train loss:0.001713613929929957\n",
      "train loss:0.0004746847999011396\n",
      "train loss:0.0017404072864057628\n",
      "train loss:0.0009607273077074933\n",
      "train loss:0.0008259838138417661\n",
      "train loss:0.002597568403905701\n",
      "train loss:0.004641246826931341\n",
      "train loss:0.00011078776421480871\n",
      "train loss:0.0013176684747489816\n",
      "train loss:0.019831374798006337\n",
      "train loss:0.0008782247133288881\n",
      "train loss:5.257351914844907e-05\n",
      "train loss:0.0019231871505059617\n",
      "train loss:0.0021797008532689526\n",
      "train loss:0.0035349908046887367\n",
      "train loss:0.0005766753797964545\n",
      "train loss:0.0018246716446045192\n",
      "train loss:6.276491081016825e-05\n",
      "train loss:0.0001380396053309742\n",
      "train loss:0.006804993766102563\n",
      "train loss:0.0013851399798301997\n",
      "train loss:0.00315602230520579\n",
      "train loss:0.0002516468900422877\n",
      "train loss:2.640510658814395e-05\n",
      "train loss:0.003209154196330652\n",
      "train loss:0.0003226241378127255\n",
      "train loss:0.019307797721441745\n",
      "train loss:0.00032825788508747557\n",
      "train loss:0.0001401031907725563\n",
      "train loss:0.00014316298614747516\n",
      "train loss:0.013154620952376551\n",
      "train loss:0.03506297876514411\n",
      "train loss:0.0009328549934755736\n",
      "train loss:3.558915154001863e-05\n",
      "train loss:0.0004653687173099721\n",
      "train loss:8.223353518281722e-05\n",
      "train loss:0.001593046058892567\n",
      "train loss:0.00022534722222097584\n",
      "train loss:0.014085107687128933\n",
      "train loss:0.00010749540984701215\n",
      "train loss:0.0007926084311772412\n",
      "train loss:0.000568161260492275\n",
      "train loss:0.002615566585599792\n",
      "train loss:0.001792603292455687\n",
      "train loss:0.001073484808888813\n",
      "train loss:3.882155402854181e-05\n",
      "train loss:0.0011379189388268341\n",
      "train loss:0.002033587440526672\n",
      "train loss:0.004366958329092029\n",
      "train loss:0.00025248997278981783\n",
      "train loss:0.0003186350287575939\n",
      "train loss:0.000140299362233459\n",
      "train loss:0.0002480341140366494\n",
      "train loss:0.00037953370479906485\n",
      "train loss:0.00047602197667417814\n",
      "train loss:0.002549531036626868\n",
      "train loss:0.00015642478659266238\n",
      "train loss:0.0006787153822367586\n",
      "train loss:0.0013718800595788519\n",
      "train loss:0.0004308229207178233\n",
      "train loss:0.002703896751996756\n",
      "train loss:0.0009858869506767884\n",
      "train loss:0.0014970833557700037\n",
      "train loss:0.017867413401182065\n",
      "train loss:0.0004612261581786815\n",
      "train loss:0.00031731128373665594\n",
      "train loss:0.00011447351565942813\n",
      "train loss:0.0032152251641624063\n",
      "train loss:0.0011981215704040564\n",
      "train loss:0.0012239695956537166\n",
      "train loss:0.0008114384328171499\n",
      "train loss:0.0011497877805816848\n",
      "train loss:0.0005640382234694582\n",
      "train loss:0.005501381831140845\n",
      "train loss:0.006453222145879074\n",
      "train loss:0.0014838439629972825\n",
      "train loss:0.003214320593733139\n",
      "train loss:0.0005203113999984773\n",
      "train loss:0.0027188536619186495\n",
      "train loss:0.0017492468396194225\n",
      "train loss:0.0006276247970447136\n",
      "train loss:0.009040961511242444\n",
      "train loss:0.0008607919563534202\n",
      "train loss:0.00044248768765584013\n",
      "train loss:0.0018620613920348988\n",
      "train loss:0.0013682555296396434\n",
      "=== epoch:18, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.004861605624945112\n",
      "train loss:4.341458148781294e-06\n",
      "train loss:0.0026922095822690608\n",
      "train loss:0.004271855448411232\n",
      "train loss:0.00016920007448376886\n",
      "train loss:6.039721084821951e-05\n",
      "train loss:0.003140571910593494\n",
      "train loss:0.001730166582502303\n",
      "train loss:0.0015457213777693574\n",
      "train loss:0.0001790324669084418\n",
      "train loss:0.00016006032814156653\n",
      "train loss:0.001838053444564672\n",
      "train loss:0.0019103867840637818\n",
      "train loss:0.0030776761990727363\n",
      "train loss:0.0010247321803245923\n",
      "train loss:0.0006574503636868603\n",
      "train loss:0.0025259718724865367\n",
      "train loss:4.9486502421322015e-05\n",
      "train loss:5.014872417556338e-05\n",
      "train loss:0.001074201688299583\n",
      "train loss:0.0012039251438586902\n",
      "train loss:0.001617901194550312\n",
      "train loss:0.0023484520283877453\n",
      "train loss:0.001549064477152235\n",
      "train loss:0.003131196490460086\n",
      "train loss:0.0015794186702199728\n",
      "train loss:0.001002313825138709\n",
      "train loss:0.0008482522644618237\n",
      "train loss:0.0009884051248299761\n",
      "train loss:0.00017091912255023212\n",
      "train loss:0.002143149113053393\n",
      "train loss:0.0029518756319434104\n",
      "train loss:0.002906144236946507\n",
      "train loss:0.0004899785327907737\n",
      "train loss:0.0021974715113790154\n",
      "train loss:0.0028546313510548317\n",
      "train loss:0.0005170918502429213\n",
      "train loss:0.0007247056281522794\n",
      "train loss:0.00032559794028175877\n",
      "train loss:1.9229548599920088e-05\n",
      "train loss:0.0027300001480451055\n",
      "train loss:0.0001827877804214588\n",
      "train loss:0.0011258777498714646\n",
      "train loss:0.0008056901175130205\n",
      "train loss:0.004601649775542039\n",
      "train loss:0.0012740652838751543\n",
      "train loss:0.00043824678889850603\n",
      "train loss:0.0013822819140871837\n",
      "train loss:9.593444653229585e-05\n",
      "train loss:0.00017722297188711115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010830468885727935\n",
      "train loss:0.0002107883112011077\n",
      "train loss:0.001865960092901949\n",
      "train loss:0.002679894526279249\n",
      "train loss:0.000596305496852002\n",
      "train loss:0.00014231186280862554\n",
      "train loss:0.00023498740375100556\n",
      "train loss:0.0007306293976752732\n",
      "train loss:0.0052249365439233945\n",
      "train loss:0.0014971687574886778\n",
      "train loss:0.005983943741854855\n",
      "train loss:0.00012958018065379668\n",
      "train loss:0.0007277466049427873\n",
      "train loss:0.002560516144899441\n",
      "train loss:0.0011569246777220865\n",
      "train loss:0.00039414345747307305\n",
      "train loss:0.002210848160158804\n",
      "train loss:0.000140204357319376\n",
      "train loss:0.0010258007728261803\n",
      "train loss:0.0031930657449018313\n",
      "train loss:0.0022302681485226053\n",
      "train loss:0.00020822831835974314\n",
      "train loss:0.0007527009535521005\n",
      "train loss:0.003816697491951123\n",
      "train loss:0.00935125782030351\n",
      "train loss:0.0019031039315236216\n",
      "train loss:0.002606298080569665\n",
      "train loss:0.00219434681593894\n",
      "train loss:0.0008491339658752809\n",
      "train loss:0.00543319454608223\n",
      "train loss:0.006927589153446764\n",
      "train loss:0.0042419147251021696\n",
      "train loss:0.001498344416712915\n",
      "train loss:0.00044287496108367125\n",
      "train loss:0.0007195872456748364\n",
      "train loss:0.0008320758656771426\n",
      "train loss:0.0028429627188059857\n",
      "train loss:0.0026059799745856414\n",
      "train loss:0.0016035652427992902\n",
      "train loss:0.0017572466198691851\n",
      "train loss:0.0002267104762484334\n",
      "train loss:0.0076894751534421525\n",
      "train loss:0.014232736275316247\n",
      "train loss:0.05695887145159241\n",
      "train loss:0.00012908861207274253\n",
      "train loss:0.0003808697095174742\n",
      "train loss:0.0001417218409099686\n",
      "train loss:0.000418767979447821\n",
      "train loss:0.0007643229138894486\n",
      "train loss:0.0007895234450566266\n",
      "train loss:0.002274658721299995\n",
      "train loss:0.0005438635717178225\n",
      "train loss:0.0013467102586284423\n",
      "train loss:0.00047059922189238325\n",
      "train loss:0.0003365244141063896\n",
      "train loss:0.0010065617402815164\n",
      "train loss:0.0017303879945435774\n",
      "train loss:0.00271646778566387\n",
      "train loss:0.00011473008643273117\n",
      "train loss:0.001262334393387341\n",
      "train loss:0.00022882431578331104\n",
      "train loss:0.015920896158084723\n",
      "train loss:0.00388078013034126\n",
      "train loss:0.0001836982961284552\n",
      "train loss:0.0011915004226401831\n",
      "train loss:0.0020731583609698177\n",
      "train loss:8.282323304280451e-05\n",
      "train loss:0.000545777206112959\n",
      "train loss:0.003939637039909744\n",
      "train loss:0.0013131292278548829\n",
      "train loss:0.0022385598836555374\n",
      "train loss:0.0008092317321574334\n",
      "train loss:0.0006256673996667561\n",
      "train loss:0.023819852925023054\n",
      "train loss:0.0017695395668986965\n",
      "train loss:0.0010890686932619094\n",
      "train loss:0.0007787715882333206\n",
      "train loss:0.025770718075186952\n",
      "train loss:0.0012621357757850555\n",
      "train loss:0.0007967966536650056\n",
      "train loss:0.001838612982143068\n",
      "train loss:0.0007720891612883183\n",
      "train loss:0.0010211710181491575\n",
      "train loss:0.004862878998147763\n",
      "train loss:0.0010930457258496568\n",
      "train loss:0.004013300286937293\n",
      "train loss:0.0012876051731011595\n",
      "train loss:0.001153756971569105\n",
      "train loss:0.0018838778231950635\n",
      "train loss:0.005080786142596042\n",
      "train loss:0.001082773078889614\n",
      "train loss:0.005821461731469341\n",
      "train loss:0.00029847904751234946\n",
      "train loss:0.0011467714412713474\n",
      "train loss:0.003631863430755716\n",
      "train loss:0.00018471866528739327\n",
      "train loss:0.002629106213325164\n",
      "train loss:0.0001757917018380065\n",
      "train loss:0.0012520231752154024\n",
      "train loss:0.002038066623049406\n",
      "train loss:0.00020677711815430072\n",
      "train loss:0.00017122239471569625\n",
      "train loss:0.0008480732855734863\n",
      "train loss:0.0007123843974875432\n",
      "train loss:0.0024798749911107403\n",
      "train loss:0.012369725962987386\n",
      "train loss:0.00019663928451047274\n",
      "train loss:0.004478625379225566\n",
      "train loss:0.0007369482228370986\n",
      "train loss:0.001184852281983165\n",
      "train loss:0.0004842529888809639\n",
      "train loss:0.00280271931474625\n",
      "train loss:0.00024799523188451684\n",
      "train loss:0.009479669788390332\n",
      "train loss:0.00030733191127049595\n",
      "train loss:0.00395582757115594\n",
      "train loss:0.0015429937846348743\n",
      "train loss:0.0012457511781110598\n",
      "train loss:0.0036607836029749095\n",
      "train loss:0.0014139035662791648\n",
      "train loss:0.006315885812066989\n",
      "train loss:0.000997091124769232\n",
      "train loss:0.00040977771498336917\n",
      "train loss:0.0006644857017721575\n",
      "train loss:0.0001401993212365834\n",
      "train loss:0.000515322291577268\n",
      "train loss:0.00019488220550076225\n",
      "train loss:0.0020752285086978934\n",
      "train loss:0.0011282691004157622\n",
      "train loss:4.991141265805828e-05\n",
      "train loss:0.0014690551743902643\n",
      "train loss:0.001160589366061243\n",
      "train loss:0.0010908155851435328\n",
      "train loss:0.0004889405367030712\n",
      "train loss:0.002950302279545276\n",
      "train loss:0.0034660906101745006\n",
      "train loss:0.0010097811652590117\n",
      "train loss:0.006358482855055444\n",
      "train loss:0.007545325308302558\n",
      "train loss:0.0042606432263601725\n",
      "train loss:0.0012677263901097451\n",
      "train loss:0.0010774515689830884\n",
      "train loss:0.017152339945790514\n",
      "train loss:0.0034998675108155203\n",
      "train loss:0.00028211390918100697\n",
      "train loss:0.0016885063642098188\n",
      "train loss:0.0008073871122005718\n",
      "train loss:0.002636843688613739\n",
      "train loss:0.00020669024751954155\n",
      "train loss:0.0014284261852863674\n",
      "train loss:0.002367214124363372\n",
      "train loss:0.004314304408898963\n",
      "train loss:0.0012346039239096054\n",
      "train loss:0.00113009736028128\n",
      "train loss:0.0002653952195856767\n",
      "train loss:0.0029017867735071177\n",
      "train loss:0.00019945063972132994\n",
      "train loss:0.0004387123924484051\n",
      "train loss:0.00063717265657431\n",
      "train loss:0.0014959067291041056\n",
      "train loss:0.001449563272389572\n",
      "train loss:7.949612213423336e-05\n",
      "train loss:0.0002776022383100795\n",
      "train loss:0.0012085281150081553\n",
      "train loss:0.009683972989790249\n",
      "train loss:0.004399231821203477\n",
      "train loss:0.0002856710040006857\n",
      "train loss:0.0027278485697371695\n",
      "train loss:0.0008747373144606846\n",
      "train loss:0.0010982374030028962\n",
      "train loss:0.0005429278275506007\n",
      "train loss:0.003686613173797168\n",
      "train loss:0.0005307640768995157\n",
      "train loss:0.0018232239157591615\n",
      "train loss:0.0010801418752998365\n",
      "train loss:0.000234574600131287\n",
      "train loss:0.020899454065948123\n",
      "train loss:0.0018872129878370347\n",
      "train loss:0.0003005804370838039\n",
      "train loss:0.0026548808716702925\n",
      "train loss:0.004531623393531793\n",
      "train loss:0.012340757994468533\n",
      "train loss:0.0005791019865845498\n",
      "train loss:0.00028805732295704174\n",
      "train loss:0.0029715298525748264\n",
      "train loss:0.00037519094503917947\n",
      "train loss:0.00019717009310082762\n",
      "train loss:0.0009869807490175183\n",
      "train loss:0.0005341172914175927\n",
      "train loss:0.0030662705145885027\n",
      "train loss:0.0012055564371722697\n",
      "train loss:0.0019720069588523154\n",
      "train loss:0.002224303469181883\n",
      "train loss:0.005651095336961442\n",
      "train loss:0.0012441007611420276\n",
      "train loss:0.000624527540851395\n",
      "train loss:0.002545100655025933\n",
      "train loss:0.0010585246115562628\n",
      "train loss:0.0012422350165182242\n",
      "train loss:0.00035989918144928307\n",
      "train loss:0.0012326117592054992\n",
      "train loss:0.0013877573718409492\n",
      "train loss:0.001281991060082378\n",
      "train loss:0.0005107234988320213\n",
      "train loss:0.018964536624033308\n",
      "train loss:0.002197788102639238\n",
      "train loss:0.0009614550193519099\n",
      "train loss:0.00036660421635617004\n",
      "train loss:0.0011524499938458004\n",
      "train loss:0.0029734194562374087\n",
      "train loss:0.0009465086735799786\n",
      "train loss:0.0006012733762403489\n",
      "train loss:0.004758680893272089\n",
      "train loss:0.0018047714391723959\n",
      "train loss:0.0005448337386319206\n",
      "train loss:0.0006600788795855313\n",
      "train loss:0.004090621383386818\n",
      "train loss:0.002567825662626715\n",
      "train loss:0.00010798368573659515\n",
      "train loss:0.005110406105782281\n",
      "train loss:0.00014669524597262017\n",
      "train loss:0.00026882152525623383\n",
      "train loss:0.0026091298546123526\n",
      "train loss:0.0023944897096651197\n",
      "train loss:0.004417007158037864\n",
      "train loss:0.0025822072261419988\n",
      "train loss:0.0011111489604062178\n",
      "train loss:0.0015587115689188872\n",
      "train loss:5.775451596017551e-05\n",
      "train loss:0.00043741683814388176\n",
      "train loss:0.001017875958101607\n",
      "train loss:0.0005931964687589892\n",
      "train loss:0.0005013213954151624\n",
      "train loss:0.0003835367701371014\n",
      "train loss:0.0004683402707493707\n",
      "train loss:0.00043218065597210156\n",
      "train loss:0.00049800325600915\n",
      "train loss:0.0029150167075368072\n",
      "train loss:0.0029489454014538937\n",
      "train loss:0.001993044139792964\n",
      "train loss:0.00013815653533010518\n",
      "train loss:0.0011116334942521205\n",
      "train loss:0.00034970040023432863\n",
      "train loss:9.128096407605505e-05\n",
      "train loss:0.0028044334260707952\n",
      "train loss:0.0006147724355280499\n",
      "train loss:0.0011901497980118137\n",
      "train loss:0.0008760574091435228\n",
      "train loss:0.00027639896318094133\n",
      "train loss:0.00014445769385871464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007838362759253727\n",
      "train loss:0.006479091482244998\n",
      "train loss:0.00017146769322486276\n",
      "train loss:9.594874864348206e-05\n",
      "train loss:0.0012091705209717214\n",
      "train loss:0.001117940232754677\n",
      "train loss:0.0008495523206469748\n",
      "train loss:0.00018503859243388933\n",
      "train loss:0.004413871997113178\n",
      "train loss:0.00031107313817072007\n",
      "train loss:5.897051220500515e-05\n",
      "train loss:0.0007999234480979022\n",
      "train loss:6.271451288741531e-05\n",
      "train loss:0.0019396044597329647\n",
      "train loss:0.0036216738968318225\n",
      "train loss:0.0024077489929196123\n",
      "train loss:0.004380207924157534\n",
      "train loss:0.0017239903492185641\n",
      "train loss:0.001010066028821431\n",
      "train loss:0.0008627469007969283\n",
      "train loss:0.0016414745595497455\n",
      "train loss:3.2592301886046396e-05\n",
      "train loss:0.0032966535870645477\n",
      "train loss:0.00013072769562874815\n",
      "train loss:0.0019204085069648225\n",
      "train loss:0.002820329036730367\n",
      "train loss:0.00040904905247352014\n",
      "train loss:0.00026647495948224783\n",
      "train loss:0.005460169255611938\n",
      "train loss:0.00012639612218711776\n",
      "train loss:0.0015180438410908\n",
      "train loss:4.2182683337500365e-05\n",
      "train loss:0.0020846980250098656\n",
      "train loss:0.004337018594744457\n",
      "train loss:3.490215178011901e-05\n",
      "train loss:0.00021236730210308586\n",
      "train loss:0.0035726578064945364\n",
      "train loss:0.00031032890309290267\n",
      "train loss:0.000581532855136123\n",
      "train loss:0.0003168185523371906\n",
      "train loss:0.0008840097139202743\n",
      "train loss:0.0006507596634075462\n",
      "train loss:0.005126564555274637\n",
      "train loss:0.00031587679914670387\n",
      "train loss:0.0035351407007794345\n",
      "train loss:0.008048033086375979\n",
      "train loss:0.0014789845742312403\n",
      "train loss:0.001029199044907433\n",
      "train loss:0.00039207531649180935\n",
      "train loss:0.0005604043304427618\n",
      "train loss:0.0001650213447106738\n",
      "train loss:0.00123072586327531\n",
      "train loss:0.0030085621520953842\n",
      "train loss:0.0012778200905100676\n",
      "train loss:2.9510797168323648e-05\n",
      "train loss:0.0024385614456211313\n",
      "train loss:0.000708564913023724\n",
      "train loss:0.00046148312829939324\n",
      "train loss:0.00020799719477705345\n",
      "train loss:0.0031539289587822032\n",
      "train loss:0.0015799499975014397\n",
      "train loss:0.0009460720886241436\n",
      "train loss:0.003214742987960024\n",
      "train loss:0.00022215939558189928\n",
      "train loss:0.0007363984444690834\n",
      "train loss:0.0005397055120433048\n",
      "train loss:0.00022866430841051355\n",
      "train loss:0.0009425215383072978\n",
      "train loss:0.0029160247012752277\n",
      "train loss:0.002563642434946449\n",
      "train loss:0.0038734400242228535\n",
      "train loss:0.0026734621496672796\n",
      "train loss:0.0007775523892743062\n",
      "train loss:0.0019769331354513235\n",
      "train loss:0.0016194761921675565\n",
      "train loss:0.0005106543585950078\n",
      "train loss:0.000366532723485532\n",
      "train loss:0.00033250987339397285\n",
      "train loss:0.002178226842753888\n",
      "train loss:0.006106926121822033\n",
      "train loss:9.24675523998418e-05\n",
      "train loss:0.003425253179534607\n",
      "train loss:0.002676264074745037\n",
      "train loss:0.0009312585048581744\n",
      "train loss:0.0016027931079457822\n",
      "train loss:0.0015916562520305602\n",
      "train loss:8.808459193525707e-05\n",
      "train loss:0.0017184674913525723\n",
      "train loss:0.0015633645777711725\n",
      "train loss:0.0008004555962077054\n",
      "train loss:0.0005566252769266754\n",
      "train loss:0.0011290731148833725\n",
      "train loss:4.0305559829900016e-05\n",
      "train loss:0.0002746181849519875\n",
      "train loss:0.0010133680094540872\n",
      "train loss:5.031313381410057e-05\n",
      "train loss:0.00029919131397544853\n",
      "train loss:0.0014256728554112117\n",
      "train loss:0.00015193929400608242\n",
      "train loss:0.002045490645431437\n",
      "train loss:0.001841795823575544\n",
      "train loss:0.00038446115243204036\n",
      "train loss:0.000250209289072863\n",
      "train loss:0.0014015005486232293\n",
      "train loss:0.000152842105227175\n",
      "train loss:0.00030205595806793794\n",
      "train loss:0.000665465928026387\n",
      "train loss:0.0012682590552497725\n",
      "train loss:0.003351478781021639\n",
      "train loss:7.900782148349553e-06\n",
      "train loss:2.414889927302409e-05\n",
      "train loss:0.0015512757864525122\n",
      "train loss:0.0009697449280258204\n",
      "train loss:4.1609236074704863e-05\n",
      "train loss:0.000713414951789722\n",
      "train loss:0.0015560337699488309\n",
      "train loss:0.0019309768003652648\n",
      "train loss:0.002804744088950818\n",
      "train loss:0.000726996314735073\n",
      "train loss:0.0008290601620384113\n",
      "train loss:3.217425839031963e-05\n",
      "train loss:0.00012050185766775954\n",
      "train loss:0.0019521126541252709\n",
      "train loss:0.0032010349303065976\n",
      "train loss:0.0044969503593499036\n",
      "train loss:0.001752487162048548\n",
      "train loss:0.0035397656150555805\n",
      "train loss:0.002614718109620418\n",
      "train loss:0.0010669901326071317\n",
      "train loss:3.4052839394281017e-05\n",
      "train loss:0.003104289029274637\n",
      "train loss:0.00462844419660545\n",
      "train loss:9.851127477538229e-05\n",
      "train loss:0.0009563083606920353\n",
      "train loss:0.0010152099042860904\n",
      "train loss:0.0033083606198419124\n",
      "train loss:0.0025906243030075866\n",
      "train loss:0.0010783285633463706\n",
      "train loss:0.0002002207890513174\n",
      "train loss:0.0038806115876738444\n",
      "train loss:0.002219186008427373\n",
      "train loss:0.0034191249081698717\n",
      "train loss:0.012143671522356854\n",
      "train loss:0.0014609571181148817\n",
      "train loss:0.0020654528471695955\n",
      "train loss:0.0002856749139885268\n",
      "train loss:0.0007742073369683629\n",
      "train loss:0.0005338915390065144\n",
      "train loss:0.0005253867272934388\n",
      "train loss:0.0008120770186284176\n",
      "train loss:0.0005929055505490983\n",
      "train loss:0.001317907820397633\n",
      "train loss:0.001086521421366085\n",
      "train loss:0.007134775308779202\n",
      "train loss:0.0010256918334182778\n",
      "train loss:0.016231808236459935\n",
      "train loss:0.00019482208742596714\n",
      "train loss:0.00012285921872703834\n",
      "train loss:0.0001373082027369297\n",
      "train loss:0.00257768950190007\n",
      "train loss:0.000528883503935967\n",
      "train loss:0.0021227478660223206\n",
      "train loss:0.00019414826276428204\n",
      "train loss:0.0006103718125991546\n",
      "train loss:0.0034694065468275415\n",
      "train loss:0.0025311396019183363\n",
      "train loss:0.0008397583823646738\n",
      "train loss:0.000307479803167719\n",
      "train loss:0.00019432325258359994\n",
      "train loss:0.0007734891500476219\n",
      "train loss:0.0011825484403088864\n",
      "train loss:0.0012544567336330154\n",
      "train loss:0.006288055310981714\n",
      "train loss:0.0028392490605706516\n",
      "train loss:0.00011217762007906506\n",
      "train loss:0.003006417338049461\n",
      "train loss:0.00011116964003159346\n",
      "train loss:0.0006312572752348737\n",
      "train loss:0.001261432933684907\n",
      "train loss:0.00025849529245092337\n",
      "train loss:0.0003363962679577172\n",
      "train loss:0.0019464459006415429\n",
      "train loss:0.00012023308228463151\n",
      "train loss:0.00045047730595833014\n",
      "train loss:0.0013909716842137332\n",
      "train loss:4.944801680267609e-05\n",
      "train loss:0.0022496726992329887\n",
      "train loss:0.0009304869287479967\n",
      "train loss:0.0006986670813259962\n",
      "train loss:0.0001782482543719032\n",
      "train loss:9.870546618786034e-05\n",
      "train loss:6.064898177560137e-05\n",
      "train loss:8.783077980937611e-05\n",
      "train loss:0.003092721521006364\n",
      "train loss:0.0034401759037029156\n",
      "train loss:0.0005212974928489928\n",
      "train loss:0.0002222140224458334\n",
      "train loss:0.008116108964065578\n",
      "train loss:8.80557746755627e-05\n",
      "train loss:0.000508087908547965\n",
      "train loss:0.0016578467165825712\n",
      "train loss:0.0026575187994916268\n",
      "train loss:0.00014620628449039624\n",
      "train loss:0.0007612590812909713\n",
      "train loss:0.0007070647373723263\n",
      "train loss:0.00073439251603595\n",
      "train loss:0.0005933048491252314\n",
      "train loss:8.727275949800915e-05\n",
      "train loss:0.002415352269636495\n",
      "train loss:0.0018411039890375367\n",
      "train loss:0.0011304063624786457\n",
      "train loss:0.0004324053935562644\n",
      "train loss:0.00032325688909980263\n",
      "train loss:0.0006091530785286938\n",
      "train loss:4.2734737112742935e-05\n",
      "train loss:0.0002714111402361004\n",
      "train loss:0.007267510369317582\n",
      "train loss:0.00018067810204134858\n",
      "train loss:0.00026883086572342\n",
      "train loss:0.0012532511272580434\n",
      "train loss:0.003379577934482799\n",
      "train loss:0.02032510016432314\n",
      "train loss:0.0012844977690341316\n",
      "train loss:0.0020923781961845562\n",
      "train loss:0.005482637277361706\n",
      "train loss:0.001018438585334364\n",
      "train loss:0.0035105237286529706\n",
      "train loss:0.0001810207550412065\n",
      "train loss:0.0009472855521574389\n",
      "train loss:0.004798769068818827\n",
      "train loss:0.0002269411164316126\n",
      "train loss:0.0026563864866426057\n",
      "train loss:0.0007849816148277751\n",
      "train loss:8.038742951612621e-05\n",
      "train loss:0.00011340115847788311\n",
      "train loss:0.00037549541237962155\n",
      "train loss:0.0019395212569264112\n",
      "train loss:0.0009087994699450122\n",
      "train loss:0.00017936705354789362\n",
      "train loss:0.000182443804369919\n",
      "train loss:0.00023887737229653808\n",
      "train loss:0.0004019880622886246\n",
      "train loss:0.005996525860469675\n",
      "train loss:0.00039847548417364673\n",
      "train loss:0.0012413465887819266\n",
      "train loss:0.0010111110034201345\n",
      "train loss:0.0004893915525846556\n",
      "train loss:0.0013500478692223458\n",
      "train loss:1.0075500329424529e-05\n",
      "train loss:0.0011107294774318707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006415930231624952\n",
      "train loss:0.000152469410528139\n",
      "train loss:5.090630333959972e-05\n",
      "train loss:0.00040099972878198905\n",
      "train loss:0.00016994776730761235\n",
      "train loss:0.00012272925887663643\n",
      "train loss:0.000342381002319334\n",
      "train loss:5.321279469907761e-05\n",
      "train loss:0.0037141460826237054\n",
      "train loss:0.0005353041610146237\n",
      "train loss:0.0015426067701283875\n",
      "train loss:0.000724978708648454\n",
      "train loss:0.0007659678281580393\n",
      "train loss:0.0005385763567660815\n",
      "train loss:0.0020191103253213057\n",
      "train loss:0.002219741305529587\n",
      "train loss:0.0007438683680815525\n",
      "train loss:0.0015171459582331433\n",
      "train loss:0.007075398408157834\n",
      "train loss:0.0003313645217214901\n",
      "train loss:0.0013141208255975935\n",
      "train loss:0.0038984104627699046\n",
      "train loss:0.0011636720497708117\n",
      "train loss:0.00026749748902430397\n",
      "train loss:0.0005440580408420035\n",
      "train loss:0.00145409428504255\n",
      "train loss:0.0002367719307700821\n",
      "train loss:0.003079916916637004\n",
      "train loss:0.00022120640138840507\n",
      "train loss:0.005372780203716165\n",
      "train loss:0.0009309161480996362\n",
      "train loss:0.00040090568957442806\n",
      "train loss:0.0005857176336258149\n",
      "train loss:0.0008906899843579082\n",
      "train loss:0.0027130747546829015\n",
      "train loss:0.00010654370929234328\n",
      "train loss:0.00020569596541203863\n",
      "train loss:0.0013505904482663971\n",
      "train loss:8.100776402335759e-05\n",
      "train loss:0.0006322791787535312\n",
      "train loss:0.0017916609818254283\n",
      "train loss:0.00021464528333734227\n",
      "train loss:7.514266572084701e-05\n",
      "train loss:0.0008771633460982574\n",
      "train loss:0.00232478106626117\n",
      "train loss:9.676096344746458e-05\n",
      "train loss:0.00022531151306064297\n",
      "train loss:0.000169597653763323\n",
      "train loss:0.001266130495037264\n",
      "train loss:0.0023083457113284717\n",
      "=== epoch:19, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.0007465330770396184\n",
      "train loss:0.00027944604124619795\n",
      "train loss:4.659968395875412e-05\n",
      "train loss:0.00038470605144586527\n",
      "train loss:2.84394521008285e-05\n",
      "train loss:0.00010628404587242974\n",
      "train loss:0.0018377238574109195\n",
      "train loss:0.0023993974187611527\n",
      "train loss:0.0003212465197166189\n",
      "train loss:0.00025233799238108637\n",
      "train loss:0.0001909120159644208\n",
      "train loss:0.0003119502121910201\n",
      "train loss:0.0009444558037759227\n",
      "train loss:0.001300959114735705\n",
      "train loss:0.0005186513946392851\n",
      "train loss:0.00013903346308010377\n",
      "train loss:0.0034269689171841427\n",
      "train loss:0.0021771522740867844\n",
      "train loss:0.0015914652885430408\n",
      "train loss:0.0012629644648419131\n",
      "train loss:0.0007210674382795279\n",
      "train loss:0.005196759568690965\n",
      "train loss:0.005051432952373884\n",
      "train loss:0.0053988279393649965\n",
      "train loss:0.005236345191719925\n",
      "train loss:0.00139119436785893\n",
      "train loss:0.0001336984478955253\n",
      "train loss:0.00010893229510966092\n",
      "train loss:0.0017336276382395551\n",
      "train loss:0.0003502164183119884\n",
      "train loss:0.00037469935936136194\n",
      "train loss:0.001646947073548721\n",
      "train loss:0.0005047893431461399\n",
      "train loss:0.0009099761852845014\n",
      "train loss:0.0002889978031141987\n",
      "train loss:0.005988041623314883\n",
      "train loss:0.004919923251108916\n",
      "train loss:0.0040994862906097405\n",
      "train loss:0.000551397198188679\n",
      "train loss:0.0025631574349973684\n",
      "train loss:0.005906851386150801\n",
      "train loss:0.003441175556353737\n",
      "train loss:0.0007024820692841931\n",
      "train loss:0.0006117119833000644\n",
      "train loss:0.001454804088808628\n",
      "train loss:0.0011054260077241805\n",
      "train loss:0.0023816735907668226\n",
      "train loss:0.0001283977041402783\n",
      "train loss:0.0006473916974708183\n",
      "train loss:0.00526198515094413\n",
      "train loss:2.6491331255240544e-05\n",
      "train loss:0.000790540031112327\n",
      "train loss:0.004462369378546309\n",
      "train loss:0.0002508082615398134\n",
      "train loss:0.0018235724210787893\n",
      "train loss:0.00028612446230097117\n",
      "train loss:0.004999357647801957\n",
      "train loss:0.0002596263785103393\n",
      "train loss:0.005282733760298098\n",
      "train loss:0.0003242686041026916\n",
      "train loss:7.299828549906949e-05\n",
      "train loss:0.004198331992923104\n",
      "train loss:0.0002362328905479052\n",
      "train loss:4.068839799462068e-05\n",
      "train loss:0.0002938060789317534\n",
      "train loss:0.0005391562964951364\n",
      "train loss:0.000940720474246857\n",
      "train loss:0.0014625482785443971\n",
      "train loss:0.002013187877140041\n",
      "train loss:4.516078388564172e-05\n",
      "train loss:0.013200725983650543\n",
      "train loss:0.005150414890400639\n",
      "train loss:0.0025383627135681843\n",
      "train loss:6.841743295846185e-05\n",
      "train loss:0.012768432408749562\n",
      "train loss:0.0004782920912877721\n",
      "train loss:0.0008708491457991151\n",
      "train loss:0.01651292894141539\n",
      "train loss:9.874241084690863e-05\n",
      "train loss:0.0017953865721723466\n",
      "train loss:2.393481691183398e-05\n",
      "train loss:0.00035735113110458883\n",
      "train loss:0.0010688193759859504\n",
      "train loss:0.00043972085781936307\n",
      "train loss:0.002999649513650356\n",
      "train loss:0.04838151431702582\n",
      "train loss:0.0020664932543091904\n",
      "train loss:0.0005856092472251558\n",
      "train loss:0.0018041451789272305\n",
      "train loss:0.00014043921647910432\n",
      "train loss:0.000776990320579055\n",
      "train loss:5.398184147642875e-05\n",
      "train loss:0.002427411886069131\n",
      "train loss:2.2890618480883437e-05\n",
      "train loss:0.000702725744768869\n",
      "train loss:7.395584407029271e-05\n",
      "train loss:0.0017791665719464275\n",
      "train loss:0.0004231671765536964\n",
      "train loss:5.7806197265043054e-05\n",
      "train loss:0.0014218167650387958\n",
      "train loss:0.00095038607995558\n",
      "train loss:0.0006224278143408365\n",
      "train loss:0.0010126342720744876\n",
      "train loss:7.76683648884122e-05\n",
      "train loss:0.00025892077109777314\n",
      "train loss:0.004406385416577028\n",
      "train loss:0.0021704788134411677\n",
      "train loss:0.001068268081976526\n",
      "train loss:0.005052377877364933\n",
      "train loss:0.004109426650875035\n",
      "train loss:0.0014714728015665837\n",
      "train loss:0.0005354773756665932\n",
      "train loss:0.0012909351673842512\n",
      "train loss:0.00208256776389309\n",
      "train loss:0.0004071850765783727\n",
      "train loss:0.0032815013269624923\n",
      "train loss:0.0002679236552454811\n",
      "train loss:0.000669835509690581\n",
      "train loss:0.012364899864440518\n",
      "train loss:0.0002730577210395509\n",
      "train loss:0.00040796343956055685\n",
      "train loss:0.0010498559297792433\n",
      "train loss:0.0009115078657413278\n",
      "train loss:0.0004777247698161095\n",
      "train loss:0.00031279513964030327\n",
      "train loss:0.0009297913571291154\n",
      "train loss:0.00011464093293068514\n",
      "train loss:7.231370085844144e-05\n",
      "train loss:7.077307322788912e-05\n",
      "train loss:0.0010450890103042396\n",
      "train loss:0.00207553685338366\n",
      "train loss:0.003733638164632994\n",
      "train loss:0.0002324670656737562\n",
      "train loss:0.0028186888677081546\n",
      "train loss:0.0012071601269828477\n",
      "train loss:0.0005789416231763143\n",
      "train loss:0.0001434317573251962\n",
      "train loss:0.0026227504240907097\n",
      "train loss:0.000274316311989291\n",
      "train loss:0.0005440650899770676\n",
      "train loss:0.00032094064215212507\n",
      "train loss:0.002422379552859469\n",
      "train loss:0.0025263144638154743\n",
      "train loss:0.00020153178876293265\n",
      "train loss:0.003691061899850547\n",
      "train loss:0.0002962516097969078\n",
      "train loss:0.0032432031234287044\n",
      "train loss:0.0010528085147394096\n",
      "train loss:0.0017340137986116624\n",
      "train loss:0.0019516557321083788\n",
      "train loss:0.004935683377257608\n",
      "train loss:0.0004958928829118108\n",
      "train loss:0.0010078179747501858\n",
      "train loss:0.00045042864802806193\n",
      "train loss:4.5925406035594265e-05\n",
      "train loss:0.0011345394694477393\n",
      "train loss:0.0004342196414691287\n",
      "train loss:2.5543264088245822e-05\n",
      "train loss:0.0023494783778008513\n",
      "train loss:0.0005572493912625167\n",
      "train loss:0.0007105153419496197\n",
      "train loss:0.0010673695483102436\n",
      "train loss:0.0009747922248174822\n",
      "train loss:0.001804870390973726\n",
      "train loss:0.000415963645478292\n",
      "train loss:0.00047890300963782583\n",
      "train loss:0.0003255801952424255\n",
      "train loss:0.0014712281135385882\n",
      "train loss:0.0002015199607604143\n",
      "train loss:0.00024195468258190057\n",
      "train loss:0.0006230161769305091\n",
      "train loss:0.0016659691013858834\n",
      "train loss:7.342530045059096e-05\n",
      "train loss:0.00016789078851335283\n",
      "train loss:0.00017632521591137912\n",
      "train loss:0.0014217282183303665\n",
      "train loss:2.587686600952241e-05\n",
      "train loss:0.0003035459993687222\n",
      "train loss:0.00010677588534220469\n",
      "train loss:0.00045801982096379276\n",
      "train loss:0.00032916713971688536\n",
      "train loss:0.013713968868738014\n",
      "train loss:0.0011043882039411042\n",
      "train loss:0.00012125693837730428\n",
      "train loss:0.00016579038709951417\n",
      "train loss:0.00018098057438517505\n",
      "train loss:0.0002281109219066759\n",
      "train loss:0.00043580954772348164\n",
      "train loss:0.0005507579896404508\n",
      "train loss:0.0005659176688809448\n",
      "train loss:0.00018203333064523784\n",
      "train loss:0.000898404014453502\n",
      "train loss:0.0037807752877201885\n",
      "train loss:7.371951175175195e-05\n",
      "train loss:0.0007265089355328777\n",
      "train loss:0.0002671142049073723\n",
      "train loss:0.0005131380827899958\n",
      "train loss:0.0010143895546672567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005510532515661027\n",
      "train loss:0.00010754564508371008\n",
      "train loss:0.0011144158438009704\n",
      "train loss:0.00025740354395773293\n",
      "train loss:0.0002113163622065851\n",
      "train loss:0.0011686433634655496\n",
      "train loss:0.0015532681681905967\n",
      "train loss:0.0014270391569326587\n",
      "train loss:0.0017187135224246983\n",
      "train loss:0.0024312059223781076\n",
      "train loss:0.00037513886634196405\n",
      "train loss:0.0006608375833513833\n",
      "train loss:0.0005103060797925241\n",
      "train loss:9.626084945921105e-05\n",
      "train loss:0.0012871714858828387\n",
      "train loss:0.00037236570135357286\n",
      "train loss:0.001724680729643885\n",
      "train loss:0.0012957701664453227\n",
      "train loss:0.00042706163313202257\n",
      "train loss:0.00011997428971237207\n",
      "train loss:9.381616791571712e-05\n",
      "train loss:0.00018648957200676647\n",
      "train loss:0.0009925896561934773\n",
      "train loss:0.005826524213418316\n",
      "train loss:0.00015901513886180436\n",
      "train loss:0.00041697004440575025\n",
      "train loss:0.00028856276071456796\n",
      "train loss:0.000810228116068168\n",
      "train loss:0.00014261111932588252\n",
      "train loss:0.00017450662091621815\n",
      "train loss:0.0002739178667172364\n",
      "train loss:0.005713202257584149\n",
      "train loss:0.0005056881334592325\n",
      "train loss:0.0031472224295224283\n",
      "train loss:0.000598781603074957\n",
      "train loss:0.0013678817725596923\n",
      "train loss:3.291163476541943e-05\n",
      "train loss:9.497310965885883e-05\n",
      "train loss:0.0009607203701207087\n",
      "train loss:0.0004494754606240722\n",
      "train loss:0.0007589975608607579\n",
      "train loss:6.329808931823425e-05\n",
      "train loss:6.300539283643685e-05\n",
      "train loss:0.008363114358048346\n",
      "train loss:0.0006122845552769227\n",
      "train loss:0.0004105129165525395\n",
      "train loss:0.00020165173512949597\n",
      "train loss:0.00020117292844874625\n",
      "train loss:0.0019919834875335367\n",
      "train loss:0.0009598832431052983\n",
      "train loss:0.001751492104300315\n",
      "train loss:0.00018077175828315364\n",
      "train loss:0.005616132978932393\n",
      "train loss:9.067982263441571e-05\n",
      "train loss:0.0016142666351450876\n",
      "train loss:0.0027691628258590534\n",
      "train loss:5.9166200675410875e-05\n",
      "train loss:0.0007464878003519698\n",
      "train loss:0.00018572767968337645\n",
      "train loss:3.4648592170731603e-05\n",
      "train loss:0.0002473237378267854\n",
      "train loss:0.0033796355496981973\n",
      "train loss:0.0022364172294173264\n",
      "train loss:6.62448831419024e-05\n",
      "train loss:0.00035384350161311065\n",
      "train loss:0.003817666488144633\n",
      "train loss:0.0014999589477075468\n",
      "train loss:0.003999597816374415\n",
      "train loss:0.00045331543385559515\n",
      "train loss:0.0002475689089261245\n",
      "train loss:0.00021891480086293203\n",
      "train loss:2.2614244093021688e-05\n",
      "train loss:0.0012073921856820856\n",
      "train loss:0.001506861299993108\n",
      "train loss:0.04418032115728566\n",
      "train loss:0.00041014339627735784\n",
      "train loss:0.00013312019713196226\n",
      "train loss:0.0003725493059667833\n",
      "train loss:0.0014277552205706019\n",
      "train loss:0.0002961999203216597\n",
      "train loss:0.00023959676102375108\n",
      "train loss:0.0008736800794512167\n",
      "train loss:0.000462499328984163\n",
      "train loss:0.0005483387792004968\n",
      "train loss:3.452168655583409e-05\n",
      "train loss:0.00029633490016451073\n",
      "train loss:0.002267268627647979\n",
      "train loss:0.00020555944594052145\n",
      "train loss:0.0027926878394188017\n",
      "train loss:0.0001453823273457522\n",
      "train loss:0.00043910388427329856\n",
      "train loss:4.732417760500425e-05\n",
      "train loss:0.0010236441994439331\n",
      "train loss:0.0021595365631091987\n",
      "train loss:0.0006023237201383313\n",
      "train loss:0.0017435952590569093\n",
      "train loss:7.22030481020757e-05\n",
      "train loss:0.001828443946919737\n",
      "train loss:0.0007528767082954382\n",
      "train loss:0.00018624029655823213\n",
      "train loss:0.0027453851266625805\n",
      "train loss:0.004150946245956717\n",
      "train loss:0.0014979392228135955\n",
      "train loss:0.0007125062840229308\n",
      "train loss:0.0016078499183335487\n",
      "train loss:0.0010628488063037943\n",
      "train loss:0.00020085276971921445\n",
      "train loss:0.00018898320388261786\n",
      "train loss:0.0008452926375453125\n",
      "train loss:0.0018123156199297272\n",
      "train loss:0.0025225889186206406\n",
      "train loss:0.0005647266902676602\n",
      "train loss:0.0005689456334734655\n",
      "train loss:0.0017866796222722999\n",
      "train loss:0.0005124307363200311\n",
      "train loss:0.00034526117383617\n",
      "train loss:0.0003090229734725883\n",
      "train loss:0.00036248708650448455\n",
      "train loss:0.0003140335004843776\n",
      "train loss:0.0002030476507123254\n",
      "train loss:0.0018764685308549785\n",
      "train loss:8.698053700978015e-05\n",
      "train loss:0.00012807769506426305\n",
      "train loss:0.00021446489548588267\n",
      "train loss:5.926699014763205e-05\n",
      "train loss:0.00013236973268037093\n",
      "train loss:0.0001991044591988697\n",
      "train loss:0.0010630040817597483\n",
      "train loss:0.0012135348217808233\n",
      "train loss:0.0012102072984988756\n",
      "train loss:0.0016859182226555763\n",
      "train loss:0.000664923190309194\n",
      "train loss:0.001049546894135629\n",
      "train loss:0.0006173583448985674\n",
      "train loss:0.0004781707133903505\n",
      "train loss:0.004461760085043201\n",
      "train loss:0.00027933312632631604\n",
      "train loss:0.0007769686659745903\n",
      "train loss:0.003944781380106864\n",
      "train loss:0.0002739761740183234\n",
      "train loss:0.0014749401854549044\n",
      "train loss:0.0013248736060972172\n",
      "train loss:0.001983160081004249\n",
      "train loss:0.0025029908941029285\n",
      "train loss:5.893225731315163e-05\n",
      "train loss:0.0002391399011700836\n",
      "train loss:0.0015888329953021695\n",
      "train loss:5.693202230274771e-05\n",
      "train loss:0.00010458237809353258\n",
      "train loss:0.0003503353510942447\n",
      "train loss:0.0005938957873707431\n",
      "train loss:0.0007294313072491072\n",
      "train loss:0.0003137868225916792\n",
      "train loss:0.0017149659153859575\n",
      "train loss:0.0004802604937476684\n",
      "train loss:0.0010820470290386465\n",
      "train loss:0.0004343542773206996\n",
      "train loss:0.0018034767642278132\n",
      "train loss:4.052010620548951e-05\n",
      "train loss:0.0022991959299387492\n",
      "train loss:3.630012953449283e-05\n",
      "train loss:1.7013692644935254e-05\n",
      "train loss:2.8094310216818974e-05\n",
      "train loss:6.257402618636811e-05\n",
      "train loss:0.0003828773915836671\n",
      "train loss:0.0004520858314879296\n",
      "train loss:5.501180467307144e-05\n",
      "train loss:0.00013649361182199257\n",
      "train loss:6.410566662971032e-05\n",
      "train loss:0.00015180863093413525\n",
      "train loss:2.2347768184147618e-05\n",
      "train loss:8.316215115326382e-05\n",
      "train loss:0.00013312240664679027\n",
      "train loss:0.0009081413464737984\n",
      "train loss:1.364515650452307e-05\n",
      "train loss:0.0012692939311819912\n",
      "train loss:0.00020025664959597461\n",
      "train loss:0.0010068505130829152\n",
      "train loss:2.2702474603516027e-05\n",
      "train loss:6.283430519015348e-05\n",
      "train loss:0.001039044636902479\n",
      "train loss:0.002842094507263385\n",
      "train loss:5.82258188684212e-06\n",
      "train loss:0.00010927421257687648\n",
      "train loss:0.00036966756109934316\n",
      "train loss:0.00032298886865382207\n",
      "train loss:0.0013235451954621627\n",
      "train loss:0.0006574961449015886\n",
      "train loss:3.8347464267433875e-05\n",
      "train loss:0.00031530621770163206\n",
      "train loss:0.0005157661811295936\n",
      "train loss:2.5794842707332776e-05\n",
      "train loss:0.0007086452654602574\n",
      "train loss:0.0009155378626884023\n",
      "train loss:0.0002379220237530591\n",
      "train loss:0.0002180210886954591\n",
      "train loss:0.001012072552546471\n",
      "train loss:0.0008269330872475593\n",
      "train loss:0.001146536899816484\n",
      "train loss:0.0003587179598606979\n",
      "train loss:0.002140188584149563\n",
      "train loss:0.00162540891651624\n",
      "train loss:0.0026016344359064275\n",
      "train loss:0.0011605602816376391\n",
      "train loss:9.443426571393746e-05\n",
      "train loss:0.002995719210141874\n",
      "train loss:0.0009713006579562546\n",
      "train loss:0.0012344276837872635\n",
      "train loss:4.070711113209758e-05\n",
      "train loss:0.0002003915844250591\n",
      "train loss:0.0016645501886161645\n",
      "train loss:0.00020850569496981726\n",
      "train loss:0.0024981691880243627\n",
      "train loss:0.00027965646513401847\n",
      "train loss:0.0012577727268178892\n",
      "train loss:0.0006973891706136271\n",
      "train loss:0.0007608517706272572\n",
      "train loss:0.002393290690445031\n",
      "train loss:0.0018892888222459725\n",
      "train loss:0.001600025599941978\n",
      "train loss:0.0001373600301277875\n",
      "train loss:0.0025092366192542657\n",
      "train loss:0.001656758554198131\n",
      "train loss:0.0008644114495462802\n",
      "train loss:0.0009595451267629582\n",
      "train loss:0.0017119275271326006\n",
      "train loss:0.00014414687963744388\n",
      "train loss:9.811541763779802e-05\n",
      "train loss:0.0013970675606173608\n",
      "train loss:0.00017048135782238514\n",
      "train loss:0.00017832544334893226\n",
      "train loss:0.0017170259830300422\n",
      "train loss:8.311896765850786e-05\n",
      "train loss:0.0028560705793642897\n",
      "train loss:0.017272304052243205\n",
      "train loss:0.001833393021352453\n",
      "train loss:0.000924775420309647\n",
      "train loss:0.0017453051237281629\n",
      "train loss:0.0013377741943300823\n",
      "train loss:0.0018599155634559787\n",
      "train loss:0.0003428602097126712\n",
      "train loss:0.0005795178590555126\n",
      "train loss:0.001962836664142111\n",
      "train loss:0.0021299602883235185\n",
      "train loss:0.0005009650362110366\n",
      "train loss:0.0009932930312545056\n",
      "train loss:0.0003998473809031549\n",
      "train loss:0.001458755118393527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0026696188351942535\n",
      "train loss:5.9539602021100364e-05\n",
      "train loss:2.6413623171311035e-05\n",
      "train loss:0.0024633440457100834\n",
      "train loss:0.00016903648363060013\n",
      "train loss:0.0006918329093244438\n",
      "train loss:0.00030695585621542536\n",
      "train loss:0.0012614295713883944\n",
      "train loss:0.0006647229276104164\n",
      "train loss:0.0001599057911470893\n",
      "train loss:0.0006260846958408887\n",
      "train loss:0.0017149793479484677\n",
      "train loss:0.0010189600073681675\n",
      "train loss:0.0032140921717110004\n",
      "train loss:0.0009984584387314414\n",
      "train loss:0.12033427402025268\n",
      "train loss:0.0032633798650852646\n",
      "train loss:4.527093531437952e-05\n",
      "train loss:0.0003053626511520456\n",
      "train loss:0.0024855351777618344\n",
      "train loss:0.00020442388067302048\n",
      "train loss:0.0004464823276827451\n",
      "train loss:0.0021708923980810215\n",
      "train loss:0.00013454216032361726\n",
      "train loss:3.3704548769641505e-05\n",
      "train loss:0.00044944378308067544\n",
      "train loss:0.0010365365270108198\n",
      "train loss:0.001480618067064623\n",
      "train loss:0.00011710340980319884\n",
      "train loss:0.0007424905636536559\n",
      "train loss:0.0025013879681751628\n",
      "train loss:0.00039622002010272604\n",
      "train loss:0.0013092567796559285\n",
      "train loss:0.02278159640846124\n",
      "train loss:0.00012475293747404317\n",
      "train loss:0.00011130714741423984\n",
      "train loss:0.00357499962585846\n",
      "train loss:0.00019592480819613005\n",
      "train loss:0.0021520129523822182\n",
      "train loss:7.414448741136501e-05\n",
      "train loss:0.0016697609040248246\n",
      "train loss:0.0014482725007291732\n",
      "train loss:5.683154607479866e-05\n",
      "train loss:8.684007422417468e-06\n",
      "train loss:3.781629971272852e-05\n",
      "train loss:0.0014978056986035449\n",
      "train loss:0.0010735212573618022\n",
      "train loss:0.00042133246804781503\n",
      "train loss:0.0011044139241230648\n",
      "train loss:0.0005957505863181629\n",
      "train loss:0.00027216192843245693\n",
      "train loss:2.897205410916617e-05\n",
      "train loss:0.0007746868705337662\n",
      "train loss:0.00044651250276779163\n",
      "train loss:0.001064266873437287\n",
      "train loss:0.0002442447749756728\n",
      "train loss:0.0001347680392147886\n",
      "train loss:0.0027079510130245204\n",
      "train loss:0.0008187500562387901\n",
      "train loss:0.0007864140745463792\n",
      "train loss:0.0051084322597142575\n",
      "train loss:7.11005575581849e-05\n",
      "train loss:0.0007173259683387492\n",
      "train loss:0.0002761209717263382\n",
      "train loss:0.0014059282926650474\n",
      "train loss:0.0017884122114683704\n",
      "train loss:0.004230250017591477\n",
      "train loss:0.0008353370243667274\n",
      "train loss:0.00011426434383684362\n",
      "train loss:0.00030064438570900453\n",
      "train loss:0.007993921192595645\n",
      "train loss:0.0031292447642546546\n",
      "train loss:0.003546913866718548\n",
      "train loss:0.0009146038336974036\n",
      "train loss:0.0006766517579370577\n",
      "train loss:0.0003582316633481234\n",
      "train loss:0.0004864475910033611\n",
      "train loss:0.0009789448215710476\n",
      "train loss:0.00011965222346907593\n",
      "train loss:0.004021564405858306\n",
      "train loss:0.000146690544398846\n",
      "train loss:0.00040058960864742377\n",
      "train loss:0.0022687885181111585\n",
      "train loss:9.916705705217942e-05\n",
      "train loss:0.00042251997074670464\n",
      "train loss:0.00031393702639255614\n",
      "train loss:6.247189624740894e-05\n",
      "train loss:0.0019387395294280184\n",
      "train loss:0.0003613879104583463\n",
      "train loss:0.0009507654026041018\n",
      "train loss:0.0007567667952758148\n",
      "train loss:0.001937081996466049\n",
      "train loss:0.0005592846453958158\n",
      "train loss:0.00037507445457050795\n",
      "train loss:0.0007269523721601416\n",
      "train loss:0.0002297865902726531\n",
      "train loss:0.0007839868928796996\n",
      "train loss:0.001369117752362069\n",
      "train loss:0.0014129371839348799\n",
      "train loss:0.00013043684539947096\n",
      "train loss:0.0001221665013230867\n",
      "train loss:6.22742969788181e-05\n",
      "train loss:4.515209219817049e-05\n",
      "train loss:0.0006009882525986787\n",
      "train loss:0.0005627796265124427\n",
      "train loss:0.00023806569870924707\n",
      "train loss:6.752674397162354e-05\n",
      "train loss:0.001133445289278622\n",
      "train loss:0.0005985055962626244\n",
      "train loss:0.0007373368127865381\n",
      "train loss:0.002396839913768008\n",
      "train loss:0.0011397198383882403\n",
      "train loss:0.00014983833812967482\n",
      "train loss:0.0005781733920758566\n",
      "train loss:0.0019051103373051942\n",
      "train loss:0.00020841838502862816\n",
      "train loss:0.001745783381537576\n",
      "train loss:0.0029564890466497844\n",
      "train loss:0.0011844997581833391\n",
      "train loss:0.0015872997993100196\n",
      "train loss:0.0010386998715761978\n",
      "train loss:0.0013661677967964504\n",
      "train loss:0.0004545052450704502\n",
      "train loss:0.00010353942855163894\n",
      "train loss:0.0008211971220806706\n",
      "train loss:0.00020284629498698033\n",
      "train loss:0.0008337618720374887\n",
      "train loss:0.0040101984797414345\n",
      "train loss:0.0008190990679494882\n",
      "train loss:6.360693116366568e-05\n",
      "train loss:0.0005222234884791864\n",
      "train loss:0.0018422935440195664\n",
      "train loss:0.00027836142101391603\n",
      "train loss:0.0001787967603674226\n",
      "train loss:0.001113862593775568\n",
      "train loss:1.84503013957744e-05\n",
      "train loss:0.0005996609653066019\n",
      "train loss:0.0007104812107718072\n",
      "train loss:0.002566849684198153\n",
      "train loss:0.004901510964968875\n",
      "train loss:0.005409916374944045\n",
      "train loss:0.00029691430846923796\n",
      "train loss:0.0004259244705188135\n",
      "train loss:0.001259297077775618\n",
      "train loss:0.0003857060811472286\n",
      "train loss:4.9216179498914706e-05\n",
      "train loss:0.0011834232079635117\n",
      "train loss:0.0005395669324478239\n",
      "train loss:0.0009056927141692288\n",
      "train loss:0.0020432793897129224\n",
      "train loss:0.0006478832991706567\n",
      "train loss:0.0009057516113170433\n",
      "train loss:0.03501315996954799\n",
      "train loss:0.0003723350026120361\n",
      "=== epoch:20, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.00010674131751937032\n",
      "train loss:1.1275897859393289e-05\n",
      "train loss:0.0006108572755744477\n",
      "train loss:0.006145386392555673\n",
      "train loss:0.026987771279227035\n",
      "train loss:0.0005489059082734799\n",
      "train loss:0.00270436534330954\n",
      "train loss:0.00048424202518659144\n",
      "train loss:0.003724782386780723\n",
      "train loss:0.0016320439647634387\n",
      "train loss:0.0018796957974536864\n",
      "train loss:0.002066963271572402\n",
      "train loss:5.098083791387974e-05\n",
      "train loss:5.630997905976246e-05\n",
      "train loss:0.0009912836763616374\n",
      "train loss:0.002358408916918648\n",
      "train loss:0.0003240038805622251\n",
      "train loss:0.00030351724489091923\n",
      "train loss:0.01166965092430924\n",
      "train loss:0.00018586398396044454\n",
      "train loss:3.85202281187613e-05\n",
      "train loss:5.999071512056743e-05\n",
      "train loss:0.0015469311161345888\n",
      "train loss:0.0006513796673202468\n",
      "train loss:0.0015096016452280192\n",
      "train loss:0.04624544249436908\n",
      "train loss:0.0007646693920545387\n",
      "train loss:0.0009697300143061974\n",
      "train loss:0.0018404480255267447\n",
      "train loss:0.00014419524345574353\n",
      "train loss:0.00017255791794152525\n",
      "train loss:0.0006465259501664723\n",
      "train loss:0.00037287536232797887\n",
      "train loss:0.000707936350813902\n",
      "train loss:0.0005427904026378883\n",
      "train loss:0.002006283987142567\n",
      "train loss:0.0007966379341972436\n",
      "train loss:0.009457726460183967\n",
      "train loss:0.006289132252715038\n",
      "train loss:0.00029455707919402566\n",
      "train loss:0.0017114862873466702\n",
      "train loss:0.00024087500178523398\n",
      "train loss:4.0354626112815775e-05\n",
      "train loss:0.0022094653904521835\n",
      "train loss:3.0364588780186216e-05\n",
      "train loss:0.00012820546964945103\n",
      "train loss:0.0009716423303524571\n",
      "train loss:7.270388821797074e-05\n",
      "train loss:0.0005100914872591374\n",
      "train loss:0.0008238822644473508\n",
      "train loss:7.21012131727818e-05\n",
      "train loss:6.02660676899651e-05\n",
      "train loss:1.805973983100975e-05\n",
      "train loss:9.08740844133279e-05\n",
      "train loss:0.0034318816820993153\n",
      "train loss:0.0034660565199961402\n",
      "train loss:0.0013804197165155415\n",
      "train loss:0.000291394545178922\n",
      "train loss:0.0001783424352423933\n",
      "train loss:3.638487616690317e-05\n",
      "train loss:0.0003785014028930876\n",
      "train loss:0.00015419984626040877\n",
      "train loss:0.001485691563662858\n",
      "train loss:0.0009219609480728814\n",
      "train loss:0.0005916153980418873\n",
      "train loss:0.0021913867918406547\n",
      "train loss:0.00021742579206146528\n",
      "train loss:0.0011032104239030072\n",
      "train loss:0.0003922394221519209\n",
      "train loss:0.0008179177412968213\n",
      "train loss:4.301879720349039e-05\n",
      "train loss:0.00018664034346272228\n",
      "train loss:0.0011097681159448062\n",
      "train loss:0.0025835873983691\n",
      "train loss:0.002746330339016856\n",
      "train loss:0.0005163414304341973\n",
      "train loss:4.88844837053126e-05\n",
      "train loss:0.00014190475135147094\n",
      "train loss:4.668633008770178e-05\n",
      "train loss:0.0006228479439569623\n",
      "train loss:0.0021615133053042015\n",
      "train loss:0.00010257706414082586\n",
      "train loss:0.002488698231913883\n",
      "train loss:1.8601536972865058e-05\n",
      "train loss:8.381673654157546e-05\n",
      "train loss:2.0004339664991514e-05\n",
      "train loss:0.0015835276041124705\n",
      "train loss:0.0042397843876214245\n",
      "train loss:0.000593038795411811\n",
      "train loss:0.0005445341571547539\n",
      "train loss:0.0005792011676696483\n",
      "train loss:0.0003441208604949502\n",
      "train loss:0.007933533316145384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007555705698303069\n",
      "train loss:0.0013205262517945221\n",
      "train loss:0.0015117356434436143\n",
      "train loss:0.00024524246221555636\n",
      "train loss:0.0002244327882229699\n",
      "train loss:0.0030333756623037666\n",
      "train loss:0.0028218621609451306\n",
      "train loss:6.684017070435872e-05\n",
      "train loss:0.00031172115806269677\n",
      "train loss:0.0028297030172301286\n",
      "train loss:5.009646780189437e-05\n",
      "train loss:0.0006169513191906411\n",
      "train loss:0.000816633911575983\n",
      "train loss:0.026919380204355622\n",
      "train loss:8.124279492165734e-05\n",
      "train loss:0.004746716553031942\n",
      "train loss:0.0023822784833342795\n",
      "train loss:0.0004140438775977994\n",
      "train loss:0.001015656382138327\n",
      "train loss:0.00023285776864323833\n",
      "train loss:0.0006065508948847671\n",
      "train loss:0.0004953685897904691\n",
      "train loss:0.004034431450110956\n",
      "train loss:0.0027020456103835034\n",
      "train loss:0.005163533994033108\n",
      "train loss:0.0005086208957900507\n",
      "train loss:0.000704414998153529\n",
      "train loss:0.002764436909504695\n",
      "train loss:0.0006224136727829462\n",
      "train loss:0.0001148671473361167\n",
      "train loss:0.0015011292339771184\n",
      "train loss:0.04514677476634487\n",
      "train loss:0.001569820906129554\n",
      "train loss:0.022214853546443415\n",
      "train loss:0.0002629182509115894\n",
      "train loss:8.911127367264137e-05\n",
      "train loss:0.0003526081158647565\n",
      "train loss:0.0009312216806634119\n",
      "train loss:0.003931100402805402\n",
      "train loss:0.0001612805354638207\n",
      "train loss:0.003035956620097627\n",
      "train loss:0.0013582918215427544\n",
      "train loss:2.4167066675822552e-05\n",
      "train loss:0.0036281815716518472\n",
      "train loss:0.0002658310433739194\n",
      "train loss:0.0017136608567028385\n",
      "train loss:0.0020180592652912998\n",
      "train loss:0.0012002971333312513\n",
      "train loss:5.3812018236816976e-05\n",
      "train loss:9.611649417485381e-05\n",
      "train loss:0.003915586889660098\n",
      "train loss:0.00018889964587534612\n",
      "train loss:4.044314406081314e-05\n",
      "train loss:8.054247254010163e-05\n",
      "train loss:0.0008386455757036615\n",
      "train loss:0.0004150932835539779\n",
      "train loss:0.0012685367870006975\n",
      "train loss:0.00034912545052836113\n",
      "train loss:0.0004428966829095869\n",
      "train loss:0.0004999103731929892\n",
      "train loss:0.0005159886072041926\n",
      "train loss:0.0006252303907460276\n",
      "train loss:0.0013935435563459239\n",
      "train loss:0.00034722139644595055\n",
      "train loss:0.0071341182391532094\n",
      "train loss:0.0001195064008823338\n",
      "train loss:0.0012471210778661837\n",
      "train loss:0.0002813876271883822\n",
      "train loss:0.0009196149488337983\n",
      "train loss:0.000588382881335561\n",
      "train loss:0.002440246607060479\n",
      "train loss:7.18783325547827e-05\n",
      "train loss:0.0011388465491155965\n",
      "train loss:0.0002711300170825812\n",
      "train loss:0.0019278899093658596\n",
      "train loss:0.00048581590717161865\n",
      "train loss:7.119722043552884e-05\n",
      "train loss:0.0002618077142442289\n",
      "train loss:0.0002894105487728752\n",
      "train loss:0.007259965249410964\n",
      "train loss:0.0005413605826054921\n",
      "train loss:0.00028924595216522756\n",
      "train loss:0.0006207981296025466\n",
      "train loss:0.0003469002499178737\n",
      "train loss:4.301727639867225e-05\n",
      "train loss:0.00054109097902149\n",
      "train loss:0.0007214576246588531\n",
      "train loss:0.0006670415000273565\n",
      "train loss:0.003125831501976296\n",
      "train loss:0.0011788195539850872\n",
      "train loss:0.0005689035035933282\n",
      "train loss:9.466813019579529e-05\n",
      "train loss:8.056755182259161e-05\n",
      "train loss:0.0022904294671373822\n",
      "train loss:0.001312021586735636\n",
      "train loss:0.001779050331302999\n",
      "train loss:8.342688507584371e-05\n",
      "train loss:3.327104446082172e-05\n",
      "train loss:0.0004909522147431483\n",
      "train loss:0.002087155232543643\n",
      "train loss:0.0012095614843999466\n",
      "train loss:0.0003299313505229403\n",
      "train loss:0.002654606389590827\n",
      "train loss:0.0006456146714462521\n",
      "train loss:0.0012341999860257383\n",
      "train loss:9.990228573364414e-05\n",
      "train loss:0.0007141169078638246\n",
      "train loss:0.00010819595546680178\n",
      "train loss:0.0005660252399383977\n",
      "train loss:5.662790628203818e-05\n",
      "train loss:0.0001848877954903709\n",
      "train loss:0.001770778947952057\n",
      "train loss:0.00098104211397845\n",
      "train loss:0.0009074130971873568\n",
      "train loss:7.965816422528081e-05\n",
      "train loss:7.592437645218436e-06\n",
      "train loss:0.00015188429972893226\n",
      "train loss:0.00032464256270105696\n",
      "train loss:0.000282699053091438\n",
      "train loss:0.0005266256986935958\n",
      "train loss:0.00010988328783184139\n",
      "train loss:0.0005279801944341227\n",
      "train loss:1.5910915850280385e-05\n",
      "train loss:0.001230258026340851\n",
      "train loss:0.0007906345813093467\n",
      "train loss:0.0015631179448267294\n",
      "train loss:0.0005205432575329073\n",
      "train loss:0.0007361798527659878\n",
      "train loss:0.0013975359315423303\n",
      "train loss:0.001233618805888653\n",
      "train loss:0.00028908933434111786\n",
      "train loss:0.0004673941200411684\n",
      "train loss:0.00016199146401837017\n",
      "train loss:1.6510851878361485e-05\n",
      "train loss:0.0017952199765332863\n",
      "train loss:0.0011318694502763437\n",
      "train loss:0.0005780054878012083\n",
      "train loss:0.0002810741498877584\n",
      "train loss:0.0006452063514834665\n",
      "train loss:0.0002348588310468395\n",
      "train loss:0.0016749258272150222\n",
      "train loss:4.868713075892457e-05\n",
      "train loss:3.288350606418686e-05\n",
      "train loss:9.832447411270236e-05\n",
      "train loss:0.0003372388008748291\n",
      "train loss:0.0010097723018989244\n",
      "train loss:9.430725174985279e-05\n",
      "train loss:0.0009483985912225055\n",
      "train loss:0.003457491336320512\n",
      "train loss:0.00022583612174088548\n",
      "train loss:0.000734433529391735\n",
      "train loss:0.00012881135034302542\n",
      "train loss:0.0002692395299164199\n",
      "train loss:0.00017507401815592945\n",
      "train loss:0.00018337669385701122\n",
      "train loss:0.00019425873429473837\n",
      "train loss:0.00029028367277621203\n",
      "train loss:0.0025832132190891643\n",
      "train loss:0.0015816645722468872\n",
      "train loss:0.0006798496623282386\n",
      "train loss:3.628766292504346e-05\n",
      "train loss:0.00031387348762458827\n",
      "train loss:1.1119652745627186e-05\n",
      "train loss:0.0012598550563052884\n",
      "train loss:0.00010365854620379643\n",
      "train loss:0.000400511751507869\n",
      "train loss:0.001030214213942698\n",
      "train loss:0.0006809651643287953\n",
      "train loss:0.0001617502925846877\n",
      "train loss:0.00017427650444321686\n",
      "train loss:0.006432023815593117\n",
      "train loss:0.002905126048291618\n",
      "train loss:0.0007949140950993785\n",
      "train loss:0.0004250641981022234\n",
      "train loss:0.00011558601676465766\n",
      "train loss:0.0016458712051755555\n",
      "train loss:0.00039601115125585744\n",
      "train loss:0.0007846667330041137\n",
      "train loss:0.0019226889129085956\n",
      "train loss:0.002660262197058787\n",
      "train loss:0.0055346010965321955\n",
      "train loss:0.003184770847944831\n",
      "train loss:0.0003767600145617759\n",
      "train loss:0.0009129604375305568\n",
      "train loss:0.00020431726897974833\n",
      "train loss:0.0006012985630454206\n",
      "train loss:0.00488679640276813\n",
      "train loss:0.00017038578702482414\n",
      "train loss:0.0003708761038337766\n",
      "train loss:0.0001324853565383621\n",
      "train loss:0.0001103654526225095\n",
      "train loss:0.0009811621100550662\n",
      "train loss:5.152361902663758e-05\n",
      "train loss:0.0012712347310893312\n",
      "train loss:0.00034612343846630297\n",
      "train loss:9.998890503226218e-05\n",
      "train loss:0.001066581687291076\n",
      "train loss:0.0007133400221662267\n",
      "train loss:0.0002853676730182844\n",
      "train loss:0.0017252889771915481\n",
      "train loss:7.15988335425513e-05\n",
      "train loss:0.00033656675887898017\n",
      "train loss:0.0020756770468401513\n",
      "train loss:0.0013821209740597687\n",
      "train loss:0.0015083872818896452\n",
      "train loss:4.649818042352335e-05\n",
      "train loss:0.0002133834590486554\n",
      "train loss:0.0015477679256105002\n",
      "train loss:0.00034371514711576393\n",
      "train loss:0.0012900183800463605\n",
      "train loss:3.6624162043528607e-05\n",
      "train loss:0.0009562021448661773\n",
      "train loss:0.00038856236962140543\n",
      "train loss:8.174755958177767e-05\n",
      "train loss:0.00021045876025972622\n",
      "train loss:0.00013018019643225664\n",
      "train loss:0.0003310076053842216\n",
      "train loss:0.00012882889395585449\n",
      "train loss:0.0014730221191477334\n",
      "train loss:0.00048565790164903036\n",
      "train loss:0.0006275590152868389\n",
      "train loss:8.921725094873852e-05\n",
      "train loss:0.001933509450031088\n",
      "train loss:7.891477614117348e-05\n",
      "train loss:0.0012148322138816042\n",
      "train loss:0.0005240649430208715\n",
      "train loss:0.002537912067214834\n",
      "train loss:0.000496901494531829\n",
      "train loss:0.002261748097216027\n",
      "train loss:0.0006355141830001759\n",
      "train loss:0.00012916613721559065\n",
      "train loss:0.0005029857150391534\n",
      "train loss:1.0932426590082464e-05\n",
      "train loss:0.001975197549208662\n",
      "train loss:8.35393731204417e-06\n",
      "train loss:0.0006130557054687388\n",
      "train loss:0.0022319477542774757\n",
      "train loss:0.0025794846443052423\n",
      "train loss:0.0007736035046348942\n",
      "train loss:0.002952120574680157\n",
      "train loss:0.0009557613319250641\n",
      "train loss:0.0010082931451544609\n",
      "train loss:0.00403816771682229\n",
      "train loss:0.00018711888565893872\n",
      "train loss:0.00027844431959802245\n",
      "train loss:0.0005127787412327504\n",
      "train loss:7.57892185361084e-05\n",
      "train loss:0.0012533758952245361\n",
      "train loss:0.0038111161313628765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006400482112833724\n",
      "train loss:0.002413711931746683\n",
      "train loss:0.0002024963141752395\n",
      "train loss:8.36532742852469e-05\n",
      "train loss:6.0673403699875856e-05\n",
      "train loss:0.0005068265367971926\n",
      "train loss:0.0013794548226428883\n",
      "train loss:0.00019326719321723258\n",
      "train loss:0.0012848174167320787\n",
      "train loss:7.898436754780842e-05\n",
      "train loss:0.0025375858937123014\n",
      "train loss:0.00011425730491690481\n",
      "train loss:0.0007930480877399732\n",
      "train loss:0.002602386513798926\n",
      "train loss:0.000574314004131685\n",
      "train loss:0.001352837614143711\n",
      "train loss:0.000142826442039533\n",
      "train loss:0.0016759243670878478\n",
      "train loss:0.0038943963096948575\n",
      "train loss:0.005188652510592202\n",
      "train loss:0.00024785295877502065\n",
      "train loss:0.0018154190097151195\n",
      "train loss:0.0007575717578615994\n",
      "train loss:0.0006587801518635998\n",
      "train loss:0.00017314552679097907\n",
      "train loss:0.0013278421513274888\n",
      "train loss:3.748687856404235e-05\n",
      "train loss:0.00015470207008579432\n",
      "train loss:0.001487014565240176\n",
      "train loss:0.0033171977795018377\n",
      "train loss:0.00194303189226606\n",
      "train loss:0.0011332683349328902\n",
      "train loss:0.004911971013108684\n",
      "train loss:0.0007680677508950409\n",
      "train loss:0.001716376384163639\n",
      "train loss:0.0005212644800423012\n",
      "train loss:0.0016229394748711776\n",
      "train loss:0.004041451256088244\n",
      "train loss:0.001039360610876022\n",
      "train loss:0.0007388122546665982\n",
      "train loss:6.44688100066648e-05\n",
      "train loss:0.0007817531994431929\n",
      "train loss:0.008468882355976048\n",
      "train loss:0.001031717843442494\n",
      "train loss:0.0038448353171827766\n",
      "train loss:0.00022448324808661601\n",
      "train loss:0.00016396871783129187\n",
      "train loss:0.0022938890101107112\n",
      "train loss:0.00042371047157868826\n",
      "train loss:0.0001931556648323405\n",
      "train loss:0.0002294838891764401\n",
      "train loss:0.0019251877841140886\n",
      "train loss:0.0020546213989087016\n",
      "train loss:0.0005114376350576151\n",
      "train loss:0.0008042770499950908\n",
      "train loss:2.6872099371558836e-05\n",
      "train loss:4.761242167907883e-05\n",
      "train loss:0.0018296121354613754\n",
      "train loss:0.0009453836090888271\n",
      "train loss:0.006342102277367538\n",
      "train loss:0.0016526885331415045\n",
      "train loss:9.090434973100695e-05\n",
      "train loss:0.0001987146917994532\n",
      "train loss:0.0017616036314279002\n",
      "train loss:0.00013431216219009361\n",
      "train loss:0.0004093732088426692\n",
      "train loss:0.0022093118697467636\n",
      "train loss:3.1564208344050154e-05\n",
      "train loss:0.0007038999904055296\n",
      "train loss:0.0007516084797653165\n",
      "train loss:0.0029867868390910496\n",
      "train loss:0.0024515082604907564\n",
      "train loss:0.00052104927529789\n",
      "train loss:0.0008952738949569311\n",
      "train loss:0.0008446385091826158\n",
      "train loss:3.055566626883697e-05\n",
      "train loss:0.0003497795439771768\n",
      "train loss:0.00043722502936733817\n",
      "train loss:0.00015406328196040283\n",
      "train loss:0.014060711455018504\n",
      "train loss:0.0008623047466055461\n",
      "train loss:0.0005494061511584506\n",
      "train loss:0.00014700381642838683\n",
      "train loss:1.0401181865071997e-05\n",
      "train loss:0.00016534952608696508\n",
      "train loss:0.002160337171683534\n",
      "train loss:0.00026441474898824846\n",
      "train loss:0.00389309079593739\n",
      "train loss:0.00030864852210217797\n",
      "train loss:0.0012575490349456563\n",
      "train loss:0.0001138883524283949\n",
      "train loss:4.9211094730889874e-05\n",
      "train loss:0.002783264519706953\n",
      "train loss:0.0004782329259641288\n",
      "train loss:0.003814254636433625\n",
      "train loss:0.0012502741075506513\n",
      "train loss:0.00030814756527837515\n",
      "train loss:0.00010120806346318647\n",
      "train loss:0.00017480252634428058\n",
      "train loss:0.0015365667381130397\n",
      "train loss:3.946423180158384e-05\n",
      "train loss:0.0005894399029124899\n",
      "train loss:0.0007730249018191506\n",
      "train loss:0.000613747551396981\n",
      "train loss:2.9207875716254367e-05\n",
      "train loss:6.593120141788946e-05\n",
      "train loss:8.388166364234296e-05\n",
      "train loss:0.0002368904303546473\n",
      "train loss:0.0016827989305497058\n",
      "train loss:0.0009743375399095598\n",
      "train loss:0.0004877554203945306\n",
      "train loss:0.0006439463752308965\n",
      "train loss:0.00018644076301812564\n",
      "train loss:2.52105221850468e-05\n",
      "train loss:0.0007902874557085716\n",
      "train loss:0.00013519950071764128\n",
      "train loss:0.001033915030692622\n",
      "train loss:2.0196817342470094e-05\n",
      "train loss:0.0007090920155032089\n",
      "train loss:0.00019665700156003312\n",
      "train loss:0.0006601166011799884\n",
      "train loss:0.0004929228110847846\n",
      "train loss:9.862952284089386e-05\n",
      "train loss:8.081341316793292e-05\n",
      "train loss:7.355658001693251e-05\n",
      "train loss:0.0003655899837515889\n",
      "train loss:0.00014655820491238033\n",
      "train loss:0.001082046552498233\n",
      "train loss:0.001412160845318187\n",
      "train loss:0.0008783440953590932\n",
      "train loss:4.7630163964831224e-05\n",
      "train loss:0.002459366718680367\n",
      "train loss:0.00025397267902864683\n",
      "train loss:4.5043237206271744e-05\n",
      "train loss:9.201822328679846e-05\n",
      "train loss:0.0020226206349511656\n",
      "train loss:0.0018187704568478613\n",
      "train loss:0.0004385836678443533\n",
      "train loss:0.0013453581505438353\n",
      "train loss:0.00035588832847459855\n",
      "train loss:0.00017028860903699916\n",
      "train loss:0.0025368378766697543\n",
      "train loss:0.002004310191032265\n",
      "train loss:0.0003784435451094527\n",
      "train loss:4.7603545671268206e-05\n",
      "train loss:3.212993375583908e-05\n",
      "train loss:0.0034701177728703476\n",
      "train loss:0.00027532111732718706\n",
      "train loss:6.360036707206361e-05\n",
      "train loss:0.0018299893674900355\n",
      "train loss:0.0037675461493456045\n",
      "train loss:0.0001137174393412145\n",
      "train loss:0.0016523983921919421\n",
      "train loss:0.003835657518590771\n",
      "train loss:0.00022412984500896202\n",
      "train loss:0.0003697849724428814\n",
      "train loss:0.00041642400629796365\n",
      "train loss:0.0009542852243793026\n",
      "train loss:0.00024233031431264364\n",
      "train loss:0.0010540139990336834\n",
      "train loss:0.00044779238536151106\n",
      "train loss:0.0013064983699262484\n",
      "train loss:0.00011420676676965051\n",
      "train loss:0.00016301274994158217\n",
      "train loss:0.00048163581833254496\n",
      "train loss:0.0010754177943657856\n",
      "train loss:0.00042887092204619615\n",
      "train loss:0.0002267000333597804\n",
      "train loss:0.0012187292810269335\n",
      "train loss:0.0034993928279627544\n",
      "train loss:0.00024620634529900207\n",
      "train loss:0.0015402883554750033\n",
      "train loss:0.0005959850323426965\n",
      "train loss:0.002539949171247877\n",
      "train loss:0.0014753094131021236\n",
      "train loss:0.00032648199502278795\n",
      "train loss:0.00036840537381033716\n",
      "train loss:0.0004782533154779814\n",
      "train loss:7.564642451840194e-05\n",
      "train loss:0.0012457425762930244\n",
      "train loss:0.00032780194820140836\n",
      "train loss:0.00010425381449541701\n",
      "train loss:7.237278992032681e-05\n",
      "train loss:0.0006430369136643562\n",
      "train loss:0.00310827622785698\n",
      "train loss:2.9280314611096697e-05\n",
      "train loss:0.002159604535100249\n",
      "train loss:2.1787835977001212e-05\n",
      "train loss:0.0006340326419648244\n",
      "train loss:0.00019881851373387222\n",
      "train loss:0.00033652905221217644\n",
      "train loss:0.00017647886635131923\n",
      "train loss:8.908010776981855e-05\n",
      "train loss:0.0022725843946499306\n",
      "train loss:1.1059948110140098e-05\n",
      "train loss:0.00035522700043209816\n",
      "train loss:0.0005877898091800617\n",
      "train loss:0.00025609575555024197\n",
      "train loss:0.00015735807974973386\n",
      "train loss:0.00017055171122827174\n",
      "train loss:0.000873883117482411\n",
      "train loss:0.00029557233159302785\n",
      "train loss:0.00014948259439846297\n",
      "train loss:0.0013346827749470616\n",
      "train loss:0.00033772021260390964\n",
      "train loss:1.0727807602471166e-05\n",
      "train loss:0.00038387357382885327\n",
      "train loss:0.000583067303631318\n",
      "train loss:6.805786885724403e-05\n",
      "train loss:0.002025300460159744\n",
      "train loss:0.00024099107544749788\n",
      "train loss:0.00036309074998127315\n",
      "train loss:5.619487871201329e-05\n",
      "train loss:0.007689846194945299\n",
      "train loss:0.0005216791463699467\n",
      "train loss:8.39053485508724e-05\n",
      "train loss:0.0009926715494383504\n",
      "train loss:0.0007408108535098383\n",
      "train loss:0.00011888369397845613\n",
      "train loss:0.0005357222486070234\n",
      "train loss:0.0030638270026174313\n",
      "train loss:5.1305248267443425e-05\n",
      "train loss:0.0004706680152478946\n",
      "train loss:6.481056933792888e-05\n",
      "train loss:0.043135310206224624\n",
      "train loss:8.446972941360651e-05\n",
      "train loss:0.0004203159818802715\n",
      "train loss:1.1300689348024359e-05\n",
      "train loss:5.20370765123415e-05\n",
      "train loss:0.00012927908552656502\n",
      "train loss:0.00045039613253337977\n",
      "train loss:0.0007019148507143366\n",
      "train loss:0.001663667368582994\n",
      "train loss:0.0032636508484285777\n",
      "train loss:0.00568367512862099\n",
      "train loss:0.0007993279898026019\n",
      "train loss:0.0006175385263679977\n",
      "train loss:0.0022223550639734763\n",
      "train loss:0.0003410913214955008\n",
      "train loss:0.0027716008200991617\n",
      "train loss:1.1331925794220403e-05\n",
      "train loss:0.0007820320079490613\n",
      "train loss:0.0018391617216757241\n",
      "train loss:0.002469844661122238\n",
      "train loss:0.00010392976697795451\n",
      "train loss:0.0006388634426982202\n",
      "train loss:0.0024100671352776954\n",
      "train loss:0.0013936151120449735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011971318991036283\n",
      "train loss:0.0018412231391073857\n",
      "train loss:0.0014726369553277184\n",
      "train loss:1.2272068992568254e-05\n",
      "train loss:0.001849260428837766\n",
      "train loss:0.00031435263553067713\n",
      "train loss:0.0015414082922136226\n",
      "train loss:1.9042886198774183e-05\n",
      "train loss:6.007062092706354e-05\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9899\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "#用SimpleConvNet训练手写数字识别\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 处理花费时间较长的情况下减少数据 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 保存参数\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 绘制图形\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.CNN 的可视化\n",
    "CNN 中用到的卷积层在“观察”什么呢？本节将通过卷积层的可视化，探索 CNN 中到底进行了什么处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第 1 层权重的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 随机进行初始化后的权重\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学习后的权重\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**学习前和学习后的第 1 层的卷积层的权重：虽然权重的元素是实数，但是在图像的显示上，统一将最小值显示为黑色（0），最大值显示为白色（255）**\n",
    "第二个图中的有规律的滤波器在“观察”什么，答案就是它在观察边缘（颜色变化的分界线）和斑块（局部的块状区域）等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于分层结构的信息提取\n",
    "<img src=\"img/convolution_info.png\" width=80%>\n",
    "<center>CNN 的卷积层中提取的信息。第1层的神经元对边缘或斑块有响应，第3层对纹理有响应，第5层对物体部件有响应，最后的全连接层对物体的类别有响应</center>\n",
    "\n",
    "如果堆叠了多层卷积层，则随着层次加深，提取的信息也愈加复杂、抽象，这是深度学习中很有意思的一个地方。最开始的层对简单的边缘有响应，接下来的层对纹理有响应，再后面的层对更加复杂的物体部件有响应。也就是说，随着层次加深，神经元从简单的形状向“高级”信息变化。换句话说，就像我们理解东西的“含义”一样，响应的对象在逐渐变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.具有代表性的 CNN\n",
    "\n",
    "关于 CNN，迄今为止已经提出了各种网络结构。这里，我们介绍其中特别重要的两个网络，一个是在 1998 年首次被提出的 CNN 元祖 LeNet[20]，另一个是在深度学习受到关注的 2012 年被提出的 AlexNet。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
